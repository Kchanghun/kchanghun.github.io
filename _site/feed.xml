<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-08-28T16:44:55+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">No Free Knowledge</title><subtitle>There is No Free Knowledge when we study something.</subtitle><author><name>Chang Hun Kang</name></author><entry><title type="html">Recurrent Neural Networks (RNNs): A gentle Introduction and Overview</title><link href="http://localhost:4000/paper%20review/2022/08/28/Recurrent-Neural-Networks-A-gentle-Introduction-and-Overview.html" rel="alternate" type="text/html" title="Recurrent Neural Networks (RNNs): A gentle Introduction and Overview" /><published>2022-08-28T16:44:13+09:00</published><updated>2022-08-28T16:44:13+09:00</updated><id>http://localhost:4000/paper%20review/2022/08/28/Recurrent-Neural-Networks:A-gentle-Introduction-and-Overview</id><content type="html" xml:base="http://localhost:4000/paper%20review/2022/08/28/Recurrent-Neural-Networks-A-gentle-Introduction-and-Overview.html"><![CDATA[<h1 id="abstract">Abstract</h1>
<p>“Language Modeling &amp; Generating Text”, “Speech Recognition”, “Generating Image Descriptions” or<br />
“Video Tagging” 분야에서 해결책을 위한 최신기술들은 RNN을 기반으로 하고있다.<br />
따라서 현재 또는 앞으로 제시될 해결책들에 대한 구조를 이해하고 따라잡으려면<br />
RNN에 대한 기본 개념을 이해하는 것이 매우 중요할 것이다.<br />
이 논문에서는 BPTT, LSTM 뿐만아니라 Attention Mechanism과 Pointer Networks에 대한 개념을<br />
독자가 쉽게 이해할 수 있도록 가장 중요한 RNN들을 살펴볼 것이다.<br />
그리고 이와 관련해 더 복잡한 주제를 읽어보는 것을 추천한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="1-introduction--notation">1 Introduction &amp; Notation</h1>
<p>RNNs는 sequence data에서 패턴을 찾기위해 주로 사용되는 신경막 구조이다.<br />
Sequence data로는 handwriting, genomes, text 또는 주식시장과 같은 산업에서 만들어지는 numerical time series가 될 수 있다.<br />
그러나, RNNs는 이미지가 패치들로 분해되고 sequence에 따라 적용이 되는 경우에도 적용 된다.<br />
더 높은 수준에서는 RNNs는 Language Modeling &amp; Generating Text, Speech Recognition,<br />
Generating Image Descriptions or Video Tagging 에도 적용된다.<br />
RNN은 MLP라 알려진 Feedforward Neural Networks와 정보가 네트워크를 통과하는 방법에 따라 구분된다.<br />
전방향 네트워크들은 cycle없이 네트워크를 통과시키는 반면,<br />
RNN은 cycle이 있고 정보를 자신에게 다시 전송한다.<br />
이런 방식으로 RNN은 전방향 네트워크의 기능을 확장시켜<br />
현재 입력값 $X_t$ 뿐만 아니라 이전 입력값들 $X_{0:t-1}$을 고려하게 한다.<br />
높은 수준에서 이 차이점을 시각화 한것이 Figure 1이다.</p>

<p><img src="/assets/img/Paper_Review/RNNOverview/RNNOverview_0.png" alt="RNNOverview_0" /></p>

<p>여기서 여러개의 hidden layer를 갖는 옵션은 하나의 Hidden Layer block H를 갖는 것으로 집약된다.<br />
이 block H는 여러개의 hidden layer로 확장될 수 있다.</p>

<p>\(\begin{align*}\end{align*}\)
이전 iteration에서 hidden layer로 정보를 넘기는 과정은 [24]에서 볼 수 있다.<br />
앞으로 time step $t$에 대해 hidden state와 input을</p>

\[H_{t}\in\mathbb{R}^{n\times h},\ X_t\in\mathbb{R}^{n\times d}\]

<p>로 표현하고 n은 sample의 개수<br />
d는 각 샘플 별 입력 수<br />
h는 hidden units의 수를 뜻한다.<br />
게다가 가중치 메트릭스로</p>

\[W_{xh}\in\mathbb{R}^{d\times h}\]

<p>hidden state to hidden state 메트릭스로</p>

\[W_{hh}\in\mathbb{R}^{h\times h}\]

<p>편향으로</p>

\[b_h\in\mathbb{R}^{1\times h}\]

<p>마지막으로, activation function을</p>

\[\phi\]

<p>로 표현하고 역전파를 사용해 gradient를 구하기 위해 sigmoid나 tanh를 사용한다.<br />
이 표현들을 모두 사용해 만든 식은 hidden variable을 나타내는 Equation 1과<br />
output variable을 나타내는 Equation 2가 있다.</p>

\[\begin{align}
H_t&amp;=\phi_h\left(X_tW_{xh}+H_{t-1}W_{hh}+b_h\right) \label{eq1} \\
O_t&amp;=\phi_o\left(H_tW_{ho}+b_o\right) \label{eq2}
\end{align}\]

<p>$H_t$가 재귀적으로 $H_{t-1}$을 포함하는 이 과정은 RNN의 모든 time step에서 발생하고<br />
모든 hidden state들을 trace 한다. ($H_{t-1}$과 그 이전 $H_{t-1}$까지 모두)</p>

<p>\(\begin{align*}\end{align*}\)
만약 RNN을 표기했던 방법으로 전방향 신경망을 표기하면<br />
이전 식들과 차이점을 분명하게 알 수 있다.
식3에서 hidden variable을 식4에서는 output variable을 보여준다.</p>

\[\begin{align}
H=\phi_h\left(XW_{xh}+b_h\right) \label{eq3} \\
O=\phi_o\left(HW_{ho}+b_o\right) \label{eq4}
\end{align}\]

<p>\(\begin{align*}\end{align*}\)
만약 당신이 Feedforward Neural Networks를 학습시키는 기술인 역전파를 잘 알고 있다면<br />
RNN에서 오차를 어떻게 역전파 시킬지에 대한 의문이 생길 것이다.<br />
여기, 이 기술을 Backpropagation Through Time(BPTT)라고 부른다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="2-backpropagation-through-timebptt--truncated-bptt">2 Backpropagation Through Time(BPTT) &amp;<br /> Truncated BPTT</h1>
<p>BPTT는 RNN에 적용된 역전파 알고리즘이다.<br />
이론상 BPTT는 우리가 역전파를 적용 가능하도록 RNN을 펼쳐 전통적인 Feedforward Neural Network와 같은 구조로 만든다.<br />
그러기 위해서, 우리는 이전에 말했던 표기법을 사용한다.</p>

<p>\(\begin{align*}\end{align*}\)
입력값 $X_t$를 네트워크에서 forward pass하는 경우<br />
hidden state $H_t$와 output state $O_t$를 한 step에 모두 계산한다.<br />
그리고 나서 우리는 output $O_t$와 $Y_t$의 차이를 Loss function $\mathcal{L}\left(O,Y\right)$로 아래 식5와 같이 정의할 수 있다.<br />
기본적으로 지금까지 모든 loss term $\ell_t$을 더하여 계산한다.<br />
이 loss term $\ell_t$은 특정 문제에 따라 다르게 정의될 수 있다.<br />
(e.g. Mean Squared Error, Hinge Loss, Cross Entropy Loss, etc.)</p>

\[\begin{align}
\mathcal{L}\left(O,Y\right)=\sum\limits^T_{t=1}\ell_t\left(O_t,Y_t\right) \label{eq5}
\end{align}\]

<p>우리는 세개의 가중치 메트릭스 $W_{xh}, W_{hh} and W_{ho}$를 사용하기 때문에<br />
각 가중치 메트릭스별로 partial derivative를 계산해야 한다.
평범한 역전파에도 사용되는 연쇄법칙(Chain rule)에 의해 식6로 $W_{ho}$를 구할 수 있다.</p>

\[\begin{align}
\dfrac{\partial\ \mathcal{L}}{\partial\ W_{ho}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot\dfrac{\partial\ \phi_o}{\partial\ W_{ho}}=\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot\ H_t
\label{eq6}
\end{align}\]

<p>$W_{hh}$에 대한 partial derivative는 아래 식7을 통해 계산한다.</p>

\[\begin{align}
\dfrac{\partial\ \mathcal{L}}{\partial\ W_{hh}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot\dfrac{\partial\ \phi_o}{\partial\ H_t}\cdot\dfrac{\partial H_t}{\partial\ \phi_h}\cdot\dfrac{\partial\ \phi_h}{\partial\ W_{hh}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot W_{ho}\cdot\dfrac{\partial H_t}{\partial\ \phi_h}\cdot\dfrac{\partial\ \phi_h}{\partial\ W_{hh}}
\end{align}\]

<p>$W_{xh}$에 대한 partial derivative는 아래 식8을 통해 계산한다.</p>

\[\begin{align}
\dfrac{\partial\ \mathcal{L}}{\partial\ W_{xh}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot\dfrac{\partial\ \phi_o}{\partial\ H_t}\cdot\dfrac{\partial H_t}{\partial\ \phi_h}\cdot\dfrac{\partial\ \phi_h}{\partial\ W_{xh}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot W_{ho}\cdot\dfrac{\partial H_t}{\partial\ \phi_h}\cdot\dfrac{\partial\ \phi_h}{\partial\ W_{xh}}
\end{align}\]

<p>각 $H_t$가 이전 time step에 의존하기 때문에<br />
식8의 마지막 부분을 아래 식9와 식10으로 대체할 수 있다.</p>

\[\begin{align}
\dfrac{\partial\ \mathcal{L}}{\partial\ W_{hh}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot W_{ho}\sum\limits^t_{k=1}\dfrac{\partial\ H_t}{\partial\ H_k}\cdot\dfrac{\partial\ H_k}{\partial\ W_{hh}} \\
\dfrac{\partial\ \mathcal{L}}{\partial\ W_{xh}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot W_{ho}\sum\limits^t_{k=1}\dfrac{\partial\ H_t}{\partial\ H_k}\cdot\dfrac{\partial\ H_k}{\partial\ W_{xh}}
\end{align}\]

<p>개조된 부분은 아래와 같이 식11과 식12로 쓸 수 있다.</p>

\[\begin{align}
\dfrac{\partial\ \mathcal{L}}{\partial\ W_{hh}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot W_{ho}\sum\limits^t_{k=1}\left(W_{hh}^T\right)^{t-k}\cdot H_k\\
\dfrac{\partial\ \mathcal{L}}{\partial\ W_{xh}}=
\sum\limits^T_{t=1}\dfrac{\partial\ \ell_t}{\partial\ O_t}\cdot\dfrac{\partial\ O_t}{\partial\ \phi_o}\cdot W_{ho}\sum\limits^t_{k=1}\left(W_{xh}^T\right)^{t-k}\cdot X_k\\
\end{align}\]

<p>여기서 각 time step의 loss term인 $\ell_t$를 통해 매우 커질 수 있는 loss function $\mathcal{L}$을 구하기 위해<br />
$W^k_{hh}$를 저장해야한다.<br />
매우 큰 이 수를 위해 사용하는 이 방법은 매우 불안정하다.<br />
왜냐하면 만약 고유값이 1보다 작으면 gradient는 vanish 될거고<br />
만약 고유값이 1보다 크다면 gradient는 diverge할 것이기 때문이다.<br />
이 문제를 풀 수 있는 방법중 하나는 계산 가능한 수준에서 sum을 자르는 것이다.<br />
이걸 Truncated BPTT라고 하는데 이것은 기본적으로<br />
역전파로 돌아갈 수 있는 만큼 gradient의 time step을 제한하여 구현한다.<br />
여기서 Upper bound를 RNN의 window가 고려할 과거의 time step 수를 의미한다고 생각할 수 있을 것이다.<br />
BPTT는 기본적으로 RNN을 펼쳐 각 time step별로 새로운 layer를 만들기 때문에,<br />
이 과정을 hidden layers를 제한하는 것이라고 여길 수도 있을 것이다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="3-problems-of-rnns-vanishing--exploding-gradients">3 Problems of RNNs:<br /> Vanishing &amp; Exploding Gradients</h1>
<p>대부분의 신경망들처럼, vanishing 또는 exploding gradient들은 RNN의 주요한 문제점이다.
식9와 식10에서 본 잠재적으로 매우 긴 sequence에 걸친 matrix multiplication인 경우,<br />
gradient값이 1보다 작다면 점점 gradient가 작아져 결국 vanish될 것이고<br />
이것은 현재 time step으로부터 먼 초기 time step의 state가 주는 영향을 무시하게 된다.<br />
마찬가지로 gradient값들이 1보다 크다면 matrix multiplication을 할 때 exploding gradient 현상이 관찰될 것이다.</p>

<p>\(\begin{align*}\end{align*}\)
이 vanishing gradient 문제를 해결하기 위해 고안된 내용이 Long Short Term Memory units(LSTMs)가 된다.<br />
이 접근으로 Vanilla RNN을 뛰어넘는 성능이 다양한 작업에서 가능해졌다.<br />
다음 섹션에서는 LSTMs에 대해 더 깊게 알아보겠다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="4-long-short-term-memory-units-lstms">4 Long Short-Term Memory Units (LSTMs)</h1>
<p>LSTMs는 vanishing gradient 문제를 해결하기 위해 고안되었다.<br />
LSTMSs는 더 지속적인 error를 사용하기 때문에,<br />
RNNs이 긴 time step(1000번이 넘게)동안 학습을 가능하게 한다.
이것을 위해, LSTMs는 구조상 gated cell이라는 것을 사용하여<br />
전통적인 신경망 흐름 바깥에서 정보를 더 저장하도록 한다.
LSTM에서 이것이 작동하기 위해</p>
<ul>
  <li>output gate $O_t$ : cell의 입력을 읽음</li>
  <li>input gate $I_t$ : cell로 입력된 데이터를 읽음</li>
  <li>forget gate $F_t$ : cell 내용을 reset 함</li>
</ul>

<p>이 gate들의 계산을 아래 식13,14,15에 정리했다.</p>

\[\begin{align}
O_t=\sigma\left(X_tW_{xo}+H_{t-1}W_{ho}+b_o\right)\\ \notag \\
I_t=\sigma\left(X_tW_{xi}+H_{t-1}W_{hi}+b_i\right)\\ \notag \\
F_t=\sigma\left(X_tW_{xf}+H_{t-1}W_{hf}+b_f\right)
\end{align}\]

\[\begin{align*}\end{align*}\]

<p>위 식에서
\(\quad 
\begin{align*}
W_{xi},W_{xf},W_{xo}&amp;\in\mathbb{R}^{d\times h}\\
W_{hi},W_{hf},W_{ho}&amp;\in\mathbb{R}^{h\times h}\\
b_i,b_f,b_o&amp;\in\mathbb{R}^{1\times h}
\end{align*}
\quad\)
가 가중치와 편향으로 사용되었다.</p>

<p>\(\begin{align*}\end{align*}\)
게다가 sigmoid 함수를 activation 함수 $\sigma$로 사용하여 출력을 0~1로 만들어 결과적으로 0~1의 값을 갖는 벡터로 변환한다.</p>

<p>\(\begin{align*}\end{align*}\)
다음으로, 이전 gate와 비슷한 연산과정을 갖지만 활성함수로 tanh를 사용하여 결과를 -1~1로 만드는<br />
candidate memory cell $\tilde{C_t}\in\mathbb{R}^{n\times h}$이 필요하다.<br />
그리고 이 cell도 자신의 가중치와 편향 $W_{xc}\in\mathbb{R}^{d\times h},\ W_{hc}\in\mathbb{R}^{h\times h},\ b_c\in\mathbb{R}^{1\times h}$을 갖는다.<br />
아래 식16에서 증명하고 Appendix A에서 시각화 했다.</p>

\[\begin{align}
\tilde{C_t}=\tanh\left(X_tW_{xc}+H_{t-1}W_{hc}+b_c\right)
\end{align}\]

<p>\(\begin{align*}\end{align*}\)<br />
앞서 말한 gate들을 조합하기 위해 지난 메모리 내용인 $C_{t-1}\in\mathbb{R}^{n\times h}$를 사용한다.<br />
이전 메모리 내용 $C_{t-1}$은 우리가 새로운 메모리 내용 $C_t$에 얼마나 옛날 메모리 내용까지 보존시킬 것인지를 조절한다.<br />
이것은 식17에 정리하고 $\odot$은 element-wise multiplication을 뜻한다.</p>

\[\begin{align}
C_t=F_t\odot C_{t-1}+I_t\odot\tilde{C_t}
\end{align}\]

<p>마지막 단계는 hidden state $H_t\in\mathbb{R}^{n\times h}$를 프레임워크에 추가하는 것이고 아래 식18에 정리했다.</p>

\[\begin{align}
H_t=O_t\odot\tanh\left(C_t\right)
\end{align}\]

<p>tanh 함수를 통해 $H_t$의 각 원소들은 -1~1로 정의 될것이고<br />
전체 LSTM 구조는 아래와 같다.</p>

<p><img src="/assets/img/Paper_Review/RNNOverview/RNNOverview_1.png" alt="RNNOverview_1" /></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="5-deep-recurrent-neural-networks-drnns">5 Deep Recurrent Neural Networks (DRNNs)</h1>]]></content><author><name>Robin M. Schmidt</name></author><category term="[&quot;Paper Review&quot;]" /><summary type="html"><![CDATA[Abstract “Language Modeling &amp; Generating Text”, “Speech Recognition”, “Generating Image Descriptions” or “Video Tagging” 분야에서 해결책을 위한 최신기술들은 RNN을 기반으로 하고있다. 따라서 현재 또는 앞으로 제시될 해결책들에 대한 구조를 이해하고 따라잡으려면 RNN에 대한 기본 개념을 이해하는 것이 매우 중요할 것이다. 이 논문에서는 BPTT, LSTM 뿐만아니라 Attention Mechanism과 Pointer Networks에 대한 개념을 독자가 쉽게 이해할 수 있도록 가장 중요한 RNN들을 살펴볼 것이다. 그리고 이와 관련해 더 복잡한 주제를 읽어보는 것을 추천한다.]]></summary></entry><entry><title type="html">Ch7 합성곱 신경망(CNN)</title><link href="http://localhost:4000/deeplearning%20from%20scratch/2022/08/27/Ch7-%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D.html" rel="alternate" type="text/html" title="Ch7 합성곱 신경망(CNN)" /><published>2022-08-27T20:05:47+09:00</published><updated>2022-08-27T20:05:47+09:00</updated><id>http://localhost:4000/deeplearning%20from%20scratch/2022/08/27/Ch7-%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D</id><content type="html" xml:base="http://localhost:4000/deeplearning%20from%20scratch/2022/08/27/Ch7-%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D.html"><![CDATA[<h1 id="71-전체-구조">7.1 전체 구조</h1>

<p>CNN = Convolutional Layer + Pooling Layer + Fully Connected Layer</p>

<p>(ex&gt; CONV_1 ⇒ RELU ⇒ CONV_2 ⇒ RELU ⇒ POOL_3 ⇒ DROP_4 ⇒ FLATTEN_5 ⇒ FC_6 ⇒ DROP_7 ⇒ FC_8 ⇒ SOFTMAX )</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="72-합성곱-계층">7.2 합성곱 계층</h1>

<p>패딩$\mathsf{^{padding}}$ : 필터 통과 후 데이터 사이즈 조절</p>

<p>스트라이드$\mathsf{^{stride}}$ : 필터가 이동하는 보폭</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="721-완전연결-계층의-문제점">7.2.1 완전연결 계층의 문제점</h2>

<p>완전연결 계층은 입력데이터가 다차원 이더라도 Flatten작업을 통해
그것의 형상을 무시하고 1차원 데이터로 만들어서 학습한다.</p>

<p>때문에 칼라 이미지 데이터처럼 다차원 형상의 데이터인 경우
인접한 데이터끼리 연관이 있을 가능성이 큰데
이를 무시해서 정확도가 더 낮을 수 있다.</p>

<p>반면 CNN은 입력 데이터의 형상을 보존하고
한 번에 데이터 전체를 보는 것이 아니라 부분 부분 필터를 적용하며
합성곱을 하기 때문에 인접한 데이터끼리의 연관성을 파악할 수 있다.</p>

<p>또한, 이러한 점 덕분에 음성 데이터의 처리에도 강점을 보이게 된다.</p>

<p>CNN에서 입출력 데이터를 특징맵$\mathsf{^{feature\ map}}$이라고 한다.</p>

<p>입력 특징 맵$\mathsf{^{input\ feature\ map}}$ : 합성곱 계층의 입력 데이터</p>

<p>출력 특징 맵$\mathsf{^{output\ feature\ map}}$ : 합성곱 계층의 출력 데이터</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="722-합성곱-연산">7.2.2 합성곱 연산</h2>

<p>데이터와 필터의 형상을 (높이, 너비)로 표기 한다.</p>

<p>문헌에 따라 필터를 커널이라 칭하기도 한다.</p>

<p>합성곱 연산은 필터의 윈도우를 일정 간격으로 이동해가며 단일 곱셈-누산$\mathsf{^{fused\ multiply-add,\ FMA}}$를 한다.</p>

<p>필터에 매개변수가 그동안의 가중치와 같은 역할을 한다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled.jpeg" alt="Untitled" /></p>

<p>편향까지 포함한 흐름이다. 편향은 항상 (1,1)이다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled.png" alt="Untitled" /></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="723-패딩">7.2.3 패딩</h2>

<p>패딩 : 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값으로 채우는 것</p>

<p>아래는 zero padding이고 padding_size = 1</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%201.png" alt="Untitled" /></p>

<p>입력 데이터 형상 유지에 사용</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="724-스트라이드">7.2.4 스트라이드</h2>

<p>스트라이드 : 필터가 움직이는 간격</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%201.jpeg" alt="Untitled" /></p>

<p>필터 적용시 출력 크기 관계식</p>

<p>입력 크기 : (H, W)</p>

<p>필터 크기 : (FH, FW)</p>

<p>출력 크기 : (OH, OW)</p>

<p>패딩 : P</p>

<p>스트라이드 : S</p>

\[OH={H+2P-FH\over S}+1\\
OW={W+2P-FW\over S}+1\]

<p>단, 출력 크기는 모두 정수여야 함.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="725-3차원-데이터의-합성곱-연산">7.2.5 3차원 데이터의 합성곱 연산</h2>

<p>채널까지 고려한 3차원 데이터를 연산해 본다.</p>

<p>입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고, 그 결과를 더해서 하나의 출력을 얻는다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%202.jpeg" alt="Untitled" /></p>

<p>주의할점</p>

<ul>
  <li>입력 데이터의 채널 수 = 필터의 채널 수</li>
  <li>모든 채널의 필터 크기가 같아야함</li>
</ul>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="726-블록으로-생각하기">7.2.6 블록으로 생각하기</h2>

<p>데이터 형상 = (채널, 높이, 너비)</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%203.jpeg" alt="Untitled" /></p>

<p>위에서의 결과는 채널이 1개다.</p>

<p>따라서 특징 맵을 여러장 얻기 위해서는 필터를 여러장 사용하면 된다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%202.png" alt="Untitled" /></p>

<p>필터의 형상 = (필터 수 = 출력 채널 수, 채널 수 = 입력 채널 수, 높이, 너비)</p>

<p>필터를 FN개 만큼 만들어서 합성곱을 하면 출력 데이터의 형상에서 채널 수가 FN개가 된다.</p>

<p>다음은 편향을 적용한 그림 ( 편향은 브로드캐스팅으로 계산됨 )</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%203.png" alt="Untitled" /></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="727-배치-처리">7.2.7 배치 처리</h2>

<p>한번에 여러개의 데이터를 학습하기 위해 배치 처리를 지원하게 하려면</p>

<p>데이터의 차원을 하나 늘려줘야 한다. ( 3차원 ⇒ 4차원 )</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%204.jpeg" alt="Untitled" /></p>

<p>데이터 형상 = ( 데이터 수, 채널 수, 높이, 너비 )</p>

<p>정리 : 4차원 데이터가 하나 하른다 → N개에 대한 합성곱 연산이 이뤄진다 = N회 분의 처리를 한 번에 수행한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="73-풀링-계층">7.3 풀링 계층</h1>

<p>세로, 가로 방향의 공간을 줄이는 연산</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%205.jpeg" alt="Untitled" /></p>

<p>2X2 최대 풀링을 스트라이드 2로 처리 ( 보통 풀링 윈도우 크기와 스트라이드는 같은 값으로 설정 )</p>

<p>풀링의 종류는 최대 풀링 말고도 평균 풀링 같은 것이 있지만 이미지에서는 주로 최대 풀링 사용</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="731-풀링-계층의-특징">7.3.1 풀링 계층의 특징</h2>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="1-학습해야-할-매개변수가-없다">1. 학습해야 할 매개변수가 없다</h3>

<p>풀링 계층은 오히려 매개변수를 줄인다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="2-채널-수가-변하지-않는다">2. 채널 수가 변하지 않는다</h3>

<p>풀링 연산을 통해 각 채널의 높이와 너비는 작아져도</p>

<p>채녈마다 독립적으로 계산해서 채널 수는 그대로다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="3-입력의-변화에-영향을-적게-받는다--강건하다-">3. 입력의 변화에 영향을 적게 받는다 ( 강건하다 )</h3>

<p>입력 데이터가 조금 변해도 풀리의 결과는 잘 변하지 않는다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%206.jpeg" alt="Untitled" /></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="74-합성곱--풀링-계층-구현하기">7.4 합성곱 / 풀링 계층 구현하기</h1>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="741-4차원-배열">7.4.1 4차원 배열</h2>

<p>CNN에는 4차원 데이터가 흐른다.</p>

<p>ex&gt; (10, 1, 28, 28) ⇒ 높이 28, 너비 28, 채널 1개인 데이터가 10개</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="742-im2col로-데이터-전개하기">7.4.2 im2col로 데이터 전개하기</h2>

<p>합성곱 연산의 가장 간단한 구현 방법은 for 문을 겹겹이 쓰는 것이다.</p>

<p>그렇게하면 numpy의 퍼포먼스가 떨어지기 때문에 좋은 방법이 아니다.</p>

<p>대신 im2col을 사용해서 쉽게 구현 가능하다.</p>

<p>그림은 3차원을 2차원으로 변환한 것이지만</p>

<p>4차원 데이터도 2차원으로 변환시켜준다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%204.png" alt="Untitled" /></p>

<p>im2col은 필터링하기 좋게 입력 데이터를 전개한다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%205.png" alt="Untitled" /></p>

<p>여기서는 스트라이드를 크게 잡아 필터의 적용 영역이 겹치지 않도록 했지만,</p>

<p>실제 상황에서는 영역이 겹치는 경우가 대부분이다.</p>

<p>필터 적용 영역이 겹치게 되면 im2col로 전개한 후의 원소 수가 원래 블록의 원소 수보다 많아진다.</p>

<p>그래서 im2col을 사용해 구현하면 메모리를 더 많이 소비하는 단점이 있다.</p>

<p>하지만 행렬 계산에 고도로 최적화된 선형 대수 라이브러리 등을 통해 다시 계산 효율을 높일 수 있다.</p>

<p>입력 데이터도 전개했으므로 필터도 전개해서 행렬 곱을 하면 된다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%207.jpeg" alt="Untitled" /></p>

<p>CNN은 4차원 데이터가 흐르므로 다시 reshape한다.</p>

<p>ex&gt; (1,3,7,7) — im2col(5,5,stride=1,pad=0) —&gt; (9,75)</p>

<p>결과 ⇒ (입력 데이터 수 * 채널 하나에 들어가는 필터 수) X (필터 사이즈 * 입력 데이터의 채널 수)</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%206.png" alt="Untitled" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Convolution</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>
        
        <span class="c1"># 중간 데이터（backward 시 사용）
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">None</span>   
        <span class="bp">self</span><span class="p">.</span><span class="n">col</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">col_W</span> <span class="o">=</span> <span class="bp">None</span>
        
        <span class="c1"># 가중치와 편향 매개변수의 기울기
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">db</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">FN</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">FH</span><span class="p">,</span> <span class="n">FW</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">out_h</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">int</span><span class="p">((</span><span class="n">H</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">pad</span> <span class="o">-</span> <span class="n">FH</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="n">out_w</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">int</span><span class="p">((</span><span class="n">W</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">pad</span> <span class="o">-</span> <span class="n">FW</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">)</span>

        <span class="n">col</span> <span class="o">=</span> <span class="n">im2col</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">FH</span><span class="p">,</span> <span class="n">FW</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pad</span><span class="p">)</span>
        <span class="n">col_W</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">FN</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">T</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">col_W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">out_h</span><span class="p">,</span> <span class="n">out_w</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">col</span> <span class="o">=</span> <span class="n">col</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">col_W</span> <span class="o">=</span> <span class="n">col_W</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">FN</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">FH</span><span class="p">,</span> <span class="n">FW</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">dout</span> <span class="o">=</span> <span class="n">dout</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">col</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dW</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">FN</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">FH</span><span class="p">,</span> <span class="n">FW</span><span class="p">)</span>

        <span class="n">dcol</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">col_W</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">col2im</span><span class="p">(</span><span class="n">dcol</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">FH</span><span class="p">,</span> <span class="n">FW</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pad</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dx</span>
</code></pre></div></div>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="744-풀링-계층-구현하기">7.4.4 풀링 계층 구현하기</h2>

<p>합성곱과 다른점은 채널 독립적이라는 것.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch7/Untitled%208.jpeg" alt="Untitled" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Pooling</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_h</span><span class="p">,</span> <span class="n">pool_w</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pool_h</span> <span class="o">=</span> <span class="n">pool_h</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pool_w</span> <span class="o">=</span> <span class="n">pool_w</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">arg_max</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">out_h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_h</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="n">out_w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_w</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">)</span>

        <span class="n">col</span> <span class="o">=</span> <span class="n">im2col</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_h</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_w</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pad</span><span class="p">)</span>
        <span class="n">col</span> <span class="o">=</span> <span class="n">col</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_h</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">pool_w</span><span class="p">)</span>

        <span class="n">arg_max</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">out_h</span><span class="p">,</span> <span class="n">out_w</span><span class="p">,</span> <span class="n">C</span><span class="p">).</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">arg_max</span> <span class="o">=</span> <span class="n">arg_max</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dout</span> <span class="o">=</span> <span class="n">dout</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">pool_size</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_h</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_w</span>
        <span class="n">dmax</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">dout</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">))</span>
        <span class="n">dmax</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">arg_max</span><span class="p">.</span><span class="n">size</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">arg_max</span><span class="p">.</span><span class="n">flatten</span><span class="p">()]</span> <span class="o">=</span> <span class="n">dout</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">dmax</span> <span class="o">=</span> <span class="n">dmax</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dout</span><span class="p">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">pool_size</span><span class="p">,))</span> 
        
        <span class="n">dcol</span> <span class="o">=</span> <span class="n">dmax</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dmax</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dmax</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">dmax</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">col2im</span><span class="p">(</span><span class="n">dcol</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_h</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pool_w</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">pad</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">dx</span>
</code></pre></div></div>

<p>과정</p>

<ol>
  <li>입력 데이터 전개</li>
  <li>행별 최댓값 계산</li>
  <li>reshape</li>
</ol>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="75-cnn-구현">7.5 CNN 구현</h1>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="정리">정리</h2>

<ul>
  <li>데이터 준비
    <ul>
      <li>데이터 강화 ( flip, move, rotate )</li>
      <li>training data, validation data, test data
        <ul>
          <li>데이터의 분포가 고르게 나눈다.
            <ul>
              <li>분류를 하려면 3가지 데이터에 각 클래스가 차지하는 비율이 비슷해야함</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>data normalization</li>
    </ul>
  </li>
  <li>모델 정의
    <ul>
      <li>어떤 층을 조합할건지</li>
      <li>몇 층까지 쌓을건지</li>
      <li>합성곱층은 filter를 몇개로 할건지, filter size는 몇개로 할건지, padding과 stride는 어떻게 할건지, 활성화 함수는 뭘 쓸건지</li>
      <li>풀링층은 pooling size를 몇으로 할건지, padding과 stride는 몇으로 할건지</li>
      <li>Dropout은 몇%만큼 뉴런을 막을건지</li>
      <li>전결합층은 뉴런을 몇개 사용할건지</li>
      <li>Regularization은 뭘로 할건지, 얼마나 할건지</li>
    </ul>
  </li>
  <li>모델 학습
    <ul>
      <li>Optimizer는 뭘 사용할건지 learning rate는 몇으로 시작할건지</li>
      <li>batch size 는 몇으로 할지</li>
      <li>epochs는 몇으로 할건지, 조기종료 조건은 어떻게 할건지</li>
    </ul>
  </li>
</ul>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;DeepLearning from scratch&quot;]" /><summary type="html"><![CDATA[7.1 전체 구조]]></summary></entry><entry><title type="html">Ch6 학습 관련 기술들</title><link href="http://localhost:4000/deeplearning%20from%20scratch/2022/08/27/Ch6-%ED%95%99%EC%8A%B5%EA%B4%80%EB%A0%A8%EA%B8%B0%EC%88%A0%EB%93%A4.html" rel="alternate" type="text/html" title="Ch6 학습 관련 기술들" /><published>2022-08-27T19:40:27+09:00</published><updated>2022-08-27T19:40:27+09:00</updated><id>http://localhost:4000/deeplearning%20from%20scratch/2022/08/27/Ch6-%ED%95%99%EC%8A%B5%EA%B4%80%EB%A0%A8%EA%B8%B0%EC%88%A0%EB%93%A4</id><content type="html" xml:base="http://localhost:4000/deeplearning%20from%20scratch/2022/08/27/Ch6-%ED%95%99%EC%8A%B5%EA%B4%80%EB%A0%A8%EA%B8%B0%EC%88%A0%EB%93%A4.html"><![CDATA[<h1 id="61-매개변수-갱신">6.1 매개변수 갱신</h1>

<p>최적화$\mathsf{^{optimization}}$ : 손실 함수의 값을 가능한 한 낮추는 매개변수를 찾는 것</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="611-모험가-이야기">6.1.1 모험가 이야기</h2>

<p>최적화 문제는 지도없이 눈을 가리고 광활한 산에서 가장 깊고 낮은 골짜기를 찾는 것이라고 비유 할 수 있다.</p>

<p>이때 단 하나의 단서로 발을 통해 땅의 기울기만 느낄 수 있다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="612-확률적-경사-하강법--sgd-stochastic-gradient-descent">6.1.2 확률적 경사 하강법 ( SGD, Stochastic Gradient Descent)</h2>

\[\mathrm{W}\leftarrow\mathrm{W}-\eta{\partial L\over\partial\mathrm{W}}\]

<p>$\mathbf{W}$ : 갱신할 가중치 매개변수</p>

<p>${\partial L\over\partial\mathbf{W}}$: $\mathbf{W}$에 대한 손실 함수의 기울기</p>

<p>$\eta$ : 학습률</p>

<p>$\leftarrow$ : 좌변의 값을 우변의 값으로 갱신</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SGD</span><span class="p">:</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
		<span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
	
	<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
		<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
			<span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</code></pre></div></div>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="613-sgd의-단점">6.1.3 SGD의 단점</h2>

<p>특정한 지표 없이 모든 매개변수를 검사하면서 손실 함수가 가장 낮은 지점을 찾는 것보다 SGD 처럼 기울기를 통해 방향성을 찾고 움직이는 것이 더 효율적인 방법이다.</p>

<p>SGD는 단순하고 구현도 쉽지만,</p>

<p>문제에 따라 비효율적일 때가 있다.</p>

\[f(x,y)={1\over20}x^2+y^2\]

<p>위 식을 3차원(좌)과 등고선(우)으로 그려보았다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled.png" alt="Untitled" /></p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%201.png" alt="Untitled" /></p>

<p>몇개의 $f(x,y)$ 점에서 기울기를 그려보면</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%202.png" alt="Untitled" /></p>

<p>위와 같은데 $f(x,y)$ 의 실제 최소값은 $(0,0)$이지만</p>

<p>대부분의 기울기 방향이 $(0,0)$을 가리키지 않기 때문에 문제가 발생</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%203.png" alt="Untitled" /></p>

<p>lr = 0.9 &amp; iter_num = 40</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="614-모멘텀--momentum-">6.1.4 모멘텀 ( Momentum )</h2>

<p>모멘텀$\mathsf{^{momentum}}$은 ‘운동량’을 뜻하는 단어로, 물리와 관계가 있다.</p>

<p>수식은 다음과 같다.</p>

\[\mathbf{v}\leftarrow\alpha\mathbf{v}-\eta{\partial L\over\partial\mathbf{W}}\\
\mathbf{W}\leftarrow\mathbf{W}+\mathbf{v}\]

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%204.png" alt="Untitled" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Momentum</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">None</span>
        
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">momentum</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span><span class="o">*</span><span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</code></pre></div></div>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%205.png" alt="Untitled" /></p>

<p>lr = 0.1 &amp; iter_num = 30</p>

<p>모멘텀의 갱신 경로는 공이 그릇 바닥을 구르듯 움직인다.</p>

<p>x축 방향으로의 힘은 작지만 방향이 변하지 않아 한 방향으로 일정하지만
y축 방향으로의 힘은 크면서 방향이 일정하지 않아 매개변수가 위아래로 흔들리면서 안정적이지 못한 모습을 보여준다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="615-adagrad">6.1.5 AdaGrad</h2>

<p>학습률 값은 중요하다.</p>

<p>너무 크면 최적화 과정에서 발산하고</p>

<p>너무 작으면 최적화에 드는 시간과 계산 비용이 많이 든다.</p>

<p>학습률을 정하는 효과적 기술로 학습률 감소$\mathsf{^{learning\ rate\ decay}}$가 있다.</p>

<p>학습을 진행하면서 학습률을 점차 줄여가는 방법이다.</p>

<p>매개변수 전체의 학습률 값을 일괄적으로 조절하면 구현이 간단하지만</p>

<p>AdaGrad는 더 효율적으로 하기 위해</p>

<p>각각의 매개변수에 맞게 학습률을 조절한다.</p>

\[\mathbf{h}\leftarrow\mathbf{h}+{\partial L\over\partial\mathbf{W}}\odot{\partial L\over\partial\mathbf{W}}\\
\mathbf{W}\leftarrow\mathbf{W}-\eta\dfrac{1}{\sqrt{\mathbf{h}}}\dfrac{\partial L}{\partial\mathbf{W}}\]

<p>$\mathbf{h}$에는 기존 기울기 값을 제곱하여 계속 더해준다.</p>

<p>그리고 $\mathbf{W}$를 업데이트할 때 $\sqrt{\mathbf{h}}$로 나눠준다.</p>

<p>이렇게 해서 각 매개변수의 원소마다 각각 많이 움직인 원소는 학습률이 낮아지게 적용이 된다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AdaGrad</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="o">=</span> <span class="bp">None</span>
        
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">*</span><span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span><span class="o">*</span><span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="o">+</span><span class="mf">1e-7</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%206.png" alt="Untitled" /></p>

<p>lr = 1.4 &amp; iter_num = 30</p>

<p>y축 방향은 기우리각 커서 처음에 크게 움직이지만,</p>

<p>그 큰 움직임에 비례해 갱신 정도도 큰 폭으로 작아지도록 조정된다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%207.png" alt="Untitled" /></p>

<p><a href="https://onevision.tistory.com/entry/Optimizer-%EC%9D%98-%EC%A2%85%EB%A5%98%EC%99%80-%ED%8A%B9%EC%84%B1-Momentum-RMSProp-Adam">Optimizer 의 종류와 특성 (Momentum, RMSProp, Adam)</a></p>

<p><a href="https://ko.wikipedia.org/wiki/%EC%9D%B4%EB%8F%99%ED%8F%89%EA%B7%A0">이동평균 - 위키백과, 우리 모두의 백과사전</a></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="616-adam">6.1.6 Adam</h2>

<p>Adagrad는 SGD에서 개선된 방법이지만</p>

<p>이동할 수록 학습률이 낮아져 멈추게 된다.</p>

<p>이 문제를 해결하기 위해 RMSProp 이 제시되었는데</p>

<p>RMSProp은 지수이동평균( EMA, Exponential Moving Average )을 이용해 이전에 움직였던 정보보다 최근 움직인 크기에 높은 가중치를 부여해 학습률이 낮아져서 학습이 멈추는 문제를 해결했다.</p>

<p>그리고 RMSProp과 Momentum을 합쳐서 Adam을 만들었다.</p>

<p>Adam은 Momentum에서 관성계수 m과 함께 계산된 v로 매개변수를 업데이트 하고 기울기 값과 기울기의 제곱값의 EMA를 활용해 step 변화량을 조절한다.</p>

\[\mathbf{m}\leftarrow\beta_1\mathbf{m}+(1-\beta_1){\partial L\over\partial\mathbf{W}}\\
\mathbf{v}\leftarrow\beta_2\mathbf{v}+(1-\beta_2){\partial L\over\partial\mathbf{W}}\odot{\partial L\over\partial\mathbf{W}}\\
\mathbf{W}\leftarrow\mathbf{W}-\mathbf{m}{\eta\over\sqrt{\mathbf{v}+\epsilon}}\]

<p>$\beta_1, \beta_2$는 0.9, 0.999가 적절하다고 한다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%208.png" alt="Untitled" /></p>

<p>lr = 0.3 &amp; iter_num = 30</p>

<p>모멘텀과 비슷한 패턴이지만 상하 흔들림이 적은 이유는</p>

<p>학습의 갱신 강도를 적응적으로 조정해서 얻은 혜택이다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="617-어느-갱신-방법">6.1.7 어느 갱신 방법?</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%209.png" alt="Untitled" /></p>

<p>사용한 기법에 따라 갱신 경로가 다르지만 그림만 보면 이 문제에서는 AdaGrad가 가장 좋아보인다.</p>

<p>하지만 어떤 optimizer를 쓸지는 풀어야 하는 문제가 무엇이냐에 따라 다르고 하이퍼파라미터를 어떻게 설정하느냐에 따라서도 결과가 다르니 잘 골라야 한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="618-mnist-데이터셋으로-본-방법-비교">6.1.8 MNIST 데이터셋으로 본 방법 비교</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2010.png" alt="Untitled" /></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="62-가중치의-초깃값">6.2 가중치의 초깃값</h1>

<p>가중치의 초깃값은 어떻게 설정하느냐에 따라 학습의 성패가 갈려서 특히 중요하다.</p>

<p>때문에 연구를 통해 권장하는 초깃값을 사용해 학습이 이뤄지는 것을 확인.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="621-초기값을-0으로">6.2.1 초기값을 0으로</h2>

<h3 id="가중치-감소mathsfweight-decay">가중치 감소$\mathsf{^{weight\ decay}}$</h3>

<p>오버피팅을 억제해 범용 성능을 높이는 테크닉으로</p>

<p>가중치 매개변수의 값이 작아지도록 학습하는 방법이다.</p>

<p>가중치를 작게 만들고 싶으면 초깃값을 작게 시작하는게 정공법이다.</p>

<p>지금까지는 초깃값을 만들 때 정규분포에서 생성되는 값을 0.01배 한 작은 값(표준편차가 0.01인 정규분포)를 사용했다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="그렇다면-초깃값을-모두-0으로-설정하면-어떻게-되나">그렇다면 초깃값을 모두 0으로 설정하면 어떻게 되나?</h3>

<p>실제로 가중치 초깃값을 모두 0으로 설정하면 학습이 올바로 이뤄지지 않는다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="초깃값을-모두-0으로-해서는-안-되는-이유는-정확히는-가중치를-균일한-값으로-설정-해서는-안되는-이유-">초깃값을 모두 0으로 해서는 안 되는 이유는( 정확히는 가중치를 균일한 값으로 설정 해서는 안되는 이유 )?</h3>

<p>오차역전파법에서 모든 가중치의 값이 똑같이 갱신되기 때문에 문제가 발생한다.</p>

<p>예를 들어 2층 신경망에서 첫 번째와 두 번째 층의 가중치가 0이면 순전파 때는 입력층의 가중치가 0이기 때문에 두 번째 층의 뉴런에 모두 같은 값이 전달된다.</p>

<p>두번째 층의 모든 뉴런에 같은 값이 입력된다는 것은 역전파 때 두 번째 층의 가중치가 모두 똑같이 갱신된다는 것이기 때문에</p>

<p>갱신을 거쳐도 여전히 같은 값을 유지하게 되고
이는 가중치를 여러 개 갖는 의미를 사라지게 한다.</p>

<p>따라서 초깃값을 무작위로 설정해야 한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="622-은닉층의-활성화값-분포">6.2.2 은닉층의 활성화값 분포</h2>

<p>sigmoid함수를 활성함수로 사용하는 5층 신경망에 무작위로 생성한 입력 데이터를 흘리며 각 층의 활성화값 분포를 히스토그램으로 그려보겠다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2011.png" alt="Untitled" /></p>

<p>histogram을 보면 각 층의 활성화값들이 0과 1에 치우쳐 분포한다.</p>

<p>초깃값 설정은 다음과 같이 했다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">0</span>
</code></pre></div></div>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2012.png" alt="Untitled" /></p>

<p>초깃값은 표준편차가 1이고 평균은 0인 정규분포를 따르도록 (100,100) 모양으로 무작위로 골랐다. ( 입력값도 같은 정규분포를 따름 )</p>

<p>때문에 입력값과 가중치의 곱이 활성함수 sigmoid를 통과하게 되면 모든 층에서 출력값이 0과 1에 치우치게 된다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2013.png" alt="Untitled" /></p>

<p>이런 경우는 역전파 계산시 미분 값이 0에 가까운수를 계속 곱해나가 기울기 소실$\mathsf{^{gradient\ vanishing}}$ 문제를 생긴다</p>

<p>이번에는 가중치의 표준편차를 0.01로 바꿔서 다시 한다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2014.png" alt="Untitled" /></p>

<p>이전처럼 0과 1로 치우치진 않았으나 기울기 소실 문제는 일어나지 않는다.</p>

<p>하지만 앞에서 가중치를 균일하게 설정했을 때 다수의 뉴런이 거의 같은 값을 출력해서 뉴런을 여러 개 둔 의미가 없어진다는 문제를 말했었다.</p>

<p>뉴런들이 비슷한 값을 출력하면 여러 개를 사용한 의미가 없는 거고 그 의미는 표현력을 제한한다는 관점에서 문제가 된다.</p>

<p>각 층의 활성화값은 적당히 고루 분포해 층과 층 사이에 적당하게 다양한 데이터가 흐르게 해야 신경망 학습이 효율적으로 이뤄진다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="xavier-초깃값">Xavier 초깃값</h3>

<p>사비에르 그롤로트$\mathsf{^{Xavier\ Glorot}}$와 요슈아 벤지오$\mathsf{^{Yoshua\ Bengio}}$의 논문에서 권장하는 가중치 초깃값.</p>

<p>일반적인 딥러닝 프레임워크들이 표준적으로 이용하고 있다.</p>

<p>니 논문은 각 층의 활성화값들을 광범위하게 분포시키려면</p>

<p>앞 계층의 노드가 $n$개일 때 표준 편차가 $1\over\sqrt n$인 분포를 사용해야 한다는 결론을 말한다.</p>

<p>가중치 설정 코드</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node_num</span><span class="p">,</span> <span class="n">node_num</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">node_num</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2015.png" alt="Untitled" /></p>

<p>지난 두차례 결과보다 확실히 넓게 분포된 것을 확인 했다.</p>

<p>하지만 1층의 결과는 종모양으로 제대로 분포되어있는데</p>

<p>층을 통과할 수록 모양이 일그러지고 있다.</p>

<p>이는 sigmoid함 수가 (0,0.5)에서 대칭인 S자 곡선이기 때문인데</p>

<p>원점에서 대칭인 S곡선인 tanh를 활성화 함수로 사용하여 이를 해결 한다고 한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="tanh">tanh</h3>

\[\mathsf{tanh}={e^x-e^{-x}\over e^x+e^{-x}}\]

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2016.png" alt="Untitled" /></p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2017.png" alt="Untitled" /></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="623-relu를-사용할-때의-가중치-초깃값">6.2.3 ReLu를 사용할 때의 가중치 초깃값</h2>

<p>Xavier 초깃값이 학습에 효율적인 이유는 활성함수로 sigmoid와 tanh를 사용했기 때문이다.</p>

<p>Xavier는 선형 함수인 활성함수를 상대로 효율이 좋은데 sigmoid와 tanh는 중앙 부근에서 선형이라 볼 수 있기 때문이다.</p>

<p>반면에 ReLu를 사용하려면 ReLu에 특화된 초깃값을 이용해야 한다.</p>

<p>카이밍 히$\mathsf{^{Kaiming\ He}}$의 이름을 따 ‘He 초깃값’ 이라 한다.</p>

<p>He 초깃값은 앞 계층의 노드가 n개일 때,</p>

<p>표준편차가 $\sqrt {2\over n}$ 인 정규분포를 사용한다.</p>

<p>Xavier 초깃값은 표준편차가 $1\over\sqrt n$ 이었는데
ReLu는 음의 영역에서 결과값이 0이라</p>

<p>뉴런의 출력값을 더 넓게 분포시키기 위해 2배의 계수를 적용했다고 해석할 수 있다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2018.png" alt="Untitled" /></p>

<p>ReLu 표준편차 0.01</p>

<p>층들의 활성함수값들이 아주 작아서 신경망에 데이터가 조금 흐르게 되는데</p>

<p>가중치 작게해서 오버피팅 피하려다</p>

<p>역전파에서 기울기가 작아서 학습이 안됨</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2019.png" alt="Untitled" /></p>

<p>ReLu Xavier</p>

<p>처음엔 괜찮은데 층이 깊어지면서 치우침이 커져 ‘기울기 소실’ 문제 발생</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2020.png" alt="Untitled" /></p>

<p>ReLu He</p>

<p>모든 층에서 균일하게 분포, 층이 깊어져도 분포가 균일하여 학습이 적절히 된다고 기대할 수 있다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="624-mnist-데이터셋으로-본-가중치-초깃값-비교">6.2.4 MNIST 데이터셋으로 본 가중치 초깃값 비교</h2>

<p>5층신경망, 활성함수 : ReLu</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2021.png" alt="Untitled" /></p>

<ol>
  <li>
    <p>std = 0.01</p>

    <p>위에서 봤듯이 가중치가 너무 작아 기울기 소실이 발생해 학습이 되고있지 않음</p>
  </li>
  <li>
    <p>He</p>

    <p>ReLu에 잘 맞는 초깃값을 제공하는 방법으로 제일 학습 속도가 빠름</p>
  </li>
  <li>
    <p>Xavier</p>

    <p>학습이 잘 진행되지만 He 초깃값보다 학습 진도가 느림</p>
  </li>
</ol>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="63-배치-정규화">6.3 배치 정규화</h1>

<p>앞 절에서는 각 층의 가중치의 초깃값을 조절하여 활성화값의 분포를 관찰했는데</p>

<p>이번에는 각 층이 활성화값을 적당히 퍼뜨리도록 ‘강제’해보겠다.</p>

<p>배치 정규화$\mathsf{^{Batch\ Normalization}}$가 그런 아이디어에서 출발했다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="631-배치-정구화-알고리즘">6.3.1 배치 정구화 알고리즘</h2>

<p>배치 정규화의 장점</p>

<ol>
  <li>학습을 빨리 진행할 수 있따. (학습 속도 개선)</li>
  <li>초깃값에 크게 의존하지 않는다 ( 골치 아픈 초깃값 선택 장애 해결)</li>
  <li>오버피팅을 억제한다(드롭아웃 등의 필요성 감소)</li>
</ol>

<p>배치 정규화는 학습 시 미니배치를 단위로 정규화한다.</p>

<p>평균 0, 분산 1</p>

\[\mu_B\leftarrow{1\over m}\sum\limits^m_{i=1}x_i\\
\sigma^2_B\leftarrow{1\over m}\sum\limits^m_{i=1}(x_i-\mu_B)^2\\
\hat x_i\leftarrow{x_i-\mu_B\over\sqrt{\sigma^2_B+\epsilon}}\]

<p>위 식을 통해 배치 정규화를 하는데</p>

<p>이 단계를 활성화 함수의 앞이나 뒤에 삽입함으로써 데이터 분포를 고르게 만들 수 있다.</p>

<p>그리고 배치 정규화 계층마다 아래 수식을 통해 정규화된 데이터에 고유한 확대와 이동 변환을 수행한다.</p>

\[y_i\leftarrow\gamma\hat x_i+\beta\]

<p>gamma가 확대를, beta가 이동을 처리한다.</p>

<p>처음에는 $\gamma = 1,\ \beta=0$ 부터 시작하고,</p>

<p>학습하면서 적합한 값으로 조정해간다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="backpropagation-in-batch-normalization-layer">Backpropagation in Batch Normalization Layer</h2>

<p><a href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html">Understanding the backward pass through Batch Normalization Layer</a></p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2022.png" alt="Untitled" /></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="632-배치-정규화의-효과">6.3.2 배치 정규화의 효과</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2023.png" alt="Untitled" /></p>

<p>거의 모든 경우에서 배치 정규화를 사용할 때의 학습 진도가 빠르다.</p>

<p>실제로 배치 정규화를 이용하지 않는 경우엔 초깃값이 잘 분포되어 있지 않으면 학습이 전혀 진행되지 않는다.</p>

<p>따라서 배치 정규화를 사용하면 학습이 빠르고,</p>

<p>가중치 초깃값에 크게 의존하지 않아도 된다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="64-바른-학습을-위해">6.4 바른 학습을 위해</h1>

<p>오버피팅이 문제가 되는 일이 많다.</p>

<p>복잡하고 표현력이 높은 모델을 만들 수는 있지만,</p>

<p>그만큼 오버피팅을 억제하는 기술도 중요하다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="641-오버피팅">6.4.1 오버피팅</h2>

<p>오버피팅이 일어나는 경우</p>

<ol>
  <li>매개변수가 많고 표현력이 높은 모델</li>
  <li>훈련 데이터가 적음</li>
</ol>

<p>이번에는 일부러 오버피팅을 일으키기 위해</p>

<ol>
  <li>7층 네트워크를 사용</li>
  <li>60000개 MNIST 데이터셋의 훈련 데이터 중 300개만 사용</li>
</ol>

<p>해보겠다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2024.png" alt="Untitled" /></p>

<p>train의 정확도는 거의 100%가 되었고</p>

<p>test의 정확도는 train과 큰 차이를 보이고 있다.</p>

<p>이런 정확도를 보이는 모델를 overfitting 되었다고 한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="642-가중치-감소">6.4.2 가중치 감소</h2>

<p>오버피팅 억제용으로 오래된 해결방법으로는 가중치 감소$\mathsf{^{weight\ decay}}$가 있다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="가중치-감소-weight-decay">가중치 감소 weight decay</h3>

<p>오버피팅은 가중치 매개변수의 값이 커서 발생하는 경우가 많기 때문에 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 패널티를 부과하여 오버피팅을 피하는 방법</p>

<p>신경망 학습의 목적은 손실 함수의 값을 줄이는 것이므로</p>

<p>손실함수에 가중치의 L2 norm을 더해서 학습을 진행하면</p>

<p>신경망은 가중치가 커지는 것을 억제할 것이다.</p>

<p>그리고 앞에 lambda를 곱해 가중치에 대한 패널티를 조절한다.</p>

\[L\leftarrow L+{1\over2}\lambda\mathbf{W}^2\]

<p>식을 위와 같이 구성하여 역전파 과정에서는 $\lambda\mathbf{W}$를 더하면 된다.</p>

<p>$\lambda$를 0.1로 적용해 가중치 감소를 사용해 학습을 하면 아래와 같은 결과가 나온다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2025.png" alt="Untitled" /></p>

<p>train과 test의 정확도 차이가 줄었고 train의 정확도가 100%에 도달하지 못한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="643-드롭아웃">6.4.3 드롭아웃</h2>

<p>가중치 감소는 구현이 간단하고 어느 정도 지나친 학습을 억제하지만</p>

<p>신경망 모델이 복잡해지면 가중치 감소만으로는 대응하기 어려워진다.</p>

<p>이럴 때는 흔히 드롭아웃$\mathsf{^{Dropout}}$을 사용한다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2026.png" alt="Untitled" /></p>

<p>드롭 아웃의 역전파는 ReLu와 같다.</p>

<p>순전파 때 신호를 통과시키는 뉴런은 역전파 때도 신호를 그대로 통과시키고,</p>

<p>순전파 때 통과시키지 않은 뉴런은 역전파 때도 신호를 차단한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Dropout</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout_ratio</span> <span class="o">=</span> <span class="n">dropout_ratio</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">train_flg</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">train_flg</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout_ratio</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">mask</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout_ratio</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">dout</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">mask</span>
</code></pre></div></div>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2027.png" alt="Untitled" /></p>

<p>드롭아웃을 사용하니 데이터에 대한 정확도 차이가 줄고
훈련 데이터에 대한 정확도가 100%에 도달하지 않는다.</p>

<p>이처럼 드롭아웃을 이용하면 표현력을 높이면서도 오버피팅을 억제할 수 있다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h3 id="ensemble-learning">Ensemble Learning</h3>

<p>앙상블 학습은 개별적으로 학습시킨 여러 모델의 출력을 평균 내어 추론하는 방식이다.</p>

<p>신경망의 맥락에서 얘기하면, 가령 같은 구조의 네트워크를 5개 준비하여 따로따로 학습시키고, 시험 때는 그 5개의 출력을 평균 내어 답하는 것이다.</p>

<p>앙상블 학습을 수행하면 신경망의 정확도가 몇% 정도 개선된다는 것이 실험적으로 알려져 있다.</p>

<p>앙상블 학습은 드롭아웃과 밀접하다.</p>

<p>드롭아웃이 학습 때 뉴런을 무작위로 삭제하는 행위를</p>

<p>앙상블 학습은 다른 모델을 학습시키는 것으로 해석할 수 있기 때문</p>

<p>추론 때는 뉴런의 출력에 삭제한 비율을 곱함으로써 앙상블 학습에서 여러 모델의 평균을 내는 것과 같은 효과를 얻는 것이다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="65-적절한-하이퍼파라미터-값-찾기">6.5 적절한 하이퍼파라미터 값 찾기</h1>

<p>신경망에는 하이퍼파라미터가 많이 등장한다.</p>

<p>하이퍼파라미터를 적절히 설정하지 않으면 모델의 성능이 크게 떨어지기도 하기 때문에 조심해야한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="651-검증-데이터">6.5.1 검증 데이터</h2>

<p>데이터를 학습 데이터와 테스트 데이터로만 나눴는데 지금부터는 하이퍼파라미터를 검증하기 위해 검증 데이터를 추가한다.</p>

<p>테스트 데이터로 하이퍼파라미터 검증하면 하이퍼파라미터가 테스트 데이터에 오버피팅 되기 때문이다.</p>

<p>데이터셋에 따라서는 훈련, 검증, 시험 데이터를 미리 분리해둔 것도 있는데</p>

<p>지금은 훈련 데이터중 20%를 검증 데이터로 분리하겠다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="652-하이퍼파라미터-최적화">6.5.2 하이퍼파라미터 최적화</h2>

<p>하이퍼파라미터 최적화할 때의 핵심은 하이퍼파라미터의 최적 값이 존재하는 범위를 조금씩 줄여간다는 것이다. 
범위를 조금씩 줄이려면 우선 대략적인 범위를 설정하고 그 범위에서 무작위로 하이퍼파라미터 값을 골라낸(샘플링) 후, 그 값으로 정확도를 평가.</p>

<p>정확도를 잘 살피면서 이 작업을 여러 번 반복하며 하이퍼파라미터의 최적 값의 범위를 좁혀가는 것이다.</p>

<p>신경망의 하이퍼파라미터 최적화에서는 그리드 서치같은 규칙적인 탐색보다는 무작위로 샘플링해 탐색하는 편이 좋은 결과를 낸다고 알려져 있다.</p>

<p>최종 정확도에 미치는 영향력이 하이퍼파라미터마다 다르기 때문</p>

<p>하이퍼파라미터의 범위는 대략적으로 로그 스케일로 지정하는것이 효과적이다.</p>

<p>딥러닝 학습에는 오랜 시간이 걸려서 나쁠 듯한 값은 일찍 포기하는 것이 좋다.</p>

<p>따라서 에폭을 작게 하여, 1회 평가에 걸리는 시간을 단축하는 것이 효과적이다.</p>

<ul>
  <li>0 단계
    <ul>
      <li>하이퍼파라미터 값의 범위 설정 ( 로그스케일 )</li>
    </ul>
  </li>
  <li>1 단계
    <ul>
      <li>설정된 범위에서 하이퍼파라미터의 값을 무작위로 추룰</li>
    </ul>
  </li>
  <li>2 단계
    <ul>
      <li>1 단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가한다. (에폭 작게)</li>
    </ul>
  </li>
  <li>3 단계
    <ul>
      <li>1, 2단계를 특정 횟수 ( 100회 등 ) 반복하며, 그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힌다.</li>
    </ul>
  </li>
</ul>

<p>이 방법은 과학이라기 보다 수행자의 지혜와 직관에 의존한다.</p>

<p>베이즈 정리를 중심으로 한 베이즈 최적화는 수학 이론을 구사하여 더 엄밀하고 효율적으로 최적화를 수행한다.</p>

<p><a href="https://proceedings.neurips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf">https://proceedings.neurips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf</a></p>

<p>\(\begin{align*}\end{align*}\)</p>
<h2 id="653-하이퍼파라미터-최적화-구현하기">6.5.3 하이퍼파라미터 최적화 구현하기</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2028.png" alt="Untitled" /></p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch6/Untitled%2029.png" alt="Untitled" /></p>

<p>학습이 잘 진행될 때의 학습률은 0.001~0.01,</p>

<p>가주이 감소 계수는 $10^{-8}$~$10^{-6}$ 정도이다.</p>

<p>이처럼 잘될 것 같은 값의 범위를 관찰하고 범위를 좁혀서 같은 작업을 반복한다.</p>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;DeepLearning from scratch&quot;]" /><summary type="html"><![CDATA[6.1 매개변수 갱신]]></summary></entry><entry><title type="html">Hnadling long term dependencies</title><link href="http://localhost:4000/rnn%20note/2022/08/23/Handling-long-term-dependencies.html" rel="alternate" type="text/html" title="Hnadling long term dependencies" /><published>2022-08-23T21:27:13+09:00</published><updated>2022-08-23T21:27:13+09:00</updated><id>http://localhost:4000/rnn%20note/2022/08/23/Handling-long-term-dependencies</id><content type="html" xml:base="http://localhost:4000/rnn%20note/2022/08/23/Handling-long-term-dependencies.html"><![CDATA[<h1 id="vanilla-rnn의-한계">Vanilla RNN의 한계</h1>
<p>아래 Vanilla RNN 의 구조를 보자.<br />
각 timestep별로 결과에 얼마나 영향을 주는지 색으로 표현했을때<br />
색이 짙을 수록 역전파 과정에서 피드백 크기가 점점 작아져서 결과에 영향을 거의 안주게 된다.<br />
만약 앞에 입력이 결과에 영향을 줘야하는 경우라면 현재 timestep으로부터 먼 앞에 입력을 기억하고 있지 않다면<br />
<strong>Long Term Dependencies problem</strong> 이 발생하게 된다.</p>

<p align="center"><img style="width: 70%" src="../../../../assets/img/RNN%20Note/Handling_long_term_dependencies/handling_0.png" /></p>
<h5><center>출처: Wiki Docs</center></h5>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="자주-사용되는-activation-functions">자주 사용되는 activation functions</h1>
<p>RNN에서 가장 많이 사용되는 activation functions들은 아래와 같다.</p>

<p align="center"><img src="../../../../assets/img/RNN%20Note/Handling_long_term_dependencies/handling_1.png" /></p>
<h5><center>출처: CS 230</center></h5>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="vanishingexploding-gradient">Vanishing/exploding gradient</h1>
<p>RNN을 사용하다보면 Vanishing/exploding gradient 문제를 자주 만나게 된다.<br />
층의 수에 따라 기하급수적으로 커지거나 작아지는 기울기 때문에<br />
long term dependencies를 포착하기 어려워서<br />
Vanishing/exploding gradient 문제가 발생하게 된다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="gradient-clipping">Gradient clipping</h1>
<p>이 테크닉은 backpropagation 수행중에 가끔 마주치는<br />
exploding gradient 문제에 대응하기 위해 사용된다.</p>

<p align="center"><img style="width: 60%" src="../../../../assets/img/RNN%20Note/Handling_long_term_dependencies/handling_2.png" /></p>
<h5><center>출처: CS 230</center></h5>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="grulstm">GRU/LSTM</h1>
<p>Gated Recurrent Unit(GRU)와 GRU의 일반화 버전인 Long Short-Term Memory units(LSTM)은 전통적인 RNNs를 통해 마주하는 vanishing gradient problem을 다루기 위해 사용한다.</p>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="types-of-gates">Types of Gates</h1>
<p><strong>vanishing gradient</strong> 문제를 해결하기 위해 RNNs에서는 목적이 잘 정의된 특정 gate들을 사용한다.<br />
그것들을 보통 $\Gamma$ 로 표기한다.</p>

\[\Gamma=\sigma\left(Wx^{&lt;t&gt;}+Ua^{&lt;t-1&gt;}+b\right)\]

<p>$W,U,b$ 는 gate의 고유한 계수들이고 $\sigma$ 는 sigmoid function이다.<br />
아래는 주요 내용이다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Type of gate</th>
      <th style="text-align: center">Role</th>
      <th style="text-align: center">Used in</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Update gate $\Gamma_u$</td>
      <td style="text-align: center">과거가 현재에 얼마나 영향을 주는가</td>
      <td style="text-align: center">GRU,LSTM</td>
    </tr>
    <tr>
      <td style="text-align: center">Relevance gate $\Gamma_r$</td>
      <td style="text-align: center">이전 정보를 버릴지</td>
      <td style="text-align: center">GRU,LSTM</td>
    </tr>
    <tr>
      <td style="text-align: center">Forget gate $\Gamma_f$</td>
      <td style="text-align: center">cell을 지울지 말지</td>
      <td style="text-align: center">LSTM</td>
    </tr>
    <tr>
      <td style="text-align: center">Output gate $\Gamma_o$</td>
      <td style="text-align: center">cell의 어느정도를 내보낼지</td>
      <td style="text-align: center">LSTM</td>
    </tr>
  </tbody>
</table>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="lstm">LSTM</h1>
<p>LSTM의 cell의 구조는 아래와 같다.</p>
<p align="center"><img src="../../../../assets/img/RNN%20Note/Handling_long_term_dependencies/handling_3.png" /></p>
<h5><center>출처 : Explain LSTM &amp; GRU</center></h5>

\[\begin{align*}\\
\text{Input gate}\quad\rightarrow\quad i_t&amp;=\sigma\left(W_{ii}x_t+b_{ii}+W_{hi}h_{t-1}+b_{hi}\right)\\ \\
\text{Forget gate}\quad\rightarrow\quad f_t&amp;=\sigma\left(W_{if}x_t+b_{if}+W_{hf}h_{t-1}+b_{hf} \right)\\ \\
\text{Cell(Gate) gate}\quad\rightarrow\quad g_t&amp;=\tanh\left(W_{ig}x_t+b_{ig}+W_{hg}h_{t-1}+b_{hg} \right)\\ \\
\text{Output gate}\quad\rightarrow\quad o_t&amp;=\sigma\left(W_{io}x_t+b_{io}+W_{ho}h_{t-1}+b_{ho} \right)\\ \\
\text{Cell state}\quad\rightarrow\quad c_t&amp;=f_t\odot c_{t-1}+i_t\odot g_t\\ \\
\text{Hidden state}\quad\rightarrow\quad h_t&amp;=o_t\odot\tanh\left(c_t\right)
\end{align*}\]

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="gru">GRU</h1>
<p>GRU의 cell의 구조는 아래와 같다.</p>

<p align="center"><img src="../../../../assets/img/RNN%20Note/Handling_long_term_dependencies/handling_4.png" /></p>
<h5><center>출처 : Explain LSTM &amp; GRU</center></h5>

\[\begin{align*}\\ 
\text{Reset gate}\quad\rightarrow\quad r_t&amp;=\sigma\left(W_{ir}x_t+b_{ir}+W_{hr}h_{t-1}+b_{hr}\right) \\ \\
\text{Update gate}\quad\rightarrow\quad z_t&amp;=\sigma\left(W_{iz}x_t+b_{iz}+W_{hz}h_{t-1}+b_{hz}\right) \\ \\
\text{New gate}\quad\rightarrow\quad n_t&amp;=\tanh\left(W_{in}x_t+b_{in}+r_t*\left(W_{hn}h_{t-1}+b_{hn}\right)\right) \\ \\
\text{Hidden state}\quad\rightarrow\quad h_t&amp;=\left(1-z_t\right)*n_t+z_t*h_{t-1}
\end{align*}\]

<p>\(\begin{align*}\end{align*}\)
\(\begin{align*}\end{align*}\)</p>
<h3 id="참고자료">참고자료:</h3>
<h4 id="cs-230---deep-learning"><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks">CS 230 - Deep Learning</a>,</h4>
<h4 id="wiki-docs"><a href="https://wikidocs.net/22888">Wiki Docs</a>,</h4>
<h4 id="mit-6s191-recurrent-neural-networks-and-transformers"><a href="https://www.youtube.com/watch?v=QvkQ1B3FBqA">MIT 6.S191: Recurrent Neural Networks and Transformers</a>,</h4>
<h4 id="explain-lstm--gru"><a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21">Explain LSTM &amp; GRU</a>,</h4>
<h4 id="pytorch-lstm"><a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html?highlight=lstm#torch.nn.LSTM">pytorch LSTM</a>,</h4>
<h4 id="pytorch-gru"><a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html?highlight=gru#torch.nn.GRU">pytorch GRU</a></h4>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;RNN Note&quot;]" /><summary type="html"><![CDATA[Vanilla RNN의 한계 아래 Vanilla RNN 의 구조를 보자. 각 timestep별로 결과에 얼마나 영향을 주는지 색으로 표현했을때 색이 짙을 수록 역전파 과정에서 피드백 크기가 점점 작아져서 결과에 영향을 거의 안주게 된다. 만약 앞에 입력이 결과에 영향을 줘야하는 경우라면 현재 timestep으로부터 먼 앞에 입력을 기억하고 있지 않다면 Long Term Dependencies problem 이 발생하게 된다.]]></summary></entry><entry><title type="html">RNN Overview</title><link href="http://localhost:4000/rnn%20note/2022/08/22/RNN.html" rel="alternate" type="text/html" title="RNN Overview" /><published>2022-08-22T15:16:15+09:00</published><updated>2022-08-22T15:16:15+09:00</updated><id>http://localhost:4000/rnn%20note/2022/08/22/RNN</id><content type="html" xml:base="http://localhost:4000/rnn%20note/2022/08/22/RNN.html"><![CDATA[<h1 id="architecture-of-a-traditional-rnn">Architecture of a traditional RNN</h1>
<p><strong>RNN</strong>에서는 은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드를 <strong>cell</strong>(메모리 셀, RNN 셀) 이라고 한다.</p>

<p>regular feed-forward network에서 hidden layer라고 부르던 뉴런은</p>

<p>RNN에서 <strong>hidden state</strong>라고 부른다.<br />
\(\begin{align*}\end{align*}\)</p>

<p><strong>hidden state</strong>에서는 이전 <strong>time step</strong>의 <strong>hidden state</strong> 로부터 얻은 출력값을 현재 <strong>time step</strong>의 <strong>hidden state</strong> 에서 입력값으로 사용한다.</p>

<p><img src="/assets/img/RNN%20Note/RNN_overview/RNN_0.png" alt="RNN_0" /></p>
<h5><center>출처: CS 230</center></h5>

<p><strong>timestep</strong> $t$ 에서 activation \(a^{&lt;t&gt;}\)와 output \(y^{&lt;t&gt;}\)는 아래와 같이 표현한다.</p>

\[\begin{align*}
a^{&lt;t&gt;}&amp;=g_1(W_{aa}a^{&lt;t-1&gt;}+W_{ax}x^{&lt;t&gt;}+b_a)\\
y^{&lt;t&gt;}&amp;=g_2(W_{ya}a^{&lt;t&gt;}+b_y)
\end{align*}\]

<p>$W_{ax},\ W_{aa},\ W_{ya},\ b_a,\ b_y$는 모든 <strong>timestep</strong>에서 변하지 않는 계수이고<br />
$g_1,\ g_2$는 활성함수들이다.<br />
\(\begin{align*}\end{align*}\)</p>

<p><img src="/assets/img/RNN%20Note/RNN_overview/RNN_1.png" alt="RNN_1" /></p>
<h5><center>출처: CS 230</center></h5>

<h2 id="rnn의-장점과-단점">RNN의 장점과 단점</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Advantages</th>
      <th style="text-align: left">Drawbacks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">$\cdot$ 어떤 길이의 입력도 처리 가능</td>
      <td style="text-align: left">$\cdot$ 계산이 느림</td>
    </tr>
    <tr>
      <td style="text-align: left">$\cdot$ 입력 크기에 따라 모델 크기가 커지지 않음</td>
      <td style="text-align: left">$\cdot$ 오래된 <strong>timestep</strong>에 접근하기 어려움</td>
    </tr>
    <tr>
      <td style="text-align: left">$\cdot$ 시간에 대한 결과를 고려한 계산</td>
      <td style="text-align: left">$\cdot$ 현재 state에서는 미래의 입력을 고려하지 못함</td>
    </tr>
    <tr>
      <td style="text-align: left">$\cdot$ 전체 시간동안 가중치가 공유됨</td>
      <td style="text-align: left"> </td>
    </tr>
  </tbody>
</table>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="applications-of-rnns">Applications of RNNs</h1>
<p>RNN model들은 NLP와 speech recognition 처럼 sequential data를 다루기 위해 사용된다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Type of RNN</th>
      <th style="text-align: center">Illustration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">One-to-one                              </td>
      <td style="text-align: center"><img src="/assets/img/RNN%20Note/RNN_overview/RNN_2.png" alt="RNN_2" /></td>
    </tr>
    <tr>
      <td style="text-align: center">One-to-many</td>
      <td style="text-align: center"><img src="/assets/img/RNN%20Note/RNN_overview/RNN_3.png" alt="RNN_3" /></td>
    </tr>
    <tr>
      <td style="text-align: center">Many-to-one</td>
      <td style="text-align: center"><img src="/assets/img/RNN%20Note/RNN_overview/RNN_4.png" alt="RNN_4" /></td>
    </tr>
    <tr>
      <td style="text-align: center">Many-to-many</td>
      <td style="text-align: center"><img src="/assets/img/RNN%20Note/RNN_overview/RNN_5.png" alt="RNN_5" /></td>
    </tr>
    <tr>
      <td style="text-align: center">Many-to-many</td>
      <td style="text-align: center"><img src="/assets/img/RNN%20Note/RNN_overview/RNN_6.png" alt="RNN_6" /></td>
    </tr>
  </tbody>
</table>

<h5><center>출처: CS 230</center></h5>

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="loss-function">Loss function</h1>
<p>RNN의 경우 모든 timestep에서 loss function $\mathcal{L}$ 은 각 timestep 별 loss를 더하는 것으로 정의한다.</p>

\[\mathcal{L}(\hat y,y)=\sum\limits^{T_y}_{t=1}\mathcal{L}\left(\hat y^{&lt;t&gt;},y^{&lt;t&gt;}\right)\]

<p>\(\begin{align*}\end{align*}\)</p>
<h1 id="backpropagation-through-time">Backpropagation through time</h1>
<p>역전파는 각 시간별로 진행된다.<br />
timestep $T$ 인 경우, ${\partial\mathcal{L}^{(T)}\over\partial W}$ 는 아래와 같이 표현된다.</p>

\[{\partial\mathcal{L}^{(T)}\over\partial W}=\left.\sum\limits^{T}_{t=1}{\partial\mathcal{L}^{(T)}\over\partial W}\right|_{(t)}\]

<h2 id="how-to-do-bptt-">How to do <strong>BPTT</strong> ?</h2>
<p><img src="/assets/img/RNN%20Note/RNN_overview/RNN_7.png" alt="RNN_7" />
예를 들어 위와 같이 $S_t=W\cdot S_{t-1}$ 이고 $\mathcal{L}=W\cdot S_t$ 인 경우<br />
${\partial\ \mathcal{L}\over\partial\ W}$ 는 아래와 같이 구한다.</p>

\[\begin{align*}
{\partial\ \mathcal{L}\over\partial\ W}&amp;=
{\partial\ \mathcal{L}\over\partial\ S_t}\cdot{\partial\ S_t\over\partial\ W}\\ \\
{\partial\ S_t\over\partial\ W}&amp;=
\underbrace{\partial^+\ S_t\over\partial\ W}_{\mathsf{explicit}}+
\underbrace{\dfrac{\partial\ S_t}{\partial\ S_{t-1}}\cdot{\partial\ S_{t-1}\over\partial\ W}}_{\mathsf{implicit}}\\ \\
&amp;=
{\partial^+\ S_t\over\partial\ W}+{\partial\ S_t\over\partial\ S_{t-1}}\left[\underbrace{\partial^+\ S_{t-1}\over\partial\ W}_{\mathsf{explicit}}+\underbrace{\dfrac{\partial\ S_{t-1}}{\partial\ S_{t-2}}\cdot{\partial\ S_{t-2}\over\partial\ W}}_{\mathsf{implicit}}\right]=\dots\\ \\
&amp;=
{\partial\ S_t\over\partial\ S_t}\ {\partial^+\ S_t\over\partial\ W}+
{\partial\ S_t\over\partial\ S_{t-1}}\ {\partial^+\ S_{t-1}\over\partial\ W}+
{\partial\ S_t\over\partial\ S_{t-1}}\ {\partial\ S_{t-1}\over\partial\ S_{t-2}}\ {\partial^+\ S_{t-2}\over\partial\ W}+\dots+{\partial\ S_t\over\partial\ S_{t-1}}\dots{\partial^+\ S_1\over\partial\ W}\\ \\
&amp;=\sum\limits^t_{k=1}{\partial\ S_t\over\partial\ S_k}\ {\partial^+\ S_k\over\partial\ W}\\ \\
\therefore\dfrac{\partial\ \mathcal{L^{&lt;t&gt;}}}{\partial\ W}&amp;=
\dfrac{\partial\ \mathcal{L^{&lt;t&gt;}}}{\partial\ S_t}\ 
\sum\limits^t_{k=1}{\partial\ S_t\over\partial\ S_k}\ {\partial^+\ S_k\over\partial\ W}
\end{align*}\]

<p>위와 같은 개념으로 BPTT 진행하여 RNN이 학습을 한다.</p>

<p>\(\begin{align*}\end{align*}\)
\(\begin{align*}\end{align*}\)</p>

<h3 id="참고자료">참고자료:</h3>
<h4 id="michigan-online"><a href="https://www.youtube.com/watch?v=dUzLD91Sj-o&amp;list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r&amp;index=12">Michigan Online</a>,</h4>
<h4 id="cs-230"><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks">CS 230</a>,</h4>
<h4 id="wiki-docs"><a href="https://wikidocs.net/22886">Wiki Docs</a></h4>
<h4 id="nptel-noc-iitm"><a href="https://www.youtube.com/watch?v=Xeb6OjnVn8g">NPTEL-NOC IITM</a></h4>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;RNN Note&quot;]" /><summary type="html"><![CDATA[Architecture of a traditional RNN RNN에서는 은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드를 cell(메모리 셀, RNN 셀) 이라고 한다.]]></summary></entry><entry><title type="html">Vector Differential</title><link href="http://localhost:4000/math%20note/2022/08/21/%EB%B2%A1%ED%84%B0%EC%9D%98-%EB%AF%B8%EB%B6%84.html" rel="alternate" type="text/html" title="Vector Differential" /><published>2022-08-21T15:08:13+09:00</published><updated>2022-08-21T15:08:13+09:00</updated><id>http://localhost:4000/math%20note/2022/08/21/%EB%B2%A1%ED%84%B0%EC%9D%98%20%EB%AF%B8%EB%B6%84</id><content type="html" xml:base="http://localhost:4000/math%20note/2022/08/21/%EB%B2%A1%ED%84%B0%EC%9D%98-%EB%AF%B8%EB%B6%84.html"><![CDATA[<h1 id="vector-differential">Vector Differential</h1>

<p><img src="/assets/img/Math_Note/VectorDifferential/vector_diff_0.jpg" alt="vector_diff_0" /></p>

<p><img src="/assets/img/Math_Note/VectorDifferential/vector_diff_1.jpg" alt="vector_diff_1" /></p>

<p><img src="/assets/img/Math_Note/VectorDifferential/vector_diff_2.jpg" alt="vector_diff_2" /></p>

<p><img src="/assets/img/Math_Note/VectorDifferential/vector_diff_3.jpg" alt="vector_diff_3" /></p>

<h1 id="watch-this-very-helpful-video-from-michigan-online"><a href="https://www.youtube.com/watch?v=dB-u77Y5a6A">Watch this Very Helpful Video from Michigan Online</a></h1>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;Math Note&quot;]" /><summary type="html"><![CDATA[Vector Differential]]></summary></entry><entry><title type="html">Ch5 오차역전파법</title><link href="http://localhost:4000/deeplearning%20from%20scratch/2022/08/21/Ch5-BackPropagation.html" rel="alternate" type="text/html" title="Ch5 오차역전파법" /><published>2022-08-21T14:55:27+09:00</published><updated>2022-08-21T14:55:27+09:00</updated><id>http://localhost:4000/deeplearning%20from%20scratch/2022/08/21/Ch5-BackPropagation</id><content type="html" xml:base="http://localhost:4000/deeplearning%20from%20scratch/2022/08/21/Ch5-BackPropagation.html"><![CDATA[<h1 id="ch5-오차역전파법">Ch5 오차역전파법</h1>

<p>수치 미분을 통해 기울기를 구하는 방법은</p>

<p>구현이 쉽다는 장접이 있지만 시간이 오래 걸린다는 단점도 있다.</p>

<p>오차역전파법을 사용해 효율적으로 계산하겠다.</p>

<h1 id="51-계산-그래프">5.1 계산 그래프</h1>

<h2 id="511-계산-그래프로-풀다">5.1.1 계산 그래프로 풀다.</h2>

<p>흐름</p>

<ol>
  <li>계산 그래프를 구성한다.</li>
  <li>그래프에서 계산을 왼쪾에서 오른쪽으로 진행한다. (순전파$\mathsf{^{forward\ propagation}}$)</li>
</ol>

<h2 id="512-국소적-계산">5.1.2 국소적 계산</h2>

<p>계산 그래프의 특징은 ‘국소적 계산’을 전파하여 최종 결과를 얻는다.</p>

<p>따라서 전체 계산이 복잡하더라도 각 단계에서 하는 일은 해당 노드의 ‘국소적 계산’이기 때문에</p>

<p>계산이 간단하지만 그것들이 모여 복잡한 계산을 해낸다.</p>

<h2 id="513-왜-계산-그래프">5.1.3 왜 계산 그래프?</h2>

<ol>
  <li>국소적 계산을 통해 문제를 단순화할 수 있다.</li>
  <li>중간 계산 결과를 모두 보관할 수 있다.</li>
  <li>역전파( back propagation )를 통해 ‘미분’을 효율적으로 계산할 수 있다.</li>
</ol>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_0.jpg" alt="ch5_0" /></p>

<h1 id="52-연쇄법칙">5.2 연쇄법칙</h1>

<h2 id="521-계산-그래프의-역전파">5.2.1 계산 그래프의 역전파</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_1.jpg" alt="ch5_1" /></p>

<p>신호 E에 노드의 국소적 미분 $\partial y\over \partial x$를 곱한 후 다음 노드로 전달한다.</p>

<h2 id="522-연쇄법칙이란">5.2.2 연쇄법칙이란</h2>

<p>합성 함수 : 여러 함수로 구성된 함수.</p>

\[z=(x+y)^2\\
\downarrow\\
z=t^2\\
t=x+y\]

<p>합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.</p>

\[{\partial z\over \partial x}={\partial z\over \partial t}{\partial t\over \partial x}\]

\[{\partial z\over \partial x}={\partial z\over \cancel{\partial t}}{\cancel{\partial t}\over \partial x}\]

<ol>
  <li>국소적 미분(편미분) 계산</li>
</ol>

\[{\partial z\over \partial t}=2t\]

\[{\partial t\over \partial x}=1\]

<ol>
  <li>연쇄법칙$\mathsf{^{chain rule}}$ 적용</li>
</ol>

\[{\partial z\over \partial x}={\partial z\over \partial t}{\partial t\over \partial x}=
2t\cdot1=2(x+y)\]

<h2 id="523-연쇄법칙과-계산-그래프">5.2.3 연쇄법칙과 계산 그래프</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_2.jpg" alt="ch5_2" /></p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_3.jpg" alt="ch5_3" /></p>

<p>역전파 방향으로 국소적 미분을 곱하면 입력에 대한 출력의 미분값을 계산한것과 같다.</p>

<h1 id="53-역전파">5.3 역전파</h1>

<h2 id="531-덧셈-노드의-역전파">5.3.1 덧셈 노드의 역전파</h2>

\[z=x+y\]

\[{\partial z\over\partial x}=1\]

\[{\partial z\over\partial y}=1\]

<p>x, y : 덧셈노드의 입력</p>

<p>z : 덧셈노드의 출력</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_4.jpeg" alt="ch5_4" /></p>

<p>앞에 임의의 계산이 있더라도 연쇄법칙에 의해
덧셈노드의 상류에서 흘러온 미분 값은 $\partial L\over\partial z$가 된다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_5.jpeg" alt="ch5_5" /></p>

<h2 id="532-곱셈-노드의-역전파">5.3.2 곱셈 노드의 역전파</h2>

\[z=xy\]

\[{\partial z\over\partial x}=y\]

\[{\partial z\over\partial y}=x\]

<p>곱셈노드의 각 입력에 의한 미분 값은 자신이 아닌 다른 입력값</p>

<p>따라서 입력 x에 의한 출력의 미분 값은 ${\partial L\over\partial z}\cdot y$</p>

<p>입력y에 의한 출력의 미분 값은 ${\partial L\over\partial z}\cdot x$</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_6.jpeg" alt="ch5_6" /></p>

<h2 id="533-사과-쇼핑의-예">5.3.3 사과 쇼핑의 예</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_7.jpeg" alt="ch5_7" /></p>

<h1 id="54-단순한-계층-구현하기">5.4 단순한 계층 구현하기</h1>

<p>계산 그래프를 파이썬으로 구현해보는 절</p>

<h2 id="541-곱셈-계층">5.4.1 곱셈 계층</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MulLayer</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span>
        
        <span class="k">return</span> <span class="n">out</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span>
        <span class="n">dy</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span>
        
        <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span>
</code></pre></div></div>

<h2 id="542-덧셈-계층">5.4.2 덧셈 계층</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AddLayer</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">+</span><span class="n">y</span>
        <span class="k">return</span> <span class="n">out</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span><span class="o">*</span><span class="mi">1</span>
        <span class="n">dy</span> <span class="o">=</span> <span class="n">dout</span><span class="o">*</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span>
</code></pre></div></div>

<h1 id="55-활성화-함수-계층-구현하기">5.5 활성화 함수 계층 구현하기</h1>

<p>활성함수 ReLu와 sigmoid 계층 구현</p>

<h2 id="551-relu-계층">5.5.1 ReLu 계층</h2>

\[y=\begin{cases}
x &amp; (x&gt;0)\\
0 &amp; (x\le0)
\end{cases}\]

\[{\partial y\over\partial x}=\begin{cases}
1 &amp; (x&gt;0)\\
0 &amp; (x\le0)
\end{cases}\]

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_8.jpeg" alt="ch5_8" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ReLu</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">None</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">out</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dout</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span>
        <span class="k">return</span> <span class="n">dx</span>
</code></pre></div></div>

<p>ReLu 계층은 전기 회로의 ‘스위치’에 비유할 수 있다.</p>

<p>순전파 때 전류가 흐르고 있으면$(x&gt;0)$ 스위치를 ON으로 하고, 흐르지 않으면$(x\le0)$ OFF로 한다.</p>

<p>역전파 때는 스위치가 ON이라면 전류가 그대로 흐르고, OFF면 더 이상 흐르지 않는다.</p>

<h2 id="552-sigmoid-계층">5.5.2 Sigmoid 계층</h2>

\[y={1\over1+e^{-x}}\]

<p>아래 sigmoid 함수의 계산 그래프를 보면</p>

<p>덧셈 노드, 곱셈 노드, ‘exp’ 노드와 ‘ / ’ 노드가 사용된다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_9.jpeg" alt="ch5_9" /></p>

<h3 id="sigmoid-함수의-역전파-과정">sigmoid 함수의 역전파 과정</h3>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_10.png" alt="ch5_10" /></p>

<h3 id="step-1-결과---partial-loverpartial-ycdot-y2">step 1 결과 : $-{\partial L\over\partial y}\cdot y^2$</h3>

<p>ex&gt;</p>

\[\begin{align*}
y&amp;={1\over x}\\
{\partial y\over\partial x}&amp;=-{1\over\ x^2}\\
&amp;=-y^2
\end{align*}\]

<h3 id="step-2-결과---partial-loverpartial-ycdot-y2">step 2 결과 : $-{\partial L\over\partial y}\cdot y^2$</h3>

<p>덧셈 노드는 상류의 값을 여과 없이 하류로 내보낸다.</p>

<p>ex&gt;</p>

\[\begin{align*}
y&amp;=x+1\\
{\partial y\over\partial x}&amp;=1
\end{align*}\]

<h3 id="step-3-결과---partial-loverpartial-ycdot-y2cdot-e-x">step 3 결과 : $-{\partial L\over\partial y}\cdot y^2\cdot e^{-x}$</h3>

<p>exp 노드의 편미분값은 원래 exp와 같다.</p>

<p>ex&gt;</p>

\[\begin{align*}
y&amp;=e^x\\
{\partial y\over\partial x}&amp;=e^x
\end{align*}\]

<p>주의할 점은 step 3에서 exp노드의 입력값이 $e^{-x}$이므로</p>

<p>역전파 계산시 exp노드를 통과하면 국소적 미분값으로 $e^{-x}$를 곱해야 한다.</p>

<h3 id="step-4-결과--partial-loverpartial-ycdot-y2cdot-e-x">step 4 결과 : ${\partial L\over\partial y}\cdot y^2\cdot e^{-x}$</h3>

<p>곱셈 노드의 역전파 계산은 순전파 때의 값을 서로 바꿔 곱한다.</p>

<p>ex&gt;</p>

\[\begin{align*}
y&amp;=x\cdot c\\
{\partial y\over\partial x}&amp;=c
\end{align*}\]

<h3 id="최종-결과">최종 결과</h3>

\[\begin{align*}
{\partial L\over\partial y}\cdot y^2\cdot e^{-x}=&amp;{\partial L\over\partial y}{1\over (1+e^{-x})^2}e^{-x}\\
=&amp;{\partial L\over\partial y}{1\over1+e^{-x}}{e^{-x}\over1+e^{-x}}\\
=&amp;{\partial L\over\partial y}\cdot y(1-y)\\
&amp;(\because y={1\over1+e^{-x}})
\end{align*}\]

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_11.jpeg" alt="ch5_11" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">out</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">out</span>
        <span class="k">return</span> <span class="n">out</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dout</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dout</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dx</span>
</code></pre></div></div>

<h1 id="56-affinesoftmax-계층-구현">5.6 Affine/Softmax 계층 구현</h1>

<h2 id="벡터의-미분"><a href="http://kchanghun.github.io/math%20note/2022/08/21/벡터의-미분.html">*벡터의 미분</a></h2>

<h2 id="561-affine-계층">5.6.1 Affine 계층</h2>

<p>신경망의 순전파 때 수행하는 행렬의 곱은 기하학에서는 어파인 변환$\mathsf{^{affine\ transformation}}$이라고 한다.</p>

<p>Affine 계층의 계산 그래프 : 변수가 행렬임에 주의, 각 변수의 형상을 변수명 위에 표기했다.</p>

<p>이제부터는 노드 사이에 벡터와 행렬도 흐른다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_12.png" alt="ch5_12" /></p>

<ol>
  <li></li>
</ol>

\[\begin{align*}{\partial L\over\partial X}=&amp;{\partial L\over\partial Y}{\partial Y\over\partial X}\\{\partial Y\over\partial X}=&amp;{\partial (X\cdot W+B)\over\partial X}={\partial (X^TW)\over\partial X}=W^T\\&amp;(\ \because Y=X\cdot W+B,\ X\mathsf{\ is\ vector,\ }W\ \mathsf{is\ matrix\ },\ B\ \mathsf{is\ constant\ })\\\therefore {\partial L\over\partial X}=&amp;{\partial L\over\partial Y}\cdot W^T\end{align*}\]

<ol>
  <li></li>
</ol>

\[\begin{align*}{\partial L\over\partial X}=&amp;
{\partial L\over\partial Y}
{\partial (X\cdot W)\over\partial X}={\partial (X^TW)\over\partial X}=
W^T\\&amp;
(\ \because Y=X\cdot W+B,\ X\mathsf{\ is\ vector,\ }W\ \mathsf{is\ matrix\ },\ B\ \mathsf{is\ constant\ })\\\therefore {\partial L\over\partial X}=&amp;{\partial L\over\partial Y}\cdot W^T\end{align*}\]

<p>dot노드의 역전파는 곱셈 노드의 역전파와 개념이 같은데 계산되는 변수가 다차원 배열이기 때문에 서로 도트곱을 할 수 있도록 차원을 맞춰줘야 한다.</p>

\[\begin{align*}
&amp;{\partial L\over\partial X}=&amp;
{\partial L\over\partial Y}\cdot &amp;W^T\\
&amp;(2,)&amp;(3,)\cdot&amp;(3,2)\\&amp;\\
&amp;{\partial L\over\partial W}=&amp;
X^T\cdot&amp;{\partial L\over\partial Y}\\
&amp;(2,3)&amp;(2,1)\cdot&amp;(,3)
\end{align*}\]

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_13.jpg" alt="ch5_13" /></p>

<h2 id="562-배치용-affine-계층">5.6.2 배치용 Affine 계층</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_14.jpg" alt="ch5_14" /></p>

<p>순전파의 편향 덧셈은 각각의 데이터( 1 번째 데이터, 2번째 데이터, …)에 더해진다.</p>

<p>그래서 역전파 때는 각 데이터의 역전파 값이 편향의 원소에 모여야 한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Affine</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">original_x_shape</span> <span class="o">=</span> <span class="bp">None</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">db</span> <span class="o">=</span> <span class="bp">None</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">original_x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span>
        <span class="k">return</span> <span class="n">out</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dout</span><span class="p">):</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="n">dx</span> <span class="o">=</span> <span class="n">dx</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">original_x_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dx</span>
</code></pre></div></div>

<h2 id="563-softmax-with-loss-layer">5.6.3 Softmax-with-Loss Layer</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_15.jpg" alt="ch5_15" /></p>

<p>손글씨 숫자 인식에서의 softmax 계층의 출력의 모습인데</p>

<p>0~9까지 10개의 숫자를 분류하기 때문에 입력도 10개고 출력도 10개다</p>

<p>softmax계층을 cross entropy error계층과 함께 구현한다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_16.png" alt="ch5_16" /></p>

<h2 id="forward-propagation">Forward Propagation</h2>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_17.png" alt="ch5_17" /></p>

<h3 id="1-softmax">1. Softmax</h3>

\[\begin{align*}
y_k&amp;={e^{a_k}\over\sum\limits_i^ne^{a_i}}\\
S&amp;=e^{a_1}+e^{a_2}+e^{a_3}\\
y_1&amp;={e^{a_1}\over S}\quad y_2={e^{a_2}\over S}\quad y_3={e^{a_3}\over S}
\end{align*}\]

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_18.png" alt="ch5_18" /></p>

<h3 id="2-cross-entropy-error">2. Cross Entropy Error</h3>

\[L=-\sum\limits_kt_k\log(y_k)\]

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_19.png" alt="ch5_19" /></p>

<h2 id="back-propagation">Back Propagation</h2>

<h3 id="1-cross-entropy-error">1. Cross Entropy Error</h3>

\[y=\log x\\
{\partial y\over\partial x}={1\over x}\]

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_20.png" alt="ch5_20" /></p>

<h3 id="2-softmax">2. Softmax</h3>

<p>step 1</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_21.png" alt="ch5_21" /></p>

<p>step 2</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_22.png" alt="ch5_22" /></p>

<p>step 3</p>

<p>순전파 때 여러 갈래로 나뉘어 흘렸다면 역전파 때는 그 반대로 흘러온 여러 값을 더한다.</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_23.png" alt="ch5_23" /></p>

<p>step 4</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_24.png" alt="ch5_24" /></p>

<p>step 5</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_25.png" alt="ch5_25" /></p>

<p>step 6</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_26.png" alt="ch5_26" /></p>

<p>결과</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch5/ch5_27.png" alt="ch5_27" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SoftmaxWithLoss</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">t</span> <span class="o">=</span> <span class="bp">None</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">t</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_error</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dout</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>
        <span class="k">return</span> <span class="n">dx</span>
</code></pre></div></div>

<h1 id="57-오차역전파법-구현하기">5.7 오차역전파법 구현하기</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TwoLayerNet</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span>\
                    <span class="n">weight_init_std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> \
                            <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_init_std</span> <span class="o">*</span> \
                            <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine1'</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">Affine</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Relu1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ReLu</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine2'</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">Affine</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">])</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">lastLayer</span> <span class="o">=</span> <span class="n">SoftmaxWithLoss</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
    
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastLayer</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">t</span><span class="p">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">accuracy</span>
    
    <span class="k">def</span> <span class="nf">numerical_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">loss_W</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W1'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b1'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'W2'</span><span class="p">])</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">loss_W</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'b2'</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">grads</span>
    
    <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="n">dout</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">dout</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastLayer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>
        
        <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">layers</span><span class="p">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
            <span class="n">dout</span> <span class="o">=</span> <span class="n">layer</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>
            
        <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine1'</span><span class="p">].</span><span class="n">dW</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine1'</span><span class="p">].</span><span class="n">db</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine2'</span><span class="p">].</span><span class="n">dW</span>
        <span class="n">grads</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="s">'Affine2'</span><span class="p">].</span><span class="n">db</span>
        
        <span class="k">return</span> <span class="n">grads</span>
</code></pre></div></div>

<h2 id="573-오차역전파법으로-구한-기울기-검증하기">5.7.3 오차역전파법으로 구한 기울기 검증하기</h2>

<p>기울기를 구하는 방법으로</p>

<ol>
  <li>수치 미분</li>
  <li>해석적 미준</li>
</ol>

<p>두가지를 알았다.</p>

<p>계산 그래프를 통해 해석적 미분을 계산하면서</p>

<p>느린 수치 미분보다 효율적 결과를 얻을 수 있다.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>수치 미분</th>
      <th>해석적 미분</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>속도</td>
      <td>느림</td>
      <td>빠름</td>
    </tr>
    <tr>
      <td>구현 난이도</td>
      <td>쉬움</td>
      <td>어려움</td>
    </tr>
  </tbody>
</table>

<p>때문에 수치 미분 값과 오차역전파법의 결과를 비교하여 제대로 구현 되었는지 확인한다. → 기울기 확인$\mathsf{^{gradient\ check}}$</p>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;DeepLearning from scratch&quot;]" /><summary type="html"><![CDATA[Ch5 오차역전파법]]></summary></entry><entry><title type="html">Ch4 신경망 학습</title><link href="http://localhost:4000/deeplearning%20from%20scratch/2022/08/21/Ch4-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%95%99%EC%8A%B5.html" rel="alternate" type="text/html" title="Ch4 신경망 학습" /><published>2022-08-21T01:10:34+09:00</published><updated>2022-08-21T01:10:34+09:00</updated><id>http://localhost:4000/deeplearning%20from%20scratch/2022/08/21/Ch4-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%95%99%EC%8A%B5</id><content type="html" xml:base="http://localhost:4000/deeplearning%20from%20scratch/2022/08/21/Ch4-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%95%99%EC%8A%B5.html"><![CDATA[<h1 id="ch4-신경망-학습">Ch4 신경망 학습</h1>

<h3 id="학습">학습</h3>

<p>훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻함</p>

<p>신경망이 학습하는 것을 나타내는 지표로 손실 함수를 사용한다.</p>

<p>이 때 손실 함수의 값이 작을수록 학습이 잘 된것이라 한다.</p>

<h1 id="41-데이터에서-학습한다">4.1 데이터에서 학습한다.</h1>

<p>신경망의 특징은 데이터를 보고 가중치 매개변수의 값을 데이터를 보고 자동으로 결정한다는 것이다.</p>

<h2 id="411-데이터-주도-학습">4.1.1 데이터 주도 학습</h2>

<p>학습 파이프라인의 전환</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch4/ch4_0.png" alt="ch4_0" /></p>

<ol>
  <li>첫 번째 방법에서는 알고리즘을 만들어내기 매우 어려움</li>
  <li>두 번째 기계학습을 통해 효율을 높였지만 여전히 사람이 특징을 적절하게 뽑아야함</li>
  <li>
    <p>세 번째 방법에서는 신경망이 직접 데이터를 통해 학습한다.</p>

    <p>따라서 숫자5를 인식하는 문제든 강아지를 인식하는 문제든 사람의 얼굴을 인식하는 문제든</p>

    <p>사람의 개입없이 문제를 해결할 수 있음 ( end-to-end machine learning )</p>
  </li>
</ol>

<h2 id="412-훈련-데이터와-시험-데이터">4.1.2 훈련 데이터와 시험 데이터</h2>

<p>학습에 사용하는 데이터는 훈련 데이터(training data)와 시험 데이터(test data)로 나뉜다.</p>

<p>좋은 모델은 새로운 데이터로도 문제를 올바르게 풀어내는 능력이 중요하기 때문에</p>

<p>모델을 평가할 때는 학습에 사용된 훈련 데이터말고 훈련에 사용되지 않은 시험 데이터로 평가한다.</p>

<p>갖고 있는 모든 데이터를 학습 데이터로 사용하면 데이터셋에 Overfitting이 일어나도 확인 할 수 없다.</p>

<h1 id="42-손실-함수--loss-function-">4.2 손실 함수 ( Loss Function )</h1>

<p>신경망의 성능을 나타내는 지표를 손실 함수라 하고</p>

<p>오차제곱합( Sum of Squares for error, SSE )과 교차 엔트로피 오차( Cross Entropy Error, CEE )가 일반적</p>

<h2 id="421-오차제곱합--sse-">4.2.1 오차제곱합 ( SSE )</h2>

\[\begin{align*}E=&amp;\frac{1}{2}\sum\limits_k(y_k-t_k)^2\\
y_k\ &amp;:\ \mathsf{output}\\
t_k\ &amp;:\ \mathsf{answer\ \ label}\\
k\ &amp;:\ \mathsf{dimension\ \ of\ \ data}\end{align*}\]

<h3 id="one-hot-encoding">*one-hot encoding</h3>

<p>한 원소만 1로하고 그 외는 0으로 나타내는 표기법</p>

<h2 id="422-교차-엔트로피-오차--cee-">4.2.2 교차 엔트로피 오차 ( CEE )</h2>

\[\begin{align*}E=&amp;-\sum\limits_kt_k\log(y_k)\\
y_k\ &amp;:\ \mathsf{output}\\
t_k\ &amp;:\ \mathsf{answer\ \ label\ (one-hot\ \ encoding)}\\
k\ &amp;:\ \mathsf{dimension\ \ of\ \ data}\end{align*}\]

<h2 id="423-미니배치-학습">4.2.3 미니배치 학습</h2>

<p>기계학습은 훈련 데이터를 사용해 학습한다.</p>

<p>훈련 데이터에 대한 손실 함수의 값을 구하고, 그 값을 최대한 줄여주는 매개변수를 찾아낸다.</p>

<p>따라서 모든 훈련 데이터를 대상으로 오차를 구하고 그 합을 지표로 삼는다.</p>

<p>( 훈련 데이터가 1000개면 1000번의 손실 함수를 실행해야함 )</p>

<p>빅데이터 수준에서는 데이터의 수가 수백만개 수천만개가 넘기 때문에</p>

<p>데이터 전체에 대한 손실 함수를 계산하기 어렵기 때문에 일부(미니배치$\mathsf{^{mini-batch}}$)만 골라서 학습.</p>

<p>이렇게 학습하는 방법을 <strong>미니배치 학습</strong> 이라고 한다.</p>

<h2 id="424-배치용-교차-엔트로피-오차">4.2.4 (배치용) 교차 엔트로피 오차</h2>

<h3 id="평균-손실-함수">평균 손실 함수</h3>

\[\begin{align*}
E&amp;=-\frac{1}{N}\sum\limits_n\sum\limits_kt_{nk}\log y_{nk}\\
\mathsf{N}\ &amp;:\ \mathsf{the\ \ number\ \ of\ \ Data}\\
t_{nk}\ &amp;:\mathsf{\ k_{th}\ answer\ of \ \ n_{th}\ \ data}\\
y_{nk}\ &amp;:\mathsf{\ k_{th}\ output\ of\ \ n_{th}\ \ data}
\end{align*}\]

<p>N으로 나눠서 정규화하면</p>

<ol>
  <li>범위를 0~1로 조절</li>
  <li>훈련 데이터의 개수와 관계없이 통일된 지표를 얻음</li>
</ol>

<h2 id="425-왜-손실-함수를-설정하는가">4.2.5 왜 손실 함수를 설정하는가?</h2>

<p>신경망 학습의 궁극적인 목표는 높은 정확도 이지만</p>

<p>학습 방법으로 정확도를 지표로 사용하지 않고 손실 함수를 사용한다.</p>

<p>학습을 통해 신경망에 사용되는 매개변수를 조절할 때 미분 값을 사용하는데</p>

<p>정확도를 지표로 삼는 함수의 미분 값은 대부분의 장소에서 0이되어 매개변수 조절이 불가능하기 때문이다.</p>

<p>또한, 정확도는 매개변수의 변화에 의해 값이 이산적으로 변하는데</p>

<p>그것은 매개변수의 변화가 주는 변화를 정확도가 무시하고 있다는 것입니다.</p>

<p>반면 손실 함수는 미분 값이 0인 경우 학습이 종료되고 매개변수의 변화에 의해 손실 함숫값은 연속적으로 변해</p>

<p>매개변수 변화에 민감하게 반응해 최적의 매개변수를 구하기 좋다.</p>

<p>같은 맥락에서 step 함수를 활성 함수로 쓰지 않는다.</p>

<p>step 함수는 대부분의 장소에서 미분 값이 0이고 그 함숫값이 이산적이어서</p>

<p>모델의 학습 지표를 손실 함수로 삼는다 하더라도 학습이 되지 않기 때문이다.</p>

<h1 id="43-수치-미분">4.3 수치 미분</h1>

<p>경사법에서는 기울기(미분 값)을 기준으로 매개변수를 조절한다.</p>

<h2 id="431-미분">4.3.1 미분</h2>

<p>미분이란 한순간의 변화량</p>

<h3 id="전방-차분--forward-difference-">전방 차분 ( Forward Difference )</h3>

\[\begin{align*}
\dfrac{d\ f(x)}{dx}=\lim_{h\rightarrow 0}\dfrac{f(x+h)-f(x)}{h}
\end{align*}\]

<p>위와 같은 미분 방법을 전방 차분이라 하고 수치 미분법 중 하나이다.</p>

<p>또 다른 수치 미분법으로는</p>

<h3 id="중앙-차분-central-difference-">중앙 차분( Central Difference )</h3>

\[\begin{align*}
\dfrac{d\ f(x)}{dx}=\lim_{h\rightarrow 0}\dfrac{f(x+h)-f(x-h)}{2h}
\end{align*}\]

<h3 id="후방-차분--backward-difference-">후방 차분 ( Backward Difference )</h3>

\[\begin{align*}
\dfrac{d\ f(x)}{dx}=\lim_{h\rightarrow 0}\dfrac{f(x)-f(x-h)}{h}
\end{align*}\]

<p>사람이 직접 수학 문제를 풀 때 사용하는  전개해서 미분하는 방법을 해석적 미분이라고 하는데</p>

\[\begin{align*}
y=x^2
\\{dy \over dx}=2x
\end{align*}\]

<p>이런 해석적 미분은 전개식을 통해 미분하는데 프로그래밍 할 때는</p>

<ol>
  <li>함수를 정의했을 경우 그 함수의 전개식을 따로 저장해둬야 한다. (ex&gt; string)</li>
</ol>

<p>그래도 미분을 위해 전개식을 string으로 저장했다 하더라도 정규 문법을 정하기 어렵다.</p>

<ol>
  <li>다변수 함수까지 처리하려면 정규 문법을 정하는 것도 쉽지않다.</li>
</ol>

<p>때문에 오차 값을 감안하고 프로그래밍 할 때는 수치 미분을 한다.</p>

<p>해석적 미분을 하면 참값이 나오지만 수치 미분을 하면 오차가 생길 수밖에 없다.</p>

<p>그래서 그 오차를 최대한 줄이기 위해서는 차분의 간격을 최대한 좁히는 것이다.</p>

<p>그렇게해서 구현을 하게 되면 아래와 같은데 먼저 잘못된 예를 보면</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">bad_numerical_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
	<span class="n">h</span> <span class="o">=</span> <span class="mf">1e-50</span>
	<span class="k">return</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">h</span>
</code></pre></div></div>

<p>차분의 간격을 줄이려고 h값을 너무 작게 설정하면</p>

<p>python이 그 값을 반올림을 해서 그 값이 무시되는(0으로 되는) 반올림 오차$\mathsf{^{rounding\ error}}$가 발생한다.</p>

<p>따라서 h값은 $10^{-4}$정도의 값으로 사용한다.</p>

<p>그리고 차분은 두 점의 기울기 값 이기고 3개의 방법 중 중앙 차분을 이용해 구현해 보면 아래와 같다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">central_numerical_diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
	<span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># 0.0001
</span>	<span class="k">return</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="432-수치-미분의-예">4.3.2 수치 미분의 예</h2>

\[y=0.01x^2+0.1x\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">function_1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
	<span class="k">return</span> <span class="mf">0.01</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">x</span>
</code></pre></div></div>

<h2 id="433-편미분">4.3.3 편미분</h2>

\[f(x_0,\ x_1)=x^2_0+x^2_1\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">function_2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
	<span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
	<span class="c1"># or return np.sum(x**2)
</span></code></pre></div></div>

\[{\partial f\over\partial x_0}=2x_0\ \ \ \ \ \ 
{\partial f\over\partial x_1}=2x_1\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># x0=3, x1=4 일 때, x0에 대한 편미분
</span><span class="k">def</span> <span class="nf">function_tmp1</span><span class="p">(</span><span class="n">x0</span><span class="p">):</span>
	<span class="k">return</span> <span class="n">x0</span><span class="o">*</span><span class="n">x0</span> <span class="o">+</span> <span class="mf">4.0</span><span class="o">**</span><span class="mf">2.0</span>

<span class="c1"># x1에 대한 편미분
</span><span class="k">def</span> <span class="nf">function_tmp2</span><span class="p">(</span><span class="n">x1</span><span class="p">):</span>
	<span class="k">return</span> <span class="mf">3.0</span><span class="o">**</span><span class="mf">2.0</span> <span class="o">+</span> <span class="n">x1</span><span class="o">*</span><span class="n">x1</span>
</code></pre></div></div>

<p>편미분 하려는 변수를 제외한 나머지 변수는 고정값을 대입하여</p>

<p>새로운 함수를 정의한다.</p>

<h1 id="44-기울기">4.4 기울기</h1>

<p>한 함수를 통해 모든 변수에 대한 편미분 결과를 벡터로 정리한 것을 기울기$\mathsf{^{gradient}}$라고 한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
	<span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span>
	<span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	
	<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">):</span>
		<span class="n">tmp_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
		
		<span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_val</span> <span class="o">+</span> <span class="n">h</span>
		<span class="n">fxh1</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

		<span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_val</span> <span class="o">-</span> <span class="n">h</span>
		<span class="n">fxh2</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

		<span class="n">grad</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fxh1</span> <span class="o">-</span> <span class="n">fxh2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>
		<span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_val</span>

	<span class="k">return</span> <span class="n">grad</span>
</code></pre></div></div>

<p>기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch4/ch4_1.png" alt="ch4_1" /></p>

<p>*잘못된 함수 구현</p>

<p>결과의 차이는 없지만 제대로 구하는 건 아니라 생각</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch4/ch4_2.png" alt="ch4_2" /></p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch4/ch4_3.png" alt="ch4_3" /></p>

<h2 id="441-경사법-gradient-method-">4.4.1 경사법( Gradient method )</h2>

<p>광대한 매개변수 공간에서 어디가 손실함수를 최솟값으로 만드는 곳인지</p>

<p>기울기를 이용여 찾는 방법</p>

<p>기울기를 지표로 최적의 매개변수를 찾으러 움직이지만</p>

<p>기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지는 보장되지 않는다.</p>

<p>함수의 기울기가 0인 지점은 최솟값, 극솟값, 안장점이 될 수 있다.</p>

<p>복잡하고 찌그러진 모양의 함수라면 평평한 곳으로 파고들면서 고원$\mathsf{^{plateau,플라토}}$라 하는 학습 정체기에 빠질 수 있다.</p>

<p>기울기의 방향이 반드시 최솟값을 가리키지는 않지만</p>

<p>그 방향으로 가야 함수의 값을 줄일 수 있다.</p>

<p>경사법에는 경사 하강법$\mathsf{^{gradient\ descent\ method}}$과 경사 상승법$\mathsf{^{gradient\ ascent\ method}}$이 있는데</p>

<p>기울기가 가리키는 방향으로 일정 거리만큼 이동하면서 함수의 값을 점차 줄여나가는 방법을 경사 하강법이라 한다.</p>

\[\begin{align*}
x_0&amp;=x_0-\eta{\partial f\over\partial x_0}\\
x_1&amp;=x_1-\eta{\partial f\over\partial x_1}\\
\eta&amp;\ :\ \mathsf{learning\ rate}
\end{align*}\]

<p>에타는 학습률을 뜻하는데 기울기 방향으로 이동할 거리를 조절하고</p>

<p>에타가 너무 크면 빠른 학습을 하지만 최솟값에 수렴하지 못할 수도 있고</p>

<p>에타가 너무 작으면 학습 속도가 너무 느려 시간 비용이 크게 들어가서</p>

<p>조절하면서 학습을 진행한다.</p>

<h3 id="경사-하강법">경사 하강법</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">init_x</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">step_num</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">init_x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_num</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">lr</span><span class="o">*</span><span class="n">grad</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<p>f : 최적화 하려는 함수</p>

<p>init_x : 학습을 시작할 위치</p>

<p>step_num : 경사법 반복 수</p>

<p><img src="/assets/img/DeepLearning_from_scratch/Ch4/ch4_4.png" alt="ch4_4" /></p>

<p>학습률 같은 매개변수를 하이퍼파라미터$\mathsf{^{hyper\ parameter,\ 초매개변수}}$라고 한다.</p>

<p>학습 과정에서 스스로 값이 설정되는 매개변수인 가중치와 편향과 달리</p>

<p>하이퍼파라미터는 사람이 직접 조절하면서 잘 맞는 값을 찾아야 한다.</p>

<h2 id="442-신경망에서의-기울기">4.4.2 신경망에서의 기울기</h2>

<p>가중치 $W$, 손실함수 $L$인 신경망에서</p>

\[\begin{align*}
W&amp;=\begin{pmatrix}
w_{11}&amp;w_{12}&amp;w_{13}\\
w_{21}&amp;w_{22}&amp;w_{23}
\end{pmatrix}\\
{\partial L\over\partial W}&amp;=
\begin{pmatrix}
{\partial L\over\partial w_{11}}&amp;{\partial L\over\partial w_{12}}&amp;{\partial L\over\partial w_{13}}\\{\partial L\over\partial w_{21}}&amp;{\partial L\over\partial w_{22}}&amp;{\partial L\over\partial w_{23}}
\end{pmatrix}
\end{align*}\]

<p>${\partial L\over\partial w_{11}}$는 $w_{11}$의 값을 변경했을 때 손실 함수 $L$이 얼마나 변화하는지를 나타낸다.</p>

<h1 id="45-학습-알고리즘-구현하기">4.5 학습 알고리즘 구현하기</h1>

<p>전체</p>

<p>신경망에는 적응 가능한 가중치와 편향이 있고</p>

<p>이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 ‘학습’이라고 한다.</p>

<p>신경망 학습은 4단계로 수행된다.</p>

<p>1단계 - 미니배치</p>

<p>훈련 데이터 중 일부를 무작위로 가져온다.</p>

<p>이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수를 줄이는것이 목표다.</p>

<p>2단계 - 기울기 산출</p>

<p>미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다.</p>

<p>기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다.</p>

<p>3단계 - 매개변수 갱신</p>

<p>가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.</p>

<p>4단계 - 반복</p>

<p>1~3단계를 반복한다.</p>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;DeepLearning from scratch&quot;]" /><summary type="html"><![CDATA[Ch4 신경망 학습]]></summary></entry><entry><title type="html">ResNet</title><link href="http://localhost:4000/paper%20review/2022/08/20/ResNet.html" rel="alternate" type="text/html" title="ResNet" /><published>2022-08-20T03:37:25+09:00</published><updated>2022-08-20T03:37:25+09:00</updated><id>http://localhost:4000/paper%20review/2022/08/20/ResNet</id><content type="html" xml:base="http://localhost:4000/paper%20review/2022/08/20/ResNet.html"><![CDATA[<h1 id="resnet">ResNet</h1>

<h1 id="deep-redisual-learning-for-image-recognition">Deep Redisual Learning for Image Recognition</h1>

<h1 id="1-introduction">1. Introduction</h1>

<p>깊은 CNN들은 이미지 분류의 돌파구를 만든다.</p>

<p>깊은 네트워크들은 end-to-end 다층 구조에서 low/mid/high 수준의 특징과 분류기들을 통합하는 본성이 있고
층이 쌓일수록(깊이가 깊어질수록) 특징의”단계”는 풍부해진다.</p>

<p>최근 밝혀진 바에 의하면 네트워크의 깊이는 아주 중요하고 까다로운 ImageNet 데이터셋의 선두 결과들은 모두 “매우 깊은” 모델들(16~30 깊이의 모델)을 활용한다고 한다.</p>

<p>다른 많은 nontrivial visual recognition 작업들도 매우 깊은 모델들로부터 좋은 결과를 얻을 수 있다.</p>

<p>깊이의 중요성으로부터 생긴 질문 : 
층을 더 많이 쌓는다고 네트워크가 더 좋은 학습을 하는가?</p>

<p>이 질문을 해결할 때 만나는 장애물은 유명한 문제인 vanishing/exploding gradients(처음부터 수렴을 방해하는 문제)이다.</p>

<p>그러나, normalize된 초기값과 네트워크 중간에 normalization 층을 끼워넣는 방법으로
(수십개의 층을 가진 네트워크가 역전파 방법을 통해 SGD optimizer로 수렴을 시작할 수 있도록 하는 방법)
이 문제는 크게 해결이 되어왔다.</p>

<p>깊은 네트워크들이 수렴하기 시작할 때,
degradation 문제가 생긴다 : 
네트워크의 깊이가 증가하면서 정확도가 (당연하게도)포화되는것인데
그렇게 되면 점점 정확도가 낮아진다.</p>

<p>뜻밖에도, 이러한 degradation은 과적합에 의한 문제가 아니고
적당히 깊은 모델이 더 깊어지도록 층을 추가하는 행위가 높은 training error 를 갖게하는 것이다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet0.png" alt="ResNet0" /></p>

<p>(학습 정확도의) degradation은 모든 시스템들이 optimize하기 쉬운건 아니라는 것을 보여준다.</p>

<p>우리는 얕은 구조와 그것을 복사하고 층을 몇개 추가한 모델을 고려했다.</p>

<p>구조에 있어서 깊은 모델에 solution이 존재한다 :
추가된 층들은 identity mapping이고
다른 층들은 학습된 얕은 모델을 복사하는 것이다.</p>

<p>이 구성으로 얻은 해결책에 의해
더 깊은 모델이 얕은 것보다 더 높은 훈련 오류를 발생해서는 안 된다는 것을 나타낸다.</p>

<p>하지만 실험에서 보여지듯 현재로써
이 구조로 인한 해결책과 비교해서 더 좋은 해결책은 찾지 못했다.</p>

<p>이 논문에서, degradation문제를 해결하기 위해 ‘deep residual learning framework’를 소개할 것이다.</p>

<p>쌓인 층들이 각각 직접 바라는 층과 mapping 되는것을 바라기 보다, 이 층들이 residual mapping에 fit 되도록 했다.</p>

<p>공식적으로, desired underlying mapping을 $H(x)$라고 하고, 비 선형 층들을 쌓은 묶음이 $F(x):=H(x)-x$와 mapping되게 했다.</p>

<p>원래 mapping은 $F(x)+x$로 변환된다.</p>

<p>residual mapping을 optimize하는 것이
original mapping보다 optimize하는 것 보다 더 쉽다.</p>

<p>극단적으로, 만약 하나의 identity mapping이 최적이라면, 비선형 층을 쌓은 identity mapping을 fit 시키는것보다 residual을 0으로 만드는게 더 쉬울 것이다.</p>

<p>$F(x)+x$라는 식은 “shortcut connections”를 통해 신경망의 feedforward에 의해 알 수 있을 것이다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet1.png" alt="ResNet1" /></p>

<p>Shortcut connections는 하나 이상의 층을 skip하는 것이다.</p>

<p>우리의 경우, shortcut connections는 단순히 identity mapping을 수행하고 그것들의 출력은 stacked layers의 출력에 더해진다.</p>

<p>Identity shortcut connections는 추가 매개변수도 없고 추가적인 계산복잡도도 없다.</p>

<p>전체 네트워크는 여전히 처음부터 끝까지 역전파와 SGD로 학습이 가능하고
라이브러리를 변형시키지 않고 쉽게 구현할 수 있다.</p>

<p>ImageNet에서 포괄적인 실험을 하여 degradation 문제도 증명하고 우리의 방법도 평가했다.</p>

<p>우리는 두가지를 증명한다</p>

<ol>
  <li>extremely deep residual net은 optimize가 쉽지만
단순히 층을 쌓아 만든 같은 네트워크는 깊이가 깊어지게 되면 학습오차가 커진다는 것</li>
  <li>deep residual net은 증가된 깊이에서 쉽게 정확도를 얻을 수 있어
이전 네트워크들과 비교해 더 나은 결과를 제공한다.</li>
</ol>

<p>비슷한 현상들을 CIFAR-10에서 볼 수 있다,
그러나 최적화 어려움과 우리 방법의 효과는 특정 데이터셋과 연관이 있지 않다.</p>

<p>100개 이상의 층을 가진 모델로 이 데이터를 학습시키고,
1000개 이상의 층을 가진 모델을 연구해 볼 것이다.</p>

<p>ImageNet 분류 데이터셋에서, extremely deep residual net을 통해 훌륭한 결과를 얻었다.</p>

<p>152층의 residual net은 VGG net보다 낮은 복잡도를 가지면서 ImageNet에 보고된 네트워크들 중에서 가장 깊은 네트워크이다.</p>

<p>ImageNet test set에서 조합을 통해 3.57%의 top-5 error를 얻었고 ILSVRC-2015 classification 대회에서 1등을 차지했다.</p>

<p>extremely deep한 표현은 generalization성능도 뛰어나다(다른 인식 작업에서도),
그리고 ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation in ILSVRC &amp; COCO2015 competitions.</p>

<p>따라서 residual learning principle은 vision problem과 non-vision problem에 모두 일반적으로 사용될 수 있을것이다.</p>

<h1 id="2-related-work">2. Related Work</h1>

<h2 id="residual-representations">Residual Representations</h2>

<p>이미지 인식에서, VLAD는 Residual vector를 dictionary로 인코딩 하는 표현법이고
Fisher Vector는 VLAD를 확률적으로 공식화한 것이다.</p>

<p>둘 다 이미지 retrieval과 분류에서 강력한 얕은 표현 방법이다.</p>

<p>vector 양자화에서 residual vector의 인코딩은
원래 vector의 인코딩보다 더 효과적이다.</p>

<p>Partial Difference Equations 분야에 low-level vision과 computer graphics에서 널리 사용되는 Multigrid method는 문제를 시스템을 여러개의 크기의 subproblem으로 나눈다.</p>

<p>Multigrid의 대체 방안은 hierarchical basis preconditioning이다.(두 scale사이의 residual vector를 표현하는 변수에 의존하는 preconditioning)</p>

<p>이 방법은 표준적인 것과 비교해 더 빠르게 수렴한다.</p>

<p>이 방법들은 좋은 reformulation과 preconditioning은 optimization을 단순화 시킨다고 한다.</p>

<h2 id="shortcut-connections">Shortcut Connections</h2>

<p>shortcut connections를 말하는 실험들과 이론들은 오랫동안 연구되어왔다.</p>

<p>MLP의 초기 연구는 선형층이 네트워크의 입력부터 출력까지 구성하도록 하는 것이다.</p>

<p>몇개의 중간 층들은 vanishing/exploding gradient문제를 다루기 위해 보조 분류기에 직접 연결된다.</p>

<p>몇몇 논문들은 shortcut connections를 구현해서 레이어 반응, gradients, 전파 오류를 중심으로 하는 방법을 제안한다.</p>

<p>“inception” 층은 shortcut 가지와 몇개의 deeper 가지로 구성된다.</p>

<p>이 논문과 동시에, “highway networks”는 gating 기능이 있는 shortcut connections를 보여준다.</p>

<p>이 gate들은 데이터에 종속적이고 가중치가 있다,
반대로 identity shorcut은 가중치가 필요없다.</p>

<p>gated shortcut이 닫히면(0이되는 순간),
highway networks의 층들은 non-residual 기능을 보인다.</p>

<p>반대로, 우리의 식은 항상 residual 기능을 학습한다;
identity shortcut은 절대 닫히지 않는다,
그리고 모든 정보들은 항상 학습되어야 하는 추가적인 residual 함수들을 통과한다.</p>

<p>추가로, highway networks는 극도로 증가된 깊이(100이상 깊이)로 인한 정확도 증가를 증명하지 못했다.</p>

<h1 id="3-deep-residual-learning">3. Deep Residual Learning</h1>

<h2 id="31-residual-learning">3.1 Residual Learning</h2>

<p>몇개의 층이 쌓여 mapping되는 함수를 $H(x)$라고 하자,
$x$는 이 층들의 입력값이다.</p>

<p>만약 여러개의 비선형 층들로 복잡한 기능을 구현할 수 있다면,
마찬가지로 residual function으로도 복잡한 기능을 할 수 있을 것이다.  $H(x)-x$</p>

<p>그러니 쌓여있는 층들이 $H(x)$에 비슷해지는게 아니라
우리는 $F(x):=H(x)-x$가 되게 할 것이다.</p>

<p>그러므로 원래 함수는 $F(x)+x$가 될것이다.</p>

<p>두가지 형식 모두 요구되는 기능으로 근사될 것이지만,
학습 난이도는 다를 것이다.</p>

<p>이 식은 degradation문제에서 counterintuitive phenomena로부터 영감을 받은 것이다.</p>

<p>앞서 말했듯, 추가적인 층들이 identity mapping 구조를 띈다면,
더 깊은 모델은 복사본인 얕은 모델보다 학습오차율이 더 클 수 없다.</p>

<p>degradation문제는 solver가 여러개의 비선형층으로 이루어진 구조에서 identity mapping을 유추하는데에 어려움을 줄것이다.</p>

<p>residual learning reformulation에서
만약 identity mapping이 최적이라면,
solver들은 다층 비선형 구조가 identity mapping이 0을 향해 근접할 수 있도록 가중치를 움직일 것이다.</p>

<p>실제로는, identity mapping은 최적이지만 우리의 reformulation은 문제가 발생하도록 돕는 것이된다.</p>

<p>만약 최적의 함수가 zero mapping이 아니라 identity mapping이라면,
새로운 함수 하나를 학습하는 것 보다 identity mapping으로 방해요인을 찾는게 더 쉬울 것이다.</p>

<p>우리는 identity mappings가 합리적인 preconditioning을 제공하기 때문에
실험적으로 학습된 residual 함수들이 일반적으로 반응이 작다는 것을 증명했다,</p>

<h2 id="32-identity-mapping-by-shortcuts">3.2 Identity Mapping by Shortcuts</h2>

<p>우리는 모든 stacked layers에 residual learning을 도입했다.</p>

<p>공식적으로 이번 논문에서 우리가 만든 block은 아래와 같다</p>

\[y=F(x,\left\{W_i\right\})+x\]

<p>x랑 y는 각각 입력과 출력 벡터이다.</p>

<p>함수 F(x,{Wi})는 학습 되어야 하는 residual mapping을 의미한다.</p>

<p>예를들어</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet1.png" alt="ResNet1" /></p>

<p>이 구조는</p>

\[F=W_2\sigma(W_1\mathbf{x})\]

<p>가 되고 여기서 $\sigma$는 ReLU이고 편향은 표기의 단순화를 위해 제거했다.</p>

<p>수식 $F+x$는 shortcut connection에 의해 수ㅐㅎㅇ되고
element-wise addition이다.</p>

<p>두번째 비선형성은 $F+x$ 후에 계산된다.(i.e., $\sigma(y))$</p>

<p>앞에서 봤듯 shortcut connection은 계산 복잡도도 안올라가고 추가적인 가중치도 필요없다.</p>

<p>실로 매력적일 뿐 아니라 plain network와 residual network의 비교에 중요하다.</p>

<p>공정하게 plain과 residual net을 비교할 것이다.
같은 가중치 수, 깊이, 크기 그리고 element-wise addition을 제외한 계산비용까지 모두 같게하여 비교할 것이다.</p>

<p>x와 F의 차원은 반드시 같아야 한다.</p>

<p>만약 이런 경우가 아니라면(예를들어 입력과 출력의 채널을 변경하는 것),
우리는 shortcut connections의 차원을 맞추기 위해 $W_s$를 사용해 linear projection을 할 것이다.</p>

\[y=F(x,\{W_i\})+W_sx\]

<p>또한 정방행렬 $W_s$를 사용할 수도 있다.</p>

<p>하지만 우리는 실험적으로 identity mapping이 충분히 degradation문제를 다룰 수 있고 경제적임을 보일 것이다.(따라서 $W_s$는 차원을 맞추기 위해서만 사용될 것이다.)</p>

<p>residual function F는 유연하다.</p>

<p>이 논문의 실험에는 두세층이 포함된 F를 실험한다.
(더 많은 층들도 가능하다)</p>

<p>하지만 만약 F가 단층이라면</p>

\[y=F(x,\{W_i\})+x\]

<p>는 선형 식이 될것이다.</p>

\[y=W_1x+x\]

<p>위 식에서는 어떤 이점도 찾을 수 없다.</p>

<p>또한 우리는 단순함을 위해 전결합을 사용했지만,
residual은 합성곱 층에서도 사용 가능하다.</p>

<p>$F(z,{W_i})$는 여러 합성곱층을 표현할 수 있다.</p>

<p>element-wise addition은 두 feature map 사이에서 이루어지고
channel별로 이루어진다.</p>

<h2 id="33-network-architectures">3.3 Network Architectures</h2>

<p>다양한 plain/residual net들을 실험해보고
일관적인 현상들을 관찰했다.</p>

<p>사례를 위해 ImageNet을 위한 두가지 모델을 설명하겠다.</p>

<h2 id="plain-network">Plain Network</h2>

<p>VGG net의 이론에서 영감을 받아 plain 네트워크 구조를 만들었다.</p>

<p>합성곱층은 최대 3x3크기의 필터와 두가지 간단한 규칙을 따른다.</p>

<ol>
  <li>output feature map size가 동일하기 위해,
층들은 같은 수의 filter를 갖는다.</li>
  <li>만약 feature map size가 반으로 준다면,
filter의 수를 두배로 해서 층마다 시간 복잡도를 유지한다.</li>
</ol>

<p>downsampling은 합성곱층에서 stride를 2로 설정해서 수행한다.</p>

<p>네트워크는 global average pooling layer와 softmax를 사용하는 1000-way 전결합층으로 마무리된다.</p>

<p>가중치층의 총 수는 34개이다.</p>

<p>Plain Network는 VGG net보다 필터 수도 적고 복잡성도 낮다는것은 주목할 만하다.</p>

<p>34개의 층들은 36억개의 FLOPs(multiply-add)가 필요하고
이는 196억개의 FLOPs인 VGG-19의 18%에 해당하는 수치이다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet2.png" alt="ResNet2" /></p>

<h2 id="residual-network">Residual Network</h2>

<p>Plain net을 기반으로, shortcut connections를 추가해 Plain과 같은 부분을 residual 로 만들었다.</p>

<p>왼쪽에서 실선 shortcut connections처럼 입력과 출력의 차원이 같다면 identity shortcut 을 바로 사용할 수 있다.</p>

<p>차원이 증가하는 경우에는 점선으로된 shortcut connections처럼표현하고 두가지 경우를 고려한다.</p>

<ol>
  <li>shortcut은 여전히 identity mapping을 수행한다.
zero padding을 통해 차원을 늘려서 사용한다.
이 방법은 추가적인 매개변수가 없다</li>
  <li>projection shortcut은 차원을 일치시킬 때 사용된다.(1x1합성곱으로 완성)</li>
</ol>

<p>두개의 크기인 feature map을 통과할 때 두가지 경우 모두 stride=2로 수행한다.</p>

<h2 id="34-implementation">3.4 Implementation</h2>

<p>이미지는 scale augmentation을 위해 256~480에서 임의로 선택된 값으로 짧은 부분을 resize한다.</p>

<p>224,224 crop은 이미지로부터 임의로 sample을 구하거나
horizontal flip(각 pixel에 평균값을 빼는 것까지)을 통해서 도 sample을 취한다.</p>

<p>표준 color augmentation도 사용되었다.</p>

<p>convolution연산 뒤에 activation연산 전에 BatchNormalization(BN)을 사용했다.</p>

<p>가중치는 13번 논문을 따라서 초기화시켰고
네트워크는 처음부터 학습시켰다.</p>

<p>SGD를 mini-batch size 256으로 사용했다</p>

<p>Learning rate는 0.1부터 시작해서 error plateau일 때마다10씩 나눴다.</p>

<p>학습은 600000번만큼 iteration했다.</p>

<p>weight decay는 0.0001을 사용하고
momentum계수는 0.9로 했다.</p>

<p>Dropout층은 사용하지 않았다.</p>

<p>test에서는 연구의 비교를 위해 표준적으로 10-crop testing을 했다.</p>

<p>최고의 결과를 위해 fully-convolutional form을 사용했고
이미지의 짧은 축의 크기를 224,256,384,480,640으로 설정한 여러개의 크기에서 계산을 하고 결과를 평균내었다.</p>

<h1 id="4-experiments">4. Experiments</h1>

<h2 id="41-imagenet-classification">4.1 ImageNet Classification</h2>

<p>네트워크 평가를 위해 1000개의 클래스로 구성된 ImageNet 2012 classification dataset을 사용했다.</p>

<p>모델들은 128만개의 학습 이미지를 통해 학습하고
5만개의 validation 이미지로 평가됐다.</p>

<p>또한, 최종 결과는 10만개의 test image를 통해 얻었ek.</p>

<p>top-1, top-5 error rate를 계산했다.</p>

<h3 id="plain-networks">Plain Networks</h3>

<p>18-layer와 34-layer를 평가했다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet3.png" alt="ResNet3" /></p>

<p>Downsampling은 conv3_1,conv4_1,conv5_1에서도 stride 2로 진행된다</p>

<p>아래 결과를 보면 더 깊은 34-layer가 얕은 18-layer보다 validation error가 더 큰 것을 알 수 있다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet4.png" alt="ResNet4" /></p>

<p>얇은 선은 training error, 굵은 선은 validation error</p>

<p>이유를 알아보기 위해 학습과정에서 training/validation error를 확인해 보니 degradation 문제가 생긴것을 확인했다.</p>

<p>왜냐하면 학습 전체 과정에서 34-layer의 학습오차가 18-layer보다 항상 높았기 때문이다.
심지어 18-layer의 해공간이 34-layer의 해공간의 하위 집합이었음에도 이러한 결과가 나타났다.</p>

<p>이런 optimize difficulty는 불행하게도 vanishing gradient 때문에 발생한다.</p>

<p>plain net들은 전파 과정에서 0이 아닌 분산값을 갖게 하도록
BN을 사용했다.</p>

<p>또한, 역전파에서 gradient들은 BN을 통해 좋은 정규화가 이루어진 것을 증명할 수 있다.</p>

<p>따라서 순전파와 역전파 모두 신호를 소실시키지 않았다.</p>

<p>사실 34-layer plain net은 여전히 경쟁적인 정확도를 달성할 수 있다. (solver가 어느정도 작동한다면)</p>

<p>deep plain net들은 매우 낮은 비율로 수렴하기 때문에 training error를 낮추는데 영향을 준다.</p>

<p>이러한 optimization difficulties는 후에 연구될 것이다.</p>

<h3 id="residual-networks">Residual Networks</h3>

<p>다음으로 18-layer와 34-layer residual nets(ResNets)를 평가했다.</p>

<p>기본 구조는 plain net과 같고 3x3 filter쌍마다 shortcut connection이 추가 되어있다.</p>

<p>아래 비교에서 모든 shortcut 에 identity mapping을 적용했고
차원을 높이기 위해 zero-padding을 했다.</p>

<p>따라서 plain net과 비교해 추가적인 매개변수가 없다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet5.png" alt="ResNet5" /></p>

<p>얇은 선은 training error, 굵은 선은 validation error</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet6.png" alt="ResNet6" /></p>

<p>위 결과로부터 3가지 주요 관찰할 것을 얻었다.</p>

<h3 id="residual-학습을-통해-상황이-반대가-되었다">Residual 학습을 통해 상황이 반대가 되었다.</h3>

<p>residual 학습으로 34-layer의 결과가 18-layer의 결과보다 좋게 나왔다.</p>

<p>더 중요한 것은 34-layer ResNet은 상당히 낮은 training error를 보이고 validation data에 범용성을 갖췄다.</p>

<p>이것은 degradation문제가 이번 setting으로 잘 해결이 되고
또 깊은 구조의 네트워크로부터 높은 정확도를 얻었다는 것을 의미한다.</p>

<h3 id="plain-net과-resnet을-비교했을-때">plain net과 ResNet을 비교했을 때,</h3>
<p>34-layer ResNet은 top-1 error가 줄었다는 것이다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet7.png" alt="ResNet7" /></p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet8.png" alt="ResNet8" /></p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet9.png" alt="ResNet9" /></p>

<p>이러한 비교는 extremely deep system에서 residual learning의 효과를 입증한다.</p>

<p>마지막으로, 18-layer Plagin/Residual net들은 비슷한 정확도를 보이지만
18-layer ResNet이 더 빠르게 수렴한다.</p>

<p>network가 지나치게 깊지 않은 경우(여기서는 18-layer)
SGD는 계속해서 좋은 solution을 Plain net에 찾아줄 수 있다.</p>

<p>이 경우, ResNet은 더 빠른 단계에서 수렴을 하도록 하기 때문에 optimization이 쉬워진다.</p>

<h3 id="identity-vs-projection-shorcuts">Identity vs. Projection Shorcuts</h3>

<p>추가 매개변수가 없는것과 identity shorcuts는 학습을 돕는다고 증명했다.</p>

<p>다음으로는 projection shortcut을 살펴보겠다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet7.png" alt="ResNet7" /></p>

<p>Table 3에서 세가지 옵션들을 비교했다.</p>

<p>(A) 차원의 증가를 위해 zero-padding을 사용하고
모든 shortcut을 identity mapping으로 구현해 추가 매개변수가 없게 함.</p>

<p>(B) projection shortcut을 사용해 차원을 증가시키고
다른 shortcut들은 identity를 사용했다.</p>

<p>(C) 모든 shortcut들을 projection으로 사용했다.</p>

<p>Table 3에서 볼 수 있듯이 세가지 옵션 모두 plain net과 비교해 상당히 좋은 결과를 만든다.</p>

<p>B가 A보다 약간 더 좋은데
A에서 zero-padding으로 늘어난 차원이 사실 residual learning이 아니기 때문이다.</p>

<p>C는 B보다 조금 더 좋은데
projection shortcut에 의해 매개변수가 더 추가 되었기 때문이라고 생각한다.</p>

<p>하지만, A/B/C 사이에 차이가 작은 것은 projection shortcut이 degradation 문제를 다루는데 필수적인 것은 아니라는 것을 나타낸다.</p>

<p>따라서 이 논문의 나머지 부분에서는 C를 사용하지 않는다.
(메모리사용량과 시간 복잡도와 모델의 크기를 줄이기 위해)</p>

<p>Identity shortcut들은 bottleneck 구조의 복잡도를 증가시키지 않기 때문에 특히 중요하다.</p>

<h3 id="deeper-bootleneck-architectures">Deeper Bootleneck Architectures</h3>

<p>다음으로 더 깊은 구조를 보겠다.</p>

<p>사용할 수 있는 학습시간에 대한 염려로 인해,
building block을 bottleneck 구조로 변경했다.</p>

<p>(non-bottleneck ResNet도 좋은 정확도를 보이지만
경제적이지 못해 bottleneck ResNet을 사용한다.
따라서 bottleneck ResNet을 사용하는 이유는 practical consideration 때문인 것이다.)</p>

<p>각 residual function F에 층을 3개씩 샇았다.</p>

<p>3개의 층은 1x1,3x3,1x1 합성곱을 한다.</p>

<p>1x1 합성곱은 차원을 줄였다가 다시 키우는 역할을 하며
3x3 합성곱은 작은 차원의 입출력에 대해 병목현상을 일으킨다.</p>

<p>bottleneck과 non-bottleneck 모두 시간 복잡도는 비슷하다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet10.png" alt="ResNet10" /></p>

<p>매개변수가 추가되지 않는 identity shortcuts는 병목 구조에서
특히 더 중요하다.</p>

<p>만약 identity shortcut이 projection으로 대체된다면,
시간복잡도와 모델 크기가 두배가 될것이다.
마치 shortcut이 두개의 높은 차원과 연결된것처럼</p>

<p>따라서 identity shortcut은 bottleneck 구조를 더 효율적으로 만든다.</p>

<h3 id="50-layer-resnet">50-layer ResNet</h3>

<p>34-layer net에서 두개의 layer block을 3-layer bottleneck block으로 대체했다.(그 결과는 Table1의 50-layer ResNet이다.)</p>

<p>옵션B를 사용해 차원을 키웠고
이 모델의 FLOPs는 38억이다.</p>

<h3 id="101-layer-and-152-layer-resnets">101-layer and 152-layer ResNets</h3>

<p>101-layer과 152-layer ResNet을 만들었다(3-layer block을 더 사용하여)</p>

<p>깊이가 충분히 증가했지만,
152-layer ResNet(113억 FLOPs)은 여전히 VGG-16/19(153억/196억 FLOPs)보다 복잡도가 낮았다.</p>

<p>50/101/152-layer ResNet은 margin을 고려한 34-layer보다 더 정확하다.</p>

<p>degradation을 관찰하지 못했으므로
상당히 깊은 네트워크로부터 충분히 높은 정확도를 얻은 것이다.</p>

<p>모든 평가겨로가에서 깊이에 대한 이점이 발견되었다.</p>

<h3 id="comparisons-with-state-of-the-art-methods">Comparisons with State-of-the art Methods</h3>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet8.png" alt="ResNet8" /></p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet9.png" alt="ResNet9" /></p>

<p>위 결과에서 보듯 이전에 사용하던 최고의 단일-모델과 비교했다.</p>

<p>34-layer ResNet이 좋은 결과를 보였다.</p>

<p>152-layer ResNet은 단일-모델로써 top-5 validation error값이 4.49%가 나왔다.</p>

<p>테이블5에서 보이는 여러 모델을 조합한 결과들과 비교가 가능할 정도로
단일 모델인 152-layer ResNet은 매우 뛴어나다.</p>

<p>ensemble을 구성하기 위해 서로다른 깊이의 6개의 모델들을 조합했다.
(제출할 때에는 152-layer 두개만 조합했다.)</p>

<p>결과는 top-5 error값으로 3.57%가 나왔고
이 결과로 ILSVRC-2015 에서 1등을 차지했다.</p>

<h2 id="42-cifar-10-and-analysis">4.2 CIFAR-10 and Analysis</h2>

<p>CIFAR-10(10개의 클래스를 갖는 5만개의 학습 1만개의 테스트이미지)에서 더 많은 연구를 해보았다.</p>

<p>우리의 초점은 최첨단 구조에서 보이는 결과를 얻는 것이 아니기 때문에
extremely deep network의 구조를 간단하게 구성했다.</p>

<p>입력으로 32x32을 받는다(각 픽셀은 평균값들을 뺀 상태이다)</p>

<p>첫 번째 층은 3x3 합성곱층이다.</p>

<p>그리고나서 6n개의 3x3 합성곱 층을 쌓아 특징맵의 크기가 32,16,8에 맞게 할당을 해서
각 특징맵별로 2n개의 합성곱 계산을 해야한다.</p>

<p>subsampling은 stride2인 합성곱으로 진행했다.</p>

<p>네트워크의 마지막 부분은 global average pooling과 10-way fully-connected layer with softmax를 사용했다.</p>

<p>따라서 총 가중치층은 6n+2가 된다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet11.png" alt="ResNet11" /></p>

<p>shortcur connection이 사용되면,
그것들은 3x3 합성곱 두개에 하나씩 연결되어 총 3n개의 shortcut이 생긴다.</p>

<p>CIFAR-10에는 모든 경우에 identity shortcut(option A)을 사용해서
plain 모델과 비교해 깊이, 크기, 매개변수의 수가 모두 같다.</p>

<p>이 때 weight decay 는 0.0001
momentum계수는 0.9
그리고 dropout은 사용하지 않지만 BN을 사용했다.</p>

<p>batch-size는 128로하고
두개의 GPU에서 학습을 진행했다.</p>

<p>learning rate는 0.1로 초기 설정하고 32k와 48k에서 10씩 나눠서 적용했다
그리고 64k iteration에서 학습을 종료했다.(train/val의 크기를 45k/5k로 설정한 결과)</p>

<p>data augmentation은 간단하게하여 학습을 진행했다 :</p>

<p>각 모서리에 4pixel만큼씩 padding을 했고
padding한 이미지와 그것을 뒤집은 이미지로부터 32x32의 크기만큼 임의로 잘랐다.</p>

<p>test를 위해 32x32이미지의 single view만 평가했다.</p>

<p>n={3,5,7,9}를 적용해 20, 32, 44, 56-layer network를 만들었다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet12.png" alt="ResNet12" /></p>

<p>Highway network를 보면 증가된 깊이로부터 error가 증가하는 것을 볼 수 있다.</p>

<p>이 현상은 ImageNet과 MNIST에서 비슷하게 보여진다.
(모두 optimization difficulty가 문제다)</p>

<p>ImageNet에서와 비슷하게 ResNet은 optimization difficulty를 극복하고
깊어진 깊이로부터 높은 정확도를 얻는다고 증명했다.</p>

<p>게다가 n=18인 경우에 110-layer ResNet을 만드는데</p>

<p>이런 경우, 수렴을 시작하기에 앞서 learning rate가 0.1인 것은 다소 높다고 판단했다.</p>

<p>그래서 training error가 80%아래로 내려갈 때까지 0.01로 학습률을 설정했다.</p>

<p>그리고 나서 학습률을 다시 0.1로 설정하고 계속 학습했다.</p>

<p>110-layer도 잘 수렴했다.</p>

<p>110-layer는 최첨단 구조가 아님에도 다른 깊거나 얕은 구조들 (Fitnet and Highway)보다 더 매개변수가 적다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet13.png" alt="ResNet13" /></p>

<p>bold : training error, dashed : test error</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet14.png" alt="ResNet14" /></p>

<p>bold : training error, dashed : test error</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet15.png" alt="ResNet15" /></p>

<h3 id="analysis-of-layer-responses">Analysis of Layer Responses</h3>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet16.png" alt="ResNet16" /></p>

<p>위 그래프에서 표준편차를 확인할 수 있다.</p>

<p>반응들은 각 3x3 layer에 의한 결과이고 BN의 결과이고 activation함수를 통과하기 전의 값이다.</p>

<p>ResNet에서 이런 분석은 residual functions의 response strength를 표출한다.</p>

<p>위 그래프는 ResNet은 일반적으로 plain 구조에 비해 response가 작다고 보여준다.</p>

<p>이러한 결과는 우리의 기본 동기를 뒷받침해준다.</p>

<p>따라서 보통 residual function이 일반적으로 non-residual인것보다 0에 더 가깝다는 것이다.</p>

<p>또한, 깊은 ResNet은 더 작은 크기의 response를 보인다.</p>

<p>더 많은 층이 있을 경우, ResNet의 각 층은 신호를 덜 수정하는 경향이 있다.</p>

<h3 id="exploring-over-1000-layers">Exploring Over 1000 layers</h3>

<p>1000층이 넘는 아주 깊은 모델을 조사해보자.</p>

<p>n=200으로 설정을해서 1202-layer network를 만들었다.
학습은 위와 같은 방법으로 진행했다.</p>

<p>우리의 방법은 optimization difficulty를 보이지 않고
이 1000-layer network는 0.1미만의 학습 오차를 달성할 수 있다.</p>

<p>이것의 test error는 여전히 괜찮은 수준인 7.93%이다.</p>

<p>하지만 여전히 매우 깊은 모델이 갖는 문제는 해결되지 않았다.</p>

<p>1202-layer의 test 결과는 우리의 110-layer 네트워크보다 안좋다.
(비록 두 모델이 비슷한 학습에러를 결과를 보이지만)</p>

<p>이것은 과적합 때문인다.</p>

<p>1202-layer는 이 작은 데이터셋에 불필요하게 많은 층이 사용되었다.</p>

<p>강력한 regularization(e.g.,  maxout, dropout)은 이 데이터셋을 상대로 최고의 결과를 얻기 위해 사용되었다.</p>

<p>그러나 이번 연구에서 maxout과 dropout은 사용하지 않았고
구조적으로 깊고 얕음을 통해 regularization을 부과하고
optimization difficulty에는 초점을 두지 않았다.</p>

<p>하지만, 강력한 regularization의 조합은 결과를 향상시킬것이다.(앞으로 연구해볼 것이다.)</p>

<h2 id="43-object-detection-on-pascal-and-ms-coco">4.3 Object Detection on PASCAL and MS COCO</h2>

<p>우리의 방법은 다른 recognition 작업에서도 좋은 generalization 성능을 보인다.</p>

<p><img src="/assets/img/Paper_Review/ResNet/ResNet17.png" alt="ResNet17" /></p>

<p>Table7과 Table8 에서 볼 수 있듯이
object detection baseline은 PASCAL VOC 2007 and 2012 and COCO를 통해 평가했다.</p>

<p>detection 방법으로 Faster R-CNN을 채택했다.</p>

<p>우리는 VGG-16을 ResNet-101로 대체하여 개선하는 것에 관심이 있다.</p>

<p>두 모델을 사용하여 detection 구현하는 것은 같다,</p>

<p>따라서 더 좋은 네트워크를 기반으로 이점이 생긴다.</p>

<p>대부분 눈에 띄는 점은, COCO데이터셋에서 6.0% 상승한 값을 얻었다는 것이다.(상대적으로 28% 개선됨)</p>

<p>이런 이점은 단지 learned representation때문인 것이다.</p>

<p>Deep residual net을 기반으로 ILSVRC &amp; COCO 2015 competition에서 몇몇 부문에서 1등을 차지했다 :
ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.</p>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;Paper Review&quot;]" /><summary type="html"><![CDATA[ResNet]]></summary></entry><entry><title type="html">VGGNet</title><link href="http://localhost:4000/paper%20review/2022/08/20/VGGNet.html" rel="alternate" type="text/html" title="VGGNet" /><published>2022-08-20T03:24:34+09:00</published><updated>2022-08-20T03:24:34+09:00</updated><id>http://localhost:4000/paper%20review/2022/08/20/VGGNet</id><content type="html" xml:base="http://localhost:4000/paper%20review/2022/08/20/VGGNet.html"><![CDATA[<h1 id="vggnet">VGGNet</h1>

<h1 id="1-introduction">1. Introduction</h1>

<p>합성곱 네트워크는 최근(2015) 대규모 공공 이미지 저장소인 ImageNet과 고성능 계산 시스템(GPU)와 대규모 cluster 덕분에 큰 규모의 이미지나 비디오 인식에 좋은 성과를 보인다.</p>

<p>특히, ILSVRC는 deep visual recognition 구조들의 진보에서 중요한 역할을 했다.</p>

<p>ILSVRC는 고차원 얕은 특징 인고딩에서 심층 ConvNet에 이르기까지 몇 세대에 걸친 대규모 이미지 분류 시스템의 테스트베드 역할을 했다.</p>

<p>ConvNet들이 computer vision 분야에서 점점 상품화 되면서 더 높은 정확도를 달성하기위해 Krizhevsky의 original 구조(AlexNet)를 개선하려고 많은 시도들이 있었다.</p>

<p>예를들어, ILSVRC-2013에서 최고의 성능은 Alexnet에서 receptive window의 크기를 줄이고 첫 번째 합성곱층에서 더 작은 stride를 사용해서 얻은 모델로부터 얻어졌다.</p>

<p>다른 라인에 대한 개선은 모델이 전체 이미지나 크기가 변형된 이미지를 더 조밀하게 학습하고 시험하게 했다.</p>

<p>이 논문에서, 우리는 ConvNet구조에서 또 다른 중요한 측면인 깊이에 대해 알아볼 것이다.</p>

<p>논문 끝에는, 구조의 다른 매개변수들을 고정시키고 모든 층에서 합성곱 필터의 크기를 3x3으로 작게 설정하게 해서 합성곱층을 더 많이 추가하여 깊이를 꾸준히 증가시켜볼 것이다.</p>

<p>결과적으로, ILSVRC classification과 localisation작업에서 최첨단 모델의 정확도를 달성할 뿐 아니라 간단한 파이프라인에 사용되더라도 다른 이미지 데이터에 대해 적용했을 때 최고의 성능을 보이는 상당히 정확한 ConvNet 구조를 만들었다.</p>

<p>우리는 연구를 통해 얻은 가장 좋은 성능의 두가지 모델을 후속연구를 위해 공개했다.</p>

<p>다음장에서는 ConvNet 구성을 묘사하고
3장에서는 image classification training과 evaluation에 대한 내용을 설명하고
4장에서는 ILSVRC classification작업에서 configuration들을 비교하고
5장에서는 결론을 내렸다.</p>

<p>ILSVRC-2014 object localisation system을 Appendix A에서 묘사하고 평가했다
Appendix B에서는 very deep features 의 generalisation에대해 논의하고
Appendix C에서는 주요 논문에 대한 개정 내용이 포함된다.</p>

<h1 id="2-convnet-configurations">2. ConvNet Configurations</h1>

<p>같은 조건에서 ConvNet depth의 증가가 가져오는 개선을 측정하려면 설계에 사용된 모든 ConvNet 층의 구성에 Ciresan과 Krizhevsky와 동일한 조건들을 적용해야 한다.</p>

<p>2장에서는 먼저 ConvNet 구성에서 일반적인 내용을 서술하고 그다음 평가에서 사용된 특정한 configuration에 대해 자세하게 서술한다.</p>

<p>마지막으로 설계할 때 했던 선택들을 이전 최신기술과 비교해볼것이다.</p>

<h2 id="21-architecture">2.1 Architecture</h2>

<p>학습하는 동안, ConvNet의 입력값은 224x224x3 형태이다.</p>

<p>각 픽셀로부터 training set에서 계산한 평균 RGB값을 빼주는 전처리 이외에 다른 전처리는 하지 않았다.</p>

<p>양옆과 위아래에 대한 정보를 담을 수 있는 가장 작은 사이즈인 3x3의 매우 작은 receptive field를 가지는 필터를 사용한 합성곱층의 stack에 이미지를 통과 시켰다.</p>

<p>우리는 non-linearity를 따르는 1x1 합성곱 필터 또한 사용했다.</p>

<p>합성곱의 stride는 1 pixel로 고정했다; convolution 연산 후에 입력과 같은 모양이 나오도록 padding은 1 pixel을 사용했다.</p>

<p>Spatial pooling은 합성곱 뒤에(모든 합성곱은 아님) 5개의 max-pooling층으로 수행된다.</p>

<p>Max-pooling은 2x2 pixel window가 stride=2의 값으로 연산을 한다.</p>

<p>모델별로 다른 깊이를 적용해서 만든 stack of convolutional layers 뒤에는 전결합층이 나온다.</p>

<p>처음 두개의 전결합층은 각각 4096개의 유닛을 가지고 세 번째 전결합층은 1000개의 유닛을 갖는다.</p>

<p>마지막층은 SoftMax층이다.</p>

<p>전결합층들의 구성은 모든 네트워크들이 같도록 설계했다.</p>

<p>모든 은닉층들은 ReLU non-linearity를 사용한다.</p>

<p>이번 연구의 네트워크들은 한 개를 제외하고 AlexNet에서 사용된 Local Response Normalisation(LRN) 을 사용하지 않았다 :
LRN은 ILSVRC 데이터 셋에서의 성능을 개선시키지 못하면서 메모리 사용량은 증가시키고 계산시간도 증가시켰다.</p>

<p>LRN이 적용된 경우 LRN층의 매개변수들은 AlexNet의 LRN층의 매개변수와 같다.</p>

<h2 id="22-configurations">2.2 Configurations</h2>

<p>이번 연구에서 평가할 ConvNet configuration들은 Table 1에 요약되어있고 column당 하나의 모델이다.</p>

<p>지금부터는 네트워크의 이름을 A-E사이로 이름을 부르겠다.</p>

<p>모든 configuration들은 2.1에서 설계한 구조를 따르고 서로 깊이만 다르게 한다: 11개의 가중치 층을 갖는 network A부터 19개의 가중치 층을 갖는 network E</p>

<p>합성곱층의 채널 수는 꽤 작다, 64부터 시작해서 512가 될 때까지 2를 곱한다.</p>

<p>Table 2에서는 각 configuration별로 매개변수의 수를 보여준다.</p>

<p>더 깊은 구조임에도 불구하고 가중치의 수는 우리의 network들이 더 깊이가 얕은 network와 비교했을 때 합성곱층의 채널 수도 적고 receptive field도 작아서 가중치가 더 많지 않다.</p>

<h2 id="23-discussion">2.3 Discussion</h2>

<p>ConvNet 구성들은 ILSVRC-2012와 ILSVRC-2013에서 입상한 가장 좋은 모델과 꽤 다르게 생겼다.</p>

<p>Krizhevsky의 11x11 크기의 필터를 stride 4만큼 씩 움직이는 합성곱층과 와 Zeiler&amp;Fergus의 7x7 크기의 필터를 stride 2만큼 씩 움직이는 합성곱층처럼 큰 receptive field를 사용하기 보다
우리는 전체 네트워크에서 3x3 크기의 receptive field를 사용하고 stride는 1씩 움직였다.</p>

<p>spatial pooling없이 두개의 3x3 크기의 필터를 사용하는 합성곱층을 사용하는 것은 5x5 크기의 receptive field를 사용하는 합성곱과 같다는 것을 쉽게 알 수 있다 ;
3x3 합성곱이 3개면 7x7 receptive field와 같은 효과를 보인다.</p>

<p>그렇다면 3x3 합성곱을 3개 연달아 사용하는 것이 7x7 합성곱을 1개 사용하는 것과 비교하여 우리가 어떤 이점을 얻는가?</p>

<p>첫째, 하나의 non-linear rectification layer를 사용하는거보다 3개의 non-linear rectification layers를 통합하여 사용하여 decision function을 더 차별적으로 만들 수 있다.</p>

<p>둘째, 매개변수의 수를 줄일 수 있다 :
만약 3개의 3x3 합성곱 stack의 입력과 출력이 C개의 채널을 갖는다면 stack의 매개변수는 $3(3^2C^2)=27C^2$ 개가 될것이다 ;
동시에 하나의 7x7 합성곱층은 $7^2C^2=49C^2$개의 가중치가 필요하다.
이전에 비해 가중치 수가 81% 증가한다.</p>

<p>이는 7x7 합성곱층에 regularization을 부과하여 사이사이 non-linearity가 주입된 3x3 필터들로 분해되도록 하는 것으로 보일 수 있다.</p>

<p>configuration C와 같이 1x1 합성곱층을 포함시키면 receptive field에 영향을 주지 않고 decision function에 non-linearity를 추가할 수 있다.</p>

<p>여기서 1x1 합성곱은 입력과 출력의 채널이 같아지도록 입력을 같은 차원에 선형 투영을 하지만
rectification 함수에 의해 추가된 non-linearity가 도입된다.</p>

<p>1x1 합성곱층은 최근 Lin의 “Network in Network” 구조에 활용되었다는 것을 알아야 한다.</p>

<p>Ciresan에 의해 이전부터 작은 크기의 합성곱 필터가 사용되었지만,
그들의 network들은 우리의 network보다 충분히 얕고 대규모 데이터셋 ILSVRC로 평가해보지 않았다.</p>

<p>Goodfellow가 11개의 가중치층을 갖는 깊은 ConvNet을 거리의 숫자 인식 작업에 적용했더니 깊이가 깊어질수록 더 좋은 성능을 보였다고 한다.</p>

<p>ILSVRC-2014 분류 작업에서 최고 실적을 보인 GoogLeNet은 우리와 따로 개발되었지만,
작은 필터를 이용한 합성곱과 매우 깊은 ConvNet(22 가중치 층)라는 점에서 유사하다.
(합성곱 필터는 3x3과 1x1 외에도 5x5를 사용했다.)</p>

<p>그러나 GoogLeNet의 topology는 우리가 설계한 구조보다 복잡하고 
feature map의 saptial resolution이 첫 번째 합성곱층에서 계산량을 줄이기 위해 더 공격적으로 줄어든다.</p>

<p>우리의 모델은 GooLeNet보다 single-network classification accuracy 측면에서 뛰어나다.</p>

<p><img src="/assets/img/Paper_Review/VGGNet/VGGNet0.png" alt="VGGNet0" /></p>

<h1 id="3-classification-framework">3. Classification Framework</h1>

<p>이전 장에서 우리의 네트워크의 구성을 자세하게 살펴보았다.</p>

<p>이번장에서는 classification ConvNet training과 evaluation을 자세하게 살펴보겠다.</p>

<h2 id="31-training">3.1 Training</h2>

<p>ConvNet 학습과정은 일반적으로 Krizhevsky를 따라했다.(나중에 설명하지만 학습 이미지의 크기를 키우고 잘라서 만든 샘플은 사용하지 않았다.)</p>

<p>즉, 학습은 multinomial logistic regression을 목적으로 mini-batch gradient descent(LeCun의 역전파를 기반으로)를 momentum과 함께 사용해 optimising 했다.</p>

<p>batch size는 256
momentum은 0.9으로 설정했다.</p>

<p>0.0005값을 weight decay로 설정한 L2 regularization과 dropout ratio를 0.5로 설정하여 첫 두개의 전결합층에 Dropout regularization을 적용했다.</p>

<p>학습률은 0.02로 초기설정을 했고 validation set accuracy가 높아지지 않을 때 10씩 나눠줬다.</p>

<p>전체적으로, 학습률은 3번 감소했고 학습은 370000iteration 뒤에 멈췄다(74epoch).</p>

<p>AlexNet과 비교해 우리 구조가 더 많은 매개변수와 더 깊은 네트워크임에도 더 적은 epoch수로 수렴할 수 있었던 이유는</p>

<ol>
  <li>더 깊지만 작은 합성곱 필터가 주는 암시적 정규화</li>
  <li>특정 층의 pre-initialisation</li>
</ol>

<p>네트워크 가중치의 초기설정은 중요하다,
왜냐하면 안좋은 초기설정은 deep net에서 gradient의 불안정한 성질 때문에 학습을 멈추게 하기 때문이다.</p>

<p>이 문제를 해결하기 위해 random 초기설정으로 학습하기에 충분히 얕은 configuration A부터 학습 시켰다.</p>

<p>그리고나서, 더 깊은 구조를 학습시킬 때, 첫 4개의 합성곱 층과 뒤에 3개의 전결합 층의 가중치를 A의 결과와 똑같이 설정해주고 중간 층은 random initialisation했다.</p>

<p>사전 초기설정된 층의 학습률을 줄이지 않고, 학습하는 동안 변경하도록 했다.</p>

<p>random initialisation의 경우, 가중치들이 평균이 0이고 표준편차가 0.01인 분포를 따르는 표본에서 추출했다.</p>

<p>편향들은 0으로 초기설정했다.</p>

<p>논문 출판 후에 우리는 Glorot&amp;Bengio(Xavier)의 random initialisation procedure를 통해 사전학습 없이 임의 설정된 가중치를 사용하는것이 가능하다는 것을 알았는데 이는 주목할만 하다.</p>

<p>224x224크기의 입력 이미지를 받기 위해서 학습 이미지들의 크기를 조절하고 임의로 잘랐다.(한번 crop하면 한 iteration동안 사용된다.)</p>

<p>학습 데이터를 더 증가시키기 위해서, crop하기 전에 임의로 horizontal flipping과 RGB colour shift를 했다.(AlexNet과 같이)</p>

<p>학습 이미지의 크기 조절은 밑에서 설명한다.</p>

<h3 id="학습-이미지-크기">학습 이미지 크기</h3>

<p>S를 학습이미지를 isotropically-rescaled 했을 때 짧은 쪽이라고 하자.(S를 training scale이라고도 한다)</p>

<p>자를 크기가 224x224로 고정된 반면,
원칙적으로 S는 224 이상의 값을 받을 수 있다. :</p>

<p>S=224라면 crop은 전체 이미지를 capture한다,  학습 이미지의 짧은 부분을 완전히 사용한다;
S»224라면 crop은 작은 객체나 객체의 일부를 포함하는 이미지의 작은 부분일 것이다.</p>

<p>training scale S를 정하기 위해 두가지 접근을 고려한다.</p>

<p>먼저 S를 single-scale training(한개의 값)과 같이 고정하는 것이다.</p>

<p>연구에서, AlexNet과 같이 256의 값으로도 해보고 384로도 고정해 보았다.</p>

<p>주어진 ConvNet 구성에서, 우리는 첫 번째 네트워크를 S=256으로 학습시켰다.</p>

<p>S=384인 네트워크의 학습 속도를 높이기 위해,
S=256일때 학습한 가중치로 초기설정을 하고 학습률을 0.001로 초기설정을 했다.</p>

<p>두번째 접근은 S를 multi-scale training(범위 지정)으로 설정하는 것이다.
각 이미지는 개별적으로 S의 범위에서 무작위로 한 값을 정해 크기조절을 진행한다.</p>

<p>S의 범위는 256~512로 정했다.</p>

<p>이미지 안에 객체들이 크기가 다를 수 있기 때문에,
학습 중에 이를 계산하는 것이 좋다.</p>

<p>이것은 하나의 모델이 넓은 범위에 걸쳐 객체를 인식하도록(scale jittering) 학습 데이터를 늘린 것처럼 보일 수 있다.</p>

<p>속도 문제 때문에 S=384인 single-scale model이 사전 학습한 모든 층의 가중치를 fine-tuning해서 같은 configuration인 multi-scale model을 학습 시켰다.</p>

<h2 id="32-testing">3.2 Testing</h2>

<p>test scale Q를 사용해 이미지를 isotropically rescale한다.</p>

<p>Q는 S와 같을 필요는 없다.</p>

<p>그리고나서, 네트워크를 조밀하게 rescale된 test image에 적용한다.</p>

<p>전결합 층들은 먼저 합성곱 층으로 전환된다.
첫번째 FC는 7x7 합성곱으로
두번째 FC는 1x1 합성곱으로 전환.</p>

<p>네트워크의 모든층을 합성곱층으로 만든 네트워크를 uncropped인 전체 이미지에 적용한다.</p>

<p>결과는 입력 이미지의 크기에 따른 variable spatial resolution과 class score map이고 채널의 수는 클래스의 수와 같다.</p>

<p>마지막으로, 이미지의 고정된 크기의 vector of class scores를 얻기 위해, class score map은 공간적 평균을 취한다. (sum-pooled)</p>

<p>또한, test set을 horizontal flipping으로 증가시킨다;
원본과 뒤집은 사진의 soft-max class posteriors를 평균내서 최종 수치를 얻는다.</p>

<p>합성곱 네트워크는 전체 이미지에 적용되기 때문에 test 때 여러개의 자른 sample은 필요없다.
각 crop별로 네트워크가 계산을 다시 하는것은 효율이 적다.</p>

<p>동시에, Szegedy에 의하면 큰 crop 집합을 사용하는 것은 입력 이미지를 미세하게 추출하기 때문에 합성곱 네트워크를 사용하는 것보다 정확도를 향상시킨다고 한다.</p>

<p>또한, multi-crop 평가는 합성곱의 결정 조건이 다르기 때문에 세밀한 평가가 가능하다:
ConvNet을 crop에 적용하면, padding을 하지 않는다, 반면 dense evaluation의 경우 같은 crop에 대한 padding은 이미지의 이웃 부분에서 합성곱과 공간 pooling으로 자연스럽게 생긴다, 그래서 실질적으로 전반적인 네트워크의 수용영역이 커지고 많은 context가 capture된다.</p>

<p>multiple crops로 인한 계산 시간 증가는 실제로 정확도를 올리지 못한다고 생각하지만,
추론을 위해 네트워크를 스케일당 50crop(5x5 regular grid with 2flips)을 사용해 평가했다.
이때 Szegedy의 4 스케일에 걸친 144crops에 비교할만한 3스케일에 걸쳐 150crops를 평가함.</p>

<h2 id="33-implementation-details">3.3 Implementation Details</h2>

<p>구현은 C++ Caffe toolbox를 사용했다.</p>

<p>대신 충분히 많은 변경사항을 적용했다.</p>

<p>여러개의 GPU를 하나의 시스템에 설치하여 학습과 평가를 수행하고
학습과 평가는 자르지 않은 전체 사이즈의 이미지를 여러개의 크기인 상태로 진행했다.</p>

<p>다중 GPU 학습은 데이터의 수평성을 이용하여 각 학습 이미지의 batch를 몇개의 GPU batch로 나누어 수행했다.</p>

<p>GPU batch gradient가 계산되고 난 뒤,
그들 전체 batch의 gradient를 얻기 위해 평균 계산을 했다.</p>

<p>Gradient계산은 GPU들 사이에서 동시에 일어나서 결과는 한개의 GPU를 사용한 경우와 같게 나온다.</p>

<p>ConvNet의 학습 속도를 높이는 많은 정교한 방법들이 제안되었지만(네트워크에서 다른 계층에 모델과 데이터의 병렬 처리),
개념적으로 더 간단한 내용인 우리 네트워크가 한개의 GPU보다 4개의 GPU로 학습해서 3.75배의 속도 향상을 시켰다.</p>

<p>4개의 NVIDIA Titan Black GPU를 장착한 시스템에서 하나의 네트워크를 학습 시키는 경우 구조에 따라 2-3주가 걸렸다.</p>

<h1 id="4-classification-experiments">4. Classification Experiments</h1>

<h3 id="dataset">Dataset</h3>

<p>4장에서는 이미지 분류 결과 얻기 위해 ILSVRC 2012-2014에 사용된 데이터를 사용했다.</p>

<p>데이터에는 1000개의 클래스가 있고
130만개의 학습 데이터셋과 validation을 위한 5만개 그리고 평가를 위한 10만개로 나눴다.</p>

<p>분류 성능 평가는 top-1과 top-5를 통해 이루어졌다.</p>

<p>top-1은 잘못 분류된 이미지의 비율을 구하고;
top-5는 ILSVRC에서 주로 사용하는 평가 기준으로 예측한 5개의 범주에 실제 class가 있는 비율을 계산한다.</p>

<p>대부분의 실험을 위해, validation set을 test set으로 사용했다.</p>

<p>특정 실험들은 test set을 사용했고
ILSVRC-2014에 “VGG”팀으로 입상하여 ILSVRC서버에 공식적으로 제출됐다.</p>

<h2 id="41-single-scale-evaluation">4.1 Single Scale Evaluation</h2>

<p>각 모델을 single scale로 성능을 평가한다.</p>

<p>test 이미지의 크기는 
$Q=S=0.5(S_{min}+S_{max})$로 설정했다.</p>

<p>먼저, local response normalisation은 normalisation층이 없는 모델 A를 향상시키지 못했기 때문에 다른 더 깊은 구조에도 normalisation을 적용하지 않았다.</p>

<p>다음으로, ConvNet이 깊어질수록 classification error가 감소하는 것을 관찰했다 :
A의 11층부터 E의 19층까지 실험했다.</p>

<p>같은 깊이임에도, C(1x1 conv)가 D(3x3 conv)보다 성능이 안좋았다.</p>

<p>C&gt;B : 추가적인 non-linearity가 도움이 된다</p>

<p>D&gt;C : trivial 하지않은(1보다 크기가 큰)합성곱 필터를 사용해 capture spatial context하는 것도 중요하다.</p>

<p>error rate는 모델의 깊이가 19층일 때 포화 되었지만 더 깊은 모델은 더 큰 데이터셋에서 효과적일지 모른다.</p>

<p>또한 B와 B의 3x3 필터를 쓰는 합성곱층의 쌍을 5x5 필터를 쓰는 합성곱으로 대체한 네트워크와 비교를 해보았다.</p>

<p>얕아진 네트워크의 top-1 error가 B보다 7% 높아진것으로 보아
깊고 작은 필터를 사용한 네트워크가 얕고 큰 필터를 사용한 네트워크보다 뛰어나다는 것을 확인했다.</p>

<p>마지막으로, 학습할 때 $S\in[256;512]$에서 scale jittering 하게 되면 test time에서 single scale을 사용하더라도 S가 256이나 384로 고정된 값을 갖는 것 보다 상당히 더 좋은 결과를 보인다.</p>

<p>따라서 training set augmentation by scale jittering은 capturing multi-scale image statistics에 도움을 준다는 것을 알 수 있다.</p>

<p><img src="/assets/img/Paper_Review/VGGNet/VGGNet1.png" alt="VGGNet1" /></p>

<h2 id="42-multi-scale-evaluation">4.2 Multi-Scale Evaluation</h2>

<p>ConvNet 모델을 single scale로 평가한 후,
scale jittering이 test time에 미치는 영향을 평가해보겠다.</p>

<p>이것은 모델을 Q를 다른값들로 바꿔보는 것과 같이 test image를 여러 크기의 버전으로 모델을 실행시킨다, 그 다음에 결과 클래스의 posterior에 대해 평균을 계산한다.</p>

<p>training고 testing scale의 차이가 성능저하를 일으킨다는 점을 고려하여 고정된 S로 학습한 모델들을 S와 비슷한 3개의 Q로 평가 했다 :
$Q=\left{S-32,\ S,\ S+32\right}$</p>

<p>동시에, 학습 때 scale jittering은 네트워크가 test time에서 광범위한 크기에 적용되도록 하기 때문에 모델은 $S\in\left[S_{min};S_{max}\right]$인 다양성으로 학습하고 
$Q=\left{S_{min},\ 0.5(S_{min}+S_{max}),\ S_{max}\right}$
로 더 큰 범위에 걸쳐 평가했다.</p>

<p>결과를 보면 test time에서 scale jittering은 더 좋은 성능으로 이끈다(같은 모델을 single scale에서 평가한것과 비교하여).</p>

<p>이전처럼, 더 깊은 네트워크(D and E)가 최고의 성능을 보여주고 scale jittering으로 학습한 것은 고정된 S로 학습한 모델보다 더 좋다.</p>

<p>가장 좋은 네트워크 성능은 validation에서 top-1 : 24.8% / top-5 : 7.5%이다.</p>

<p>test set에서 E 네트워크의 top-5 error는 7.3%가 나왔다.</p>

<p><img src="/assets/img/Paper_Review/VGGNet/VGGNet2.png" alt="VGGNet2" /></p>

<h2 id="43-multi-crop-evaluation">4.3 Multi-Crop Evaluation</h2>

<p>dense ConvNet evaluation과 mult-crop evaluation을 비교했다.</p>

<p>또한, 이 둘의 soft-max 결과를 평균내어 두가지 방법을 보완한 방법도 평가했다.</p>

<p>보이는 바와 같이 multiple crops를 사용해 평가하게 되면 dense evaluation보다 더 좋은 결과가 나오고 두가지를 조합해서 사용하면 더 좋은 결과가 나온다.</p>

<p>위에서 말했듯이 이것은 합성곱 결정 조건이 다르게 나타나기 때문이다.</p>

<p><img src="/assets/img/Paper_Review/VGGNet/VGGNet3.png" alt="VGGNet3" /></p>

<h2 id="44-convnet-fusion">4.4 ConvNet Fusion</h2>

<p>지금까지, 각 ConvNet별로 성능을 평가했다.</p>

<p>이번에는 몇가지 모델의 soft-max class posteriors를 평균내어 결과를 조합해보겠다.</p>

<p>이 과정은 모델들을 보완해주기 때문에 성능을 개선시키고 ILSVRC-2012에서 Krizhevsky가 사용했었고 2013에는 Zeiler&amp;Fergus가 사용했다.</p>

<p>ILSVRC 제출 당시 우리는 single-scale 네트워크와 multi-scale model D(전결합 층만 미세조정을 한)만 학습 시켰다.</p>

<p>7개의 네트워크를 조합한 결과 ILSVRC test error는 7.3%였다.</p>

<p>그 뒤, multi-scale 모델중 최고 성능을 보이는 D와 E만 조합했더니 test error는 dense evaluation에서 7.0%이고 dense와 multi-crop을 합쳐서 평가하니 6.8%였다.</p>

<p>참고로 가장 좋은 single model 은 7.1%의 error를 보였다.</p>

<p><img src="/assets/img/Paper_Review/VGGNet/VGGNet4.png" alt="VGGNet4" /></p>

<h2 id="45-comparison-with-the-state-of-the-art">4.5 Comparison with the State-of-the-art</h2>

<p>마지막으로, 우리의 결과를 최신 기술과 비교해 보겠다.</p>

<p>ILSVRC-2014때 분류작업에서, VGG팀은 7개의 모델을 조합해서 7.3%의 test error를 나타내며 2등을 차지했다.</p>

<p>그 뒤, 우리는 D&amp;E의 조합으로 error를 6.8까지 낮췄다.</p>

<p>결과에서 보이듯 이전 세대(ILSVRC-2012,2013)의 최고 모델과 비교해 상당히 좋은 결과를 우리 very deep ConvNet이 달성했다.</p>

<p>우리의 결과는 분류작업 우승자인 GoogLeNet(6.7%)과 비교할 수 있을정도이고
실제로 ILSVRC-2013의 우승자 Clarifai(외부 학습 데이터로 11.2% 외부학습 데이터 없이 11.7%)를 능가했다.</p>

<p>ILSVRC에 제출된 대부분의 모델들보다 상당히 적은 양인 2개의 모델을 조합해서 얻은 최고의 결과라는 점에서 매우 놀랍다.</p>

<p>single-net performance를 보면, 우리의 구조가 최고의 결과를 달성한다(test error 7.0%), single GoogLeNet를 0.9% 능가하는 수치다.</p>

<p>참고로, 우리는 LeCun의 구조에서 많이 벗어나지 않고 실질적으로 깊이만 증가시켰다.</p>

<p><img src="/assets/img/Paper_Review/VGGNet/VGGNet5.png" alt="VGGNet5" /></p>

<h1 id="5-conclusion">5. Conclusion</h1>

<p>이번 연구에서 우리는 매우 깊은 신경망(최대 19의 가중치 층)을 대규모 이미지 분류를 통해 평가했다.</p>

<p>이것으로 표현깊이는 분류 정확도에 이점이 된다는 것과
ImageNet challenge dataset에서 최첨단 모델의 성능은 ConvNet구조의 실질적 깊이를 깊게 함으로써 얻을 수 있다는 것을 확인했다.</p>

<p>부록에서, 우리는 또한 우리의 모델이 광범위한 작업과 data set으로 잘 일반화되어 덜 깊은 구조로 구축된 더 복잡한 인식 파이프라인과 성능이 같거나 능가한다는 것을 보였다.</p>

<p>이 결과로 visual representation에서 depth의 중요성을 다시한번 확인했다.</p>]]></content><author><name>Chang Hun Kang</name></author><category term="[&quot;Paper Review&quot;]" /><summary type="html"><![CDATA[VGGNet]]></summary></entry></feed>