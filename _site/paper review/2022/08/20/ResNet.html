<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>ResNet | No Free Knowledge</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="ResNet" />
<meta name="author" content="Chang Hun Kang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="ResNet" />
<meta property="og:description" content="ResNet" />
<link rel="canonical" href="http://localhost:4000/paper%20review/2022/08/20/ResNet.html" />
<meta property="og:url" content="http://localhost:4000/paper%20review/2022/08/20/ResNet.html" />
<meta property="og:site_name" content="No Free Knowledge" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-20T03:37:25+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="ResNet" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Chang Hun Kang"},"dateModified":"2022-08-20T03:37:25+09:00","datePublished":"2022-08-20T03:37:25+09:00","description":"ResNet","headline":"ResNet","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/paper%20review/2022/08/20/ResNet.html"},"url":"http://localhost:4000/paper%20review/2022/08/20/ResNet.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="No Free Knowledge" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">No Free Knowledge</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/categories/DeepLearning%20from%20scratch.html">DeepLearning from scratch</a><a class="page-link" href="/categories/Paper%20Review.html">Paper Review</a><a class="page-link" href="/categories/Project.html">Project</a><a class="page-link" href="/">All Documents</a></div>
      </nav></div>
</header>
<div class="container">
      <div>
        


<div class="category_box">
    <h2> CATEGORY </h2>
    <ul>
          
                
                <li><a href=" http://localhost:4000/categories/DeepLearning from scratch "> DeepLearning from scratch     </a></li>
                <br/>
          
                
                <li><a href=" http://localhost:4000/categories/Paper Review "> Paper Review     </a></li>
                <br/>
        
    </ul>
</div>
      </div>
      <main class="page-content" aria-label="Content">
        <div class="wrapper">
          <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML">
  MathJax.Hub.Config({
    "HTML-CSS": {
      availableFonts: ["TeX"],
    },
    tex2jax: {
      inlineMath: [['$','$'],["\\(","\\)"]]},
      displayMath: [ ['$$','$$'], ['\[','\]'] ],
    TeX: {
      extensions: ["AMSmath.js", "AMSsymbols.js", "color.js"],
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    showProcessingMessages: false,
    messageStyle: "none",
    imageFont: null,
    "AssistiveMML": { disabled: true }
  });
</script>
<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">ResNet</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2022-08-20T03:37:25+09:00" itemprop="datePublished">Aug 20, 2022
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="resnet">ResNet</h1>

<h1 id="deep-redisual-learning-for-image-recognition">Deep Redisual Learning for Image Recognition</h1>

<h1 id="1-introduction">1. Introduction</h1>

<p>깊은 CNN들은 이미지 분류의 돌파구를 만든다.</p>

<p>깊은 네트워크들은 end-to-end 다층 구조에서 low/mid/high 수준의 특징과 분류기들을 통합하는 본성이 있고
층이 쌓일수록(깊이가 깊어질수록) 특징의”단계”는 풍부해진다.</p>

<p>최근 밝혀진 바에 의하면 네트워크의 깊이는 아주 중요하고 까다로운 ImageNet 데이터셋의 선두 결과들은 모두 “매우 깊은” 모델들(16~30 깊이의 모델)을 활용한다고 한다.</p>

<p>다른 많은 nontrivial visual recognition 작업들도 매우 깊은 모델들로부터 좋은 결과를 얻을 수 있다.</p>

<p>깊이의 중요성으로부터 생긴 질문 : 
층을 더 많이 쌓는다고 네트워크가 더 좋은 학습을 하는가?</p>

<p>이 질문을 해결할 때 만나는 장애물은 유명한 문제인 vanishing/exploding gradients(처음부터 수렴을 방해하는 문제)이다.</p>

<p>그러나, normalize된 초기값과 네트워크 중간에 normalization 층을 끼워넣는 방법으로
(수십개의 층을 가진 네트워크가 역전파 방법을 통해 SGD optimizer로 수렴을 시작할 수 있도록 하는 방법)
이 문제는 크게 해결이 되어왔다.</p>

<p>깊은 네트워크들이 수렴하기 시작할 때,
degradation 문제가 생긴다 : 
네트워크의 깊이가 증가하면서 정확도가 (당연하게도)포화되는것인데
그렇게 되면 점점 정확도가 낮아진다.</p>

<p>뜻밖에도, 이러한 degradation은 과적합에 의한 문제가 아니고
적당히 깊은 모델이 더 깊어지도록 층을 추가하는 행위가 높은 training error 를 갖게하는 것이다.</p>

<p><img src="/assets/img/ResNet/ResNet0.png" alt="ResNet0" /></p>

<p>(학습 정확도의) degradation은 모든 시스템들이 optimize하기 쉬운건 아니라는 것을 보여준다.</p>

<p>우리는 얕은 구조와 그것을 복사하고 층을 몇개 추가한 모델을 고려했다.</p>

<p>구조에 있어서 깊은 모델에 solution이 존재한다 :
추가된 층들은 identity mapping이고
다른 층들은 학습된 얕은 모델을 복사하는 것이다.</p>

<p>이 구성으로 얻은 해결책에 의해
더 깊은 모델이 얕은 것보다 더 높은 훈련 오류를 발생해서는 안 된다는 것을 나타낸다.</p>

<p>하지만 실험에서 보여지듯 현재로써
이 구조로 인한 해결책과 비교해서 더 좋은 해결책은 찾지 못했다.</p>

<p>이 논문에서, degradation문제를 해결하기 위해 ‘deep residual learning framework’를 소개할 것이다.</p>

<p>쌓인 층들이 각각 직접 바라는 층과 mapping 되는것을 바라기 보다, 이 층들이 residual mapping에 fit 되도록 했다.</p>

<p>공식적으로, desired underlying mapping을 $H(x)$라고 하고, 비 선형 층들을 쌓은 묶음이 $F(x):=H(x)-x$와 mapping되게 했다.</p>

<p>원래 mapping은 $F(x)+x$로 변환된다.</p>

<p>residual mapping을 optimize하는 것이
original mapping보다 optimize하는 것 보다 더 쉽다.</p>

<p>극단적으로, 만약 하나의 identity mapping이 최적이라면, 비선형 층을 쌓은 identity mapping을 fit 시키는것보다 residual을 0으로 만드는게 더 쉬울 것이다.</p>

<p>$F(x)+x$라는 식은 “shortcut connections”를 통해 신경망의 feedforward에 의해 알 수 있을 것이다.</p>

<p><img src="/assets/img/ResNet/ResNet1.png" alt="ResNet1" /></p>

<p>Shortcut connections는 하나 이상의 층을 skip하는 것이다.</p>

<p>우리의 경우, shortcut connections는 단순히 identity mapping을 수행하고 그것들의 출력은 stacked layers의 출력에 더해진다.</p>

<p>Identity shortcut connections는 추가 매개변수도 없고 추가적인 계산복잡도도 없다.</p>

<p>전체 네트워크는 여전히 처음부터 끝까지 역전파와 SGD로 학습이 가능하고
라이브러리를 변형시키지 않고 쉽게 구현할 수 있다.</p>

<p>ImageNet에서 포괄적인 실험을 하여 degradation 문제도 증명하고 우리의 방법도 평가했다.</p>

<p>우리는 두가지를 증명한다</p>

<ol>
  <li>extremely deep residual net은 optimize가 쉽지만
단순히 층을 쌓아 만든 같은 네트워크는 깊이가 깊어지게 되면 학습오차가 커진다는 것</li>
  <li>deep residual net은 증가된 깊이에서 쉽게 정확도를 얻을 수 있어
이전 네트워크들과 비교해 더 나은 결과를 제공한다.</li>
</ol>

<p>비슷한 현상들을 CIFAR-10에서 볼 수 있다,
그러나 최적화 어려움과 우리 방법의 효과는 특정 데이터셋과 연관이 있지 않다.</p>

<p>100개 이상의 층을 가진 모델로 이 데이터를 학습시키고,
1000개 이상의 층을 가진 모델을 연구해 볼 것이다.</p>

<p>ImageNet 분류 데이터셋에서, extremely deep residual net을 통해 훌륭한 결과를 얻었다.</p>

<p>152층의 residual net은 VGG net보다 낮은 복잡도를 가지면서 ImageNet에 보고된 네트워크들 중에서 가장 깊은 네트워크이다.</p>

<p>ImageNet test set에서 조합을 통해 3.57%의 top-5 error를 얻었고 ILSVRC-2015 classification 대회에서 1등을 차지했다.</p>

<p>extremely deep한 표현은 generalization성능도 뛰어나다(다른 인식 작업에서도),
그리고 ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation in ILSVRC &amp; COCO2015 competitions.</p>

<p>따라서 residual learning principle은 vision problem과 non-vision problem에 모두 일반적으로 사용될 수 있을것이다.</p>

<h1 id="2-related-work">2. Related Work</h1>

<h2 id="residual-representations">Residual Representations</h2>

<p>이미지 인식에서, VLAD는 Residual vector를 dictionary로 인코딩 하는 표현법이고
Fisher Vector는 VLAD를 확률적으로 공식화한 것이다.</p>

<p>둘 다 이미지 retrieval과 분류에서 강력한 얕은 표현 방법이다.</p>

<p>vector 양자화에서 residual vector의 인코딩은
원래 vector의 인코딩보다 더 효과적이다.</p>

<p>Partial Difference Equations 분야에 low-level vision과 computer graphics에서 널리 사용되는 Multigrid method는 문제를 시스템을 여러개의 크기의 subproblem으로 나눈다.</p>

<p>Multigrid의 대체 방안은 hierarchical basis preconditioning이다.(두 scale사이의 residual vector를 표현하는 변수에 의존하는 preconditioning)</p>

<p>이 방법은 표준적인 것과 비교해 더 빠르게 수렴한다.</p>

<p>이 방법들은 좋은 reformulation과 preconditioning은 optimization을 단순화 시킨다고 한다.</p>

<h2 id="shortcut-connections">Shortcut Connections</h2>

<p>shortcut connections를 말하는 실험들과 이론들은 오랫동안 연구되어왔다.</p>

<p>MLP의 초기 연구는 선형층이 네트워크의 입력부터 출력까지 구성하도록 하는 것이다.</p>

<p>몇개의 중간 층들은 vanishing/exploding gradient문제를 다루기 위해 보조 분류기에 직접 연결된다.</p>

<p>몇몇 논문들은 shortcut connections를 구현해서 레이어 반응, gradients, 전파 오류를 중심으로 하는 방법을 제안한다.</p>

<p>“inception” 층은 shortcut 가지와 몇개의 deeper 가지로 구성된다.</p>

<p>이 논문과 동시에, “highway networks”는 gating 기능이 있는 shortcut connections를 보여준다.</p>

<p>이 gate들은 데이터에 종속적이고 가중치가 있다,
반대로 identity shorcut은 가중치가 필요없다.</p>

<p>gated shortcut이 닫히면(0이되는 순간),
highway networks의 층들은 non-residual 기능을 보인다.</p>

<p>반대로, 우리의 식은 항상 residual 기능을 학습한다;
identity shortcut은 절대 닫히지 않는다,
그리고 모든 정보들은 항상 학습되어야 하는 추가적인 residual 함수들을 통과한다.</p>

<p>추가로, highway networks는 극도로 증가된 깊이(100이상 깊이)로 인한 정확도 증가를 증명하지 못했다.</p>

<h1 id="3-deep-residual-learning">3. Deep Residual Learning</h1>

<h2 id="31-residual-learning">3.1 Residual Learning</h2>

<p>몇개의 층이 쌓여 mapping되는 함수를 $H(x)$라고 하자,
$x$는 이 층들의 입력값이다.</p>

<p>만약 여러개의 비선형 층들로 복잡한 기능을 구현할 수 있다면,
마찬가지로 residual function으로도 복잡한 기능을 할 수 있을 것이다.  $H(x)-x$</p>

<p>그러니 쌓여있는 층들이 $H(x)$에 비슷해지는게 아니라
우리는 $F(x):=H(x)-x$가 되게 할 것이다.</p>

<p>그러므로 원래 함수는 $F(x)+x$가 될것이다.</p>

<p>두가지 형식 모두 요구되는 기능으로 근사될 것이지만,
학습 난이도는 다를 것이다.</p>

<p>이 식은 degradation문제에서 counterintuitive phenomena로부터 영감을 받은 것이다.</p>

<p>앞서 말했듯, 추가적인 층들이 identity mapping 구조를 띈다면,
더 깊은 모델은 복사본인 얕은 모델보다 학습오차율이 더 클 수 없다.</p>

<p>degradation문제는 solver가 여러개의 비선형층으로 이루어진 구조에서 identity mapping을 유추하는데에 어려움을 줄것이다.</p>

<p>residual learning reformulation에서
만약 identity mapping이 최적이라면,
solver들은 다층 비선형 구조가 identity mapping이 0을 향해 근접할 수 있도록 가중치를 움직일 것이다.</p>

<p>실제로는, identity mapping은 최적이지만 우리의 reformulation은 문제가 발생하도록 돕는 것이된다.</p>

<p>만약 최적의 함수가 zero mapping이 아니라 identity mapping이라면,
새로운 함수 하나를 학습하는 것 보다 identity mapping으로 방해요인을 찾는게 더 쉬울 것이다.</p>

<p>우리는 identity mappings가 합리적인 preconditioning을 제공하기 때문에
실험적으로 학습된 residual 함수들이 일반적으로 반응이 작다는 것을 증명했다,</p>

<h2 id="32-identity-mapping-by-shortcuts">3.2 Identity Mapping by Shortcuts</h2>

<p>우리는 모든 stacked layers에 residual learning을 도입했다.</p>

<p>공식적으로 이번 논문에서 우리가 만든 block은 아래와 같다</p>

\[y=F(x,\left\{W_i\right\})+x\]

<p>x랑 y는 각각 입력과 출력 벡터이다.</p>

<p>함수 F(x,{Wi})는 학습 되어야 하는 residual mapping을 의미한다.</p>

<p>예를들어</p>

<p><img src="/assets/img/ResNet/ResNet1.png" alt="ResNet1" /></p>

<p>이 구조는</p>

\[F=W_2\sigma(W_1\mathbf{x})\]

<p>가 되고 여기서 $\sigma$는 ReLU이고 편향은 표기의 단순화를 위해 제거했다.</p>

<p>수식 $F+x$는 shortcut connection에 의해 수ㅐㅎㅇ되고
element-wise addition이다.</p>

<p>두번째 비선형성은 $F+x$ 후에 계산된다.(i.e., $\sigma(y))$</p>

<p>앞에서 봤듯 shortcut connection은 계산 복잡도도 안올라가고 추가적인 가중치도 필요없다.</p>

<p>실로 매력적일 뿐 아니라 plain network와 residual network의 비교에 중요하다.</p>

<p>공정하게 plain과 residual net을 비교할 것이다.
같은 가중치 수, 깊이, 크기 그리고 element-wise addition을 제외한 계산비용까지 모두 같게하여 비교할 것이다.</p>

<p>x와 F의 차원은 반드시 같아야 한다.</p>

<p>만약 이런 경우가 아니라면(예를들어 입력과 출력의 채널을 변경하는 것),
우리는 shortcut connections의 차원을 맞추기 위해 $W_s$를 사용해 linear projection을 할 것이다.</p>

\[y=F(x,\{W_i\})+W_sx\]

<p>또한 정방행렬 $W_s$를 사용할 수도 있다.</p>

<p>하지만 우리는 실험적으로 identity mapping이 충분히 degradation문제를 다룰 수 있고 경제적임을 보일 것이다.(따라서 $W_s$는 차원을 맞추기 위해서만 사용될 것이다.)</p>

<p>residual function F는 유연하다.</p>

<p>이 논문의 실험에는 두세층이 포함된 F를 실험한다.
(더 많은 층들도 가능하다)</p>

<p>하지만 만약 F가 단층이라면</p>

\[y=F(x,\{W_i\})+x\]

<p>는 선형 식이 될것이다.</p>

\[y=W_1x+x\]

<p>위 식에서는 어떤 이점도 찾을 수 없다.</p>

<p>또한 우리는 단순함을 위해 전결합을 사용했지만,
residual은 합성곱 층에서도 사용 가능하다.</p>

<p>$F(z,{W_i})$는 여러 합성곱층을 표현할 수 있다.</p>

<p>element-wise addition은 두 feature map 사이에서 이루어지고
channel별로 이루어진다.</p>

<h2 id="33-network-architectures">3.3 Network Architectures</h2>

<p>다양한 plain/residual net들을 실험해보고
일관적인 현상들을 관찰했다.</p>

<p>사례를 위해 ImageNet을 위한 두가지 모델을 설명하겠다.</p>

<h2 id="plain-network">Plain Network</h2>

<p>VGG net의 이론에서 영감을 받아 plain 네트워크 구조를 만들었다.</p>

<p>합성곱층은 최대 3x3크기의 필터와 두가지 간단한 규칙을 따른다.</p>

<ol>
  <li>output feature map size가 동일하기 위해,
층들은 같은 수의 filter를 갖는다.</li>
  <li>만약 feature map size가 반으로 준다면,
filter의 수를 두배로 해서 층마다 시간 복잡도를 유지한다.</li>
</ol>

<p>downsampling은 합성곱층에서 stride를 2로 설정해서 수행한다.</p>

<p>네트워크는 global average pooling layer와 softmax를 사용하는 1000-way 전결합층으로 마무리된다.</p>

<p>가중치층의 총 수는 34개이다.</p>

<p>Plain Network는 VGG net보다 필터 수도 적고 복잡성도 낮다는것은 주목할 만하다.</p>

<p>34개의 층들은 36억개의 FLOPs(multiply-add)가 필요하고
이는 196억개의 FLOPs인 VGG-19의 18%에 해당하는 수치이다.</p>

<p><img src="/assets/img/ResNet/ResNet2.png" alt="ResNet2" /></p>

<h2 id="residual-network">Residual Network</h2>

<p>Plain net을 기반으로, shortcut connections를 추가해 Plain과 같은 부분을 residual 로 만들었다.</p>

<p>왼쪽에서 실선 shortcut connections처럼 입력과 출력의 차원이 같다면 identity shortcut 을 바로 사용할 수 있다.</p>

<p>차원이 증가하는 경우에는 점선으로된 shortcut connections처럼표현하고 두가지 경우를 고려한다.</p>

<ol>
  <li>shortcut은 여전히 identity mapping을 수행한다.
zero padding을 통해 차원을 늘려서 사용한다.
이 방법은 추가적인 매개변수가 없다</li>
  <li>projection shortcut은 차원을 일치시킬 때 사용된다.(1x1합성곱으로 완성)</li>
</ol>

<p>두개의 크기인 feature map을 통과할 때 두가지 경우 모두 stride=2로 수행한다.</p>

<h2 id="34-implementation">3.4 Implementation</h2>

<p>이미지는 scale augmentation을 위해 256~480에서 임의로 선택된 값으로 짧은 부분을 resize한다.</p>

<p>224,224 crop은 이미지로부터 임의로 sample을 구하거나
horizontal flip(각 pixel에 평균값을 빼는 것까지)을 통해서 도 sample을 취한다.</p>

<p>표준 color augmentation도 사용되었다.</p>

<p>convolution연산 뒤에 activation연산 전에 BatchNormalization(BN)을 사용했다.</p>

<p>가중치는 13번 논문을 따라서 초기화시켰고
네트워크는 처음부터 학습시켰다.</p>

<p>SGD를 mini-batch size 256으로 사용했다</p>

<p>Learning rate는 0.1부터 시작해서 error plateau일 때마다10씩 나눴다.</p>

<p>학습은 600000번만큼 iteration했다.</p>

<p>weight decay는 0.0001을 사용하고
momentum계수는 0.9로 했다.</p>

<p>Dropout층은 사용하지 않았다.</p>

<p>test에서는 연구의 비교를 위해 표준적으로 10-crop testing을 했다.</p>

<p>최고의 결과를 위해 fully-convolutional form을 사용했고
이미지의 짧은 축의 크기를 224,256,384,480,640으로 설정한 여러개의 크기에서 계산을 하고 결과를 평균내었다.</p>

<h1 id="4-experiments">4. Experiments</h1>

<h2 id="41-imagenet-classification">4.1 ImageNet Classification</h2>

<p>네트워크 평가를 위해 1000개의 클래스로 구성된 ImageNet 2012 classification dataset을 사용했다.</p>

<p>모델들은 128만개의 학습 이미지를 통해 학습하고
5만개의 validation 이미지로 평가됐다.</p>

<p>또한, 최종 결과는 10만개의 test image를 통해 얻었ek.</p>

<p>top-1, top-5 error rate를 계산했다.</p>

<h3 id="plain-networks">Plain Networks</h3>

<p>18-layer와 34-layer를 평가했다.</p>

<p><img src="/assets/img/ResNet/ResNet3.png" alt="ResNet3" /></p>

<p>Downsampling은 conv3_1,conv4_1,conv5_1에서도 stride 2로 진행된다</p>

<p>아래 결과를 보면 더 깊은 34-layer가 얕은 18-layer보다 validation error가 더 큰 것을 알 수 있다.</p>

<p><img src="/assets/img/ResNet/ResNet4.png" alt="ResNet4" /></p>

<p>얇은 선은 training error, 굵은 선은 validation error</p>

<p>이유를 알아보기 위해 학습과정에서 training/validation error를 확인해 보니 degradation 문제가 생긴것을 확인했다.</p>

<p>왜냐하면 학습 전체 과정에서 34-layer의 학습오차가 18-layer보다 항상 높았기 때문이다.
심지어 18-layer의 해공간이 34-layer의 해공간의 하위 집합이었음에도 이러한 결과가 나타났다.</p>

<p>이런 optimize difficulty는 불행하게도 vanishing gradient 때문에 발생한다.</p>

<p>plain net들은 전파 과정에서 0이 아닌 분산값을 갖게 하도록
BN을 사용했다.</p>

<p>또한, 역전파에서 gradient들은 BN을 통해 좋은 정규화가 이루어진 것을 증명할 수 있다.</p>

<p>따라서 순전파와 역전파 모두 신호를 소실시키지 않았다.</p>

<p>사실 34-layer plain net은 여전히 경쟁적인 정확도를 달성할 수 있다. (solver가 어느정도 작동한다면)</p>

<p>deep plain net들은 매우 낮은 비율로 수렴하기 때문에 training error를 낮추는데 영향을 준다.</p>

<p>이러한 optimization difficulties는 후에 연구될 것이다.</p>

<h3 id="residual-networks">Residual Networks</h3>

<p>다음으로 18-layer와 34-layer residual nets(ResNets)를 평가했다.</p>

<p>기본 구조는 plain net과 같고 3x3 filter쌍마다 shortcut connection이 추가 되어있다.</p>

<p>아래 비교에서 모든 shortcut 에 identity mapping을 적용했고
차원을 높이기 위해 zero-padding을 했다.</p>

<p>따라서 plain net과 비교해 추가적인 매개변수가 없다.</p>

<p><img src="/assets/img/ResNet/ResNet5.png" alt="ResNet5" /></p>

<p>얇은 선은 training error, 굵은 선은 validation error</p>

<p><img src="/assets/img/ResNet/ResNet6.png" alt="ResNet6" /></p>

<p>위 결과로부터 3가지 주요 관찰할 것을 얻었다.</p>

<h3 id="residual-학습을-통해-상황이-반대가-되었다">Residual 학습을 통해 상황이 반대가 되었다.</h3>

<p>residual 학습으로 34-layer의 결과가 18-layer의 결과보다 좋게 나왔다.</p>

<p>더 중요한 것은 34-layer ResNet은 상당히 낮은 training error를 보이고 validation data에 범용성을 갖췄다.</p>

<p>이것은 degradation문제가 이번 setting으로 잘 해결이 되고
또 깊은 구조의 네트워크로부터 높은 정확도를 얻었다는 것을 의미한다.</p>

<h3 id="plain-net과-resnet을-비교했을-때">plain net과 ResNet을 비교했을 때,</h3>
<p>34-layer ResNet은 top-1 error가 줄었다는 것이다.</p>

<p><img src="/assets/img//ResNet/ResNet7.png" alt="ResNet7" /></p>

<p><img src="/assets/img/ResNet/ResNet8.png" alt="ResNet8" /></p>

<p><img src="/assets/img/ResNet/ResNet9.png" alt="ResNet9" /></p>

<p>이러한 비교는 extremely deep system에서 residual learning의 효과를 입증한다.</p>

<p>마지막으로, 18-layer Plagin/Residual net들은 비슷한 정확도를 보이지만
18-layer ResNet이 더 빠르게 수렴한다.</p>

<p>network가 지나치게 깊지 않은 경우(여기서는 18-layer)
SGD는 계속해서 좋은 solution을 Plain net에 찾아줄 수 있다.</p>

<p>이 경우, ResNet은 더 빠른 단계에서 수렴을 하도록 하기 때문에 optimization이 쉬워진다.</p>

<h3 id="identity-vs-projection-shorcuts">Identity vs. Projection Shorcuts</h3>

<p>추가 매개변수가 없는것과 identity shorcuts는 학습을 돕는다고 증명했다.</p>

<p>다음으로는 projection shortcut을 살펴보겠다.</p>

<p><img src="/assets/img/ResNet/ResNet7.png" alt="ResNet7" /></p>

<p>Table 3에서 세가지 옵션들을 비교했다.</p>

<p>(A) 차원의 증가를 위해 zero-padding을 사용하고
모든 shortcut을 identity mapping으로 구현해 추가 매개변수가 없게 함.</p>

<p>(B) projection shortcut을 사용해 차원을 증가시키고
다른 shortcut들은 identity를 사용했다.</p>

<p>(C) 모든 shortcut들을 projection으로 사용했다.</p>

<p>Table 3에서 볼 수 있듯이 세가지 옵션 모두 plain net과 비교해 상당히 좋은 결과를 만든다.</p>

<p>B가 A보다 약간 더 좋은데
A에서 zero-padding으로 늘어난 차원이 사실 residual learning이 아니기 때문이다.</p>

<p>C는 B보다 조금 더 좋은데
projection shortcut에 의해 매개변수가 더 추가 되었기 때문이라고 생각한다.</p>

<p>하지만, A/B/C 사이에 차이가 작은 것은 projection shortcut이 degradation 문제를 다루는데 필수적인 것은 아니라는 것을 나타낸다.</p>

<p>따라서 이 논문의 나머지 부분에서는 C를 사용하지 않는다.
(메모리사용량과 시간 복잡도와 모델의 크기를 줄이기 위해)</p>

<p>Identity shortcut들은 bottleneck 구조의 복잡도를 증가시키지 않기 때문에 특히 중요하다.</p>

<h3 id="deeper-bootleneck-architectures">Deeper Bootleneck Architectures</h3>

<p>다음으로 더 깊은 구조를 보겠다.</p>

<p>사용할 수 있는 학습시간에 대한 염려로 인해,
building block을 bottleneck 구조로 변경했다.</p>

<p>(non-bottleneck ResNet도 좋은 정확도를 보이지만
경제적이지 못해 bottleneck ResNet을 사용한다.
따라서 bottleneck ResNet을 사용하는 이유는 practical consideration 때문인 것이다.)</p>

<p>각 residual function F에 층을 3개씩 샇았다.</p>

<p>3개의 층은 1x1,3x3,1x1 합성곱을 한다.</p>

<p>1x1 합성곱은 차원을 줄였다가 다시 키우는 역할을 하며
3x3 합성곱은 작은 차원의 입출력에 대해 병목현상을 일으킨다.</p>

<p>bottleneck과 non-bottleneck 모두 시간 복잡도는 비슷하다.</p>

<p><img src="/assets/img/ResNet/ResNet10.png" alt="ResNet10" /></p>

<p>매개변수가 추가되지 않는 identity shortcuts는 병목 구조에서
특히 더 중요하다.</p>

<p>만약 identity shortcut이 projection으로 대체된다면,
시간복잡도와 모델 크기가 두배가 될것이다.
마치 shortcut이 두개의 높은 차원과 연결된것처럼</p>

<p>따라서 identity shortcut은 bottleneck 구조를 더 효율적으로 만든다.</p>

<h3 id="50-layer-resnet">50-layer ResNet</h3>

<p>34-layer net에서 두개의 layer block을 3-layer bottleneck block으로 대체했다.(그 결과는 Table1의 50-layer ResNet이다.)</p>

<p>옵션B를 사용해 차원을 키웠고
이 모델의 FLOPs는 38억이다.</p>

<h3 id="101-layer-and-152-layer-resnets">101-layer and 152-layer ResNets</h3>

<p>101-layer과 152-layer ResNet을 만들었다(3-layer block을 더 사용하여)</p>

<p>깊이가 충분히 증가했지만,
152-layer ResNet(113억 FLOPs)은 여전히 VGG-16/19(153억/196억 FLOPs)보다 복잡도가 낮았다.</p>

<p>50/101/152-layer ResNet은 margin을 고려한 34-layer보다 더 정확하다.</p>

<p>degradation을 관찰하지 못했으므로
상당히 깊은 네트워크로부터 충분히 높은 정확도를 얻은 것이다.</p>

<p>모든 평가겨로가에서 깊이에 대한 이점이 발견되었다.</p>

<h3 id="comparisons-with-state-of-the-art-methods">Comparisons with State-of-the art Methods</h3>

<p><img src="/assets/img/ResNet/ResNet8.png" alt="ResNet8" /></p>

<p><img src="/assets/img/ResNet/ResNet9.png" alt="ResNet9" /></p>

<p>위 결과에서 보듯 이전에 사용하던 최고의 단일-모델과 비교했다.</p>

<p>34-layer ResNet이 좋은 결과를 보였다.</p>

<p>152-layer ResNet은 단일-모델로써 top-5 validation error값이 4.49%가 나왔다.</p>

<p>테이블5에서 보이는 여러 모델을 조합한 결과들과 비교가 가능할 정도로
단일 모델인 152-layer ResNet은 매우 뛴어나다.</p>

<p>ensemble을 구성하기 위해 서로다른 깊이의 6개의 모델들을 조합했다.
(제출할 때에는 152-layer 두개만 조합했다.)</p>

<p>결과는 top-5 error값으로 3.57%가 나왔고
이 결과로 ILSVRC-2015 에서 1등을 차지했다.</p>

<h2 id="42-cifar-10-and-analysis">4.2 CIFAR-10 and Analysis</h2>

<p>CIFAR-10(10개의 클래스를 갖는 5만개의 학습 1만개의 테스트이미지)에서 더 많은 연구를 해보았다.</p>

<p>우리의 초점은 최첨단 구조에서 보이는 결과를 얻는 것이 아니기 때문에
extremely deep network의 구조를 간단하게 구성했다.</p>

<p>입력으로 32x32을 받는다(각 픽셀은 평균값들을 뺀 상태이다)</p>

<p>첫 번째 층은 3x3 합성곱층이다.</p>

<p>그리고나서 6n개의 3x3 합성곱 층을 쌓아 특징맵의 크기가 32,16,8에 맞게 할당을 해서
각 특징맵별로 2n개의 합성곱 계산을 해야한다.</p>

<p>subsampling은 stride2인 합성곱으로 진행했다.</p>

<p>네트워크의 마지막 부분은 global average pooling과 10-way fully-connected layer with softmax를 사용했다.</p>

<p>따라서 총 가중치층은 6n+2가 된다.</p>

<p><img src="/assets/img/ResNet/ResNet11.png" alt="ResNet11" /></p>

<p>shortcur connection이 사용되면,
그것들은 3x3 합성곱 두개에 하나씩 연결되어 총 3n개의 shortcut이 생긴다.</p>

<p>CIFAR-10에는 모든 경우에 identity shortcut(option A)을 사용해서
plain 모델과 비교해 깊이, 크기, 매개변수의 수가 모두 같다.</p>

<p>이 때 weight decay 는 0.0001
momentum계수는 0.9
그리고 dropout은 사용하지 않지만 BN을 사용했다.</p>

<p>batch-size는 128로하고
두개의 GPU에서 학습을 진행했다.</p>

<p>learning rate는 0.1로 초기 설정하고 32k와 48k에서 10씩 나눠서 적용했다
그리고 64k iteration에서 학습을 종료했다.(train/val의 크기를 45k/5k로 설정한 결과)</p>

<p>data augmentation은 간단하게하여 학습을 진행했다 :</p>

<p>각 모서리에 4pixel만큼씩 padding을 했고
padding한 이미지와 그것을 뒤집은 이미지로부터 32x32의 크기만큼 임의로 잘랐다.</p>

<p>test를 위해 32x32이미지의 single view만 평가했다.</p>

<p>n={3,5,7,9}를 적용해 20, 32, 44, 56-layer network를 만들었다.</p>

<p><img src="/assets/img/ResNet/ResNet12.png" alt="ResNet12" /></p>

<p>Highway network를 보면 증가된 깊이로부터 error가 증가하는 것을 볼 수 있다.</p>

<p>이 현상은 ImageNet과 MNIST에서 비슷하게 보여진다.
(모두 optimization difficulty가 문제다)</p>

<p>ImageNet에서와 비슷하게 ResNet은 optimization difficulty를 극복하고
깊어진 깊이로부터 높은 정확도를 얻는다고 증명했다.</p>

<p>게다가 n=18인 경우에 110-layer ResNet을 만드는데</p>

<p>이런 경우, 수렴을 시작하기에 앞서 learning rate가 0.1인 것은 다소 높다고 판단했다.</p>

<p>그래서 training error가 80%아래로 내려갈 때까지 0.01로 학습률을 설정했다.</p>

<p>그리고 나서 학습률을 다시 0.1로 설정하고 계속 학습했다.</p>

<p>110-layer도 잘 수렴했다.</p>

<p>110-layer는 최첨단 구조가 아님에도 다른 깊거나 얕은 구조들 (Fitnet and Highway)보다 더 매개변수가 적다.</p>

<p><img src="/assets/img/ResNet/ResNet13.png" alt="ResNet13" /></p>

<p>bold : training error, dashed : test error</p>

<p><img src="/assets/img/ResNet/ResNet14.png" alt="ResNet14" /></p>

<p>bold : training error, dashed : test error</p>

<p><img src="/assets/img/ResNet/ResNet15.png" alt="ResNet15" /></p>

<h3 id="analysis-of-layer-responses">Analysis of Layer Responses</h3>

<p><img src="/assets/img/ResNet/ResNet16.png" alt="ResNet16" /></p>

<p>위 그래프에서 표준편차를 확인할 수 있다.</p>

<p>반응들은 각 3x3 layer에 의한 결과이고 BN의 결과이고 activation함수를 통과하기 전의 값이다.</p>

<p>ResNet에서 이런 분석은 residual functions의 response strength를 표출한다.</p>

<p>위 그래프는 ResNet은 일반적으로 plain 구조에 비해 response가 작다고 보여준다.</p>

<p>이러한 결과는 우리의 기본 동기를 뒷받침해준다.</p>

<p>따라서 보통 residual function이 일반적으로 non-residual인것보다 0에 더 가깝다는 것이다.</p>

<p>또한, 깊은 ResNet은 더 작은 크기의 response를 보인다.</p>

<p>더 많은 층이 있을 경우, ResNet의 각 층은 신호를 덜 수정하는 경향이 있다.</p>

<h3 id="exploring-over-1000-layers">Exploring Over 1000 layers</h3>

<p>1000층이 넘는 아주 깊은 모델을 조사해보자.</p>

<p>n=200으로 설정을해서 1202-layer network를 만들었다.
학습은 위와 같은 방법으로 진행했다.</p>

<p>우리의 방법은 optimization difficulty를 보이지 않고
이 1000-layer network는 0.1미만의 학습 오차를 달성할 수 있다.</p>

<p>이것의 test error는 여전히 괜찮은 수준인 7.93%이다.</p>

<p>하지만 여전히 매우 깊은 모델이 갖는 문제는 해결되지 않았다.</p>

<p>1202-layer의 test 결과는 우리의 110-layer 네트워크보다 안좋다.
(비록 두 모델이 비슷한 학습에러를 결과를 보이지만)</p>

<p>이것은 과적합 때문인다.</p>

<p>1202-layer는 이 작은 데이터셋에 불필요하게 많은 층이 사용되었다.</p>

<p>강력한 regularization(e.g.,  maxout, dropout)은 이 데이터셋을 상대로 최고의 결과를 얻기 위해 사용되었다.</p>

<p>그러나 이번 연구에서 maxout과 dropout은 사용하지 않았고
구조적으로 깊고 얕음을 통해 regularization을 부과하고
optimization difficulty에는 초점을 두지 않았다.</p>

<p>하지만, 강력한 regularization의 조합은 결과를 향상시킬것이다.(앞으로 연구해볼 것이다.)</p>

<h2 id="43-object-detection-on-pascal-and-ms-coco">4.3 Object Detection on PASCAL and MS COCO</h2>

<p>우리의 방법은 다른 recognition 작업에서도 좋은 generalization 성능을 보인다.</p>

<p><img src="/assets/img/ResNet/ResNet17.png" alt="ResNet17" /></p>

<p>Table7과 Table8 에서 볼 수 있듯이
object detection baseline은 PASCAL VOC 2007 and 2012 and COCO를 통해 평가했다.</p>

<p>detection 방법으로 Faster R-CNN을 채택했다.</p>

<p>우리는 VGG-16을 ResNet-101로 대체하여 개선하는 것에 관심이 있다.</p>

<p>두 모델을 사용하여 detection 구현하는 것은 같다,</p>

<p>따라서 더 좋은 네트워크를 기반으로 이점이 생긴다.</p>

<p>대부분 눈에 띄는 점은, COCO데이터셋에서 6.0% 상승한 값을 얻었다는 것이다.(상대적으로 28% 개선됨)</p>

<p>이런 이점은 단지 learned representation때문인 것이다.</p>

<p>Deep residual net을 기반으로 ILSVRC &amp; COCO 2015 competition에서 몇몇 부문에서 1등을 차지했다 :
ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.</p>

  </div><a class="u-url" href="/paper%20review/2022/08/20/ResNet.html" hidden></a>
</article>

        </div>
      </main>
    </div><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Humans think like Machines, Machines think like Humans</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Chang Hun Kang</li><li><a class="u-email" href="mailto:abcd877287@gmail.com">abcd877287@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/Kchnaghun"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">Kchnaghun</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
